{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD Scripts Kaggle\n",
    "#### Created by [licyk](https://github.com/licyk)\n",
    "\n",
    "Jupyter Notebook 仓库：[licyk/sd-webui-all-in-one](https://github.com/licyk/sd-webui-all-in-one)\n",
    "\n",
    "一个在 [Kaggle](https://www.kaggle.com) 部署 [sd-scripts](https://github.com/kohya-ss/sd-scripts) 的 Jupyter Notebook。\n",
    "\n",
    "使用时请按顺序运行笔记单元。\n",
    "\n",
    "## 提示：\n",
    "1. 可以将训练数据上传至`kaggle/input`文件夹，运行安装时将会把训练数据放置`/kaggle/dataset`文件夹中。\n",
    "2. 训练需要的模型将下载至`/kaggle/sd-scripts/sd-models`文件夹中。\n",
    "3. 推荐将训练输出的模型路径改为`kaggle/working`文件夹，方便下载。\n",
    "4. 训练代码的部分需要根据自己的需求进行更改。\n",
    "5. 推荐使用 Kaggle 的 Save Version 的功能运行笔记，可让 Kaggle 笔记在无人值守下保持运行，直至所有单元运行完成。\n",
    "6. 如果有 [HuggingFace](https://huggingface.co) 账号或者 [ModelScope](https://modelscope.cn) 账号，可通过填写 Token 和仓库名后实现自动上传训练好的模型，仓库需要手动创建。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 功能初始化\n",
    "1. [[下一个单元 →](#参数配置)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 消息格式输出\n",
    "def echo(msg):\n",
    "    print(f\":: {msg}\")\n",
    "\n",
    "\n",
    "# ARIA2\n",
    "class ARIA2:\n",
    "    WORKSPACE = \"\"\n",
    "    WORKFOLDER = \"\"\n",
    "\n",
    "\n",
    "    def __init__(self, workspace, workfolder) -> None:\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    # 下载器\n",
    "    def aria2(self, url, path, filename):\n",
    "        import os\n",
    "        if not os.path.exists(path + \"/\" + filename):\n",
    "            echo(f\"开始下载 {filename} ，路径: {path}/{filename}\")\n",
    "            !aria2c --console-log-level=error -c -x 16 -s 16 \"{url}\" -d \"{path}\" -o \"{filename}\"\n",
    "            if os.path.exists(path + \"/\" + filename) and not os.path.exists(path + \"/\" + filename + \".aria2\"):\n",
    "                echo(f\"{filename} 下载完成\")\n",
    "            else:\n",
    "                echo(f\"{filename} 下载中断\")\n",
    "        else:\n",
    "            if os.path.exists(path + \"/\" + filename + \".aria2\"):\n",
    "                echo(f\"开始下载 {filename} ，路径: {path}/{filename}\")\n",
    "                !aria2c --console-log-level=error -c -x 16 -s 16 \"{url}\" -d \"{path}\" -o \"{filename}\"\n",
    "                if os.path.exists(path + \"/\" + filename) and not os.path.exists(path + \"/\" + filename + \".aria2\"):\n",
    "                    echo(f\"{filename} 下载完成\")\n",
    "                else:\n",
    "                    echo(f\"{filename} 下载中断\")\n",
    "            else:\n",
    "                echo(f\"{filename} 文件已存在，路径: {path}/{filename}\")\n",
    "\n",
    "\n",
    "    # 大模型下载\n",
    "    def get_sd_model(self, url, filename):\n",
    "        pass\n",
    "\n",
    "\n",
    "    # vae模型下载\n",
    "    def get_vae_model(self, url, filename):\n",
    "        pass\n",
    "\n",
    "\n",
    "# GIT\n",
    "class GIT:\n",
    "    WORKSPACE = \"\"\n",
    "    WORKFOLDER = \"\"\n",
    "\n",
    "\n",
    "    def __init__(self, workspace, workfolder) -> None:\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    # 检测要克隆的项目是否存在于指定路径\n",
    "    def exists(self, addr=None, path=None, name=None):\n",
    "        import os\n",
    "        if addr is not None:\n",
    "            if path is None and name is None:\n",
    "                path = os.getcwd() + \"/\" + addr.split(\"/\").pop().split(\".git\", 1)[0]\n",
    "            elif path is None and name is not None:\n",
    "                path = os.getcwd() + \"/\" + name\n",
    "            elif path is not None and name is None:\n",
    "                path = os.path.normpath(path) + \"/\" + addr.split(\"/\").pop().split(\".git\", 1)[0]\n",
    "\n",
    "        if os.path.exists(path):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    # 克隆项目\n",
    "    def clone(self, addr, path=None, name=None):\n",
    "        import os\n",
    "        repo = addr.split(\"/\").pop().split(\".git\", 1)[0]\n",
    "        if not self.exists(addr, path, name):\n",
    "            echo(f\"开始下载 {repo}\")\n",
    "            if path is None and name is None:\n",
    "                path = os.getcwd()\n",
    "                name = repo\n",
    "            elif path is not None and name is None:\n",
    "                name = repo\n",
    "            elif path is None and name is not None:\n",
    "                path = os.getcwd()\n",
    "            !git clone {addr} \"{path}/{name}\" --recurse-submodules\n",
    "        else:\n",
    "            echo(f\"{repo} 已存在\")\n",
    "\n",
    "\n",
    "\n",
    "# ENV\n",
    "class ENV:\n",
    "    WORKSPACE = \"\"\n",
    "    WORKFOLDER = \"\"\n",
    "\n",
    "\n",
    "    def __init__(self, workspace, workfolder) -> None:\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    # 准备ipynb笔记自身功能的依赖\n",
    "    def prepare_env_depend(self, use_mirror=True):\n",
    "        if use_mirror is True:\n",
    "            pip_mirror = \"--index-url https://mirrors.cloud.tencent.com/pypi/simple --find-links https://mirror.sjtu.edu.cn/pytorch-wheels/cu121/torch_stable.html\"\n",
    "        else:\n",
    "            pip_mirror = \"--index-url https://pypi.python.org/simple --find-links https://download.pytorch.org/whl/cu121/torch_stable.html\"\n",
    "\n",
    "        echo(\"安装自身组件依赖\")\n",
    "        !pip install huggingface_hub modelscope {pip_mirror}\n",
    "        !apt update\n",
    "        !apt install aria2 ssh google-perftools p7zip-full unzip -y\n",
    "\n",
    "\n",
    "    # 安装pytorch和xformers\n",
    "    def prepare_torch(self, torch_ver, xformers_ver, use_mirror=False):\n",
    "        arg = \"--no-deps\"\n",
    "        if use_mirror is True:\n",
    "            pip_mirror = \"--index-url https://mirrors.cloud.tencent.com/pypi/simple --find-links https://mirror.sjtu.edu.cn/pytorch-wheels/cu121/torch_stable.html\"\n",
    "        else:\n",
    "            pip_mirror = \"--index-url https://pypi.python.org/simple --find-links https://download.pytorch.org/whl/cu121/torch_stable.html\"\n",
    "        \n",
    "        if torch_ver != \"\":\n",
    "            echo(\"安装 PyTorch\")\n",
    "            !pip install {torch_ver} {pip_mirror}\n",
    "        if xformers_ver != \"\":\n",
    "            echo(\"安装 xFormers\")\n",
    "            !pip install {xformers_ver} {pip_mirror} {arg}\n",
    "    \n",
    "\n",
    "    # 安装requirements.txt依赖\n",
    "    def install_requirements(self, path, use_mirror=False):\n",
    "        import os\n",
    "        if use_mirror is True:\n",
    "            pip_mirror = \"--index-url https://mirrors.cloud.tencent.com/pypi/simple --find-links https://mirror.sjtu.edu.cn/pytorch-wheels/cu121/torch_stable.html\"\n",
    "        else:\n",
    "            pip_mirror = \"--index-url https://pypi.python.org/simple --find-links https://download.pytorch.org/whl/cu121/torch_stable.html\"\n",
    "        if os.path.exists(path):\n",
    "            echo(\"安装依赖\")\n",
    "            !pip install -r \"{path}\" {pip_mirror}\n",
    "        else:\n",
    "            echo(\"依赖文件路径为空\")\n",
    "\n",
    "\n",
    "    # python软件包安装\n",
    "    # 可使用的操作:\n",
    "    # 安装: install -> install\n",
    "    # 仅安装: install_single -> install --no-deps\n",
    "    # 强制重装: force_install -> install --force-reinstall\n",
    "    # 仅强制重装: force_install_single -> install --force-reinstall --no-deps\n",
    "    # 更新: update -> install --upgrade\n",
    "    # 卸载: uninstall -y\n",
    "    def py_pkg_manager(self, pkg, type=None, use_mirror=False):\n",
    "        if use_mirror is True:\n",
    "            pip_mirror = \"--index-url https://mirrors.cloud.tencent.com/pypi/simple --find-links https://mirror.sjtu.edu.cn/pytorch-wheels/cu121/torch_stable.html\"\n",
    "        else:\n",
    "            pip_mirror = \"--index-url https://pypi.python.org/simple --find-links https://download.pytorch.org/whl/cu121/torch_stable.html\"\n",
    "\n",
    "        if type == \"install\":\n",
    "            func = \"install\"\n",
    "            args = \"\"\n",
    "        elif type == \"install_single\":\n",
    "            func = \"install\"\n",
    "            args = \"--no-deps\"\n",
    "        elif type == \"force_install\":\n",
    "            func = \"install\"\n",
    "            args = \"--force-reinstall\"\n",
    "        elif type == \"force_install_single\":\n",
    "            func = \"install\"\n",
    "            args = \"install --force-reinstall --no-deps\"\n",
    "        elif type == \"update\":\n",
    "            func = \"install\"\n",
    "            args = \"--upgrade\"\n",
    "        elif type == \"uninstall\":\n",
    "            func = \"uninstall\"\n",
    "            args = \"-y\"\n",
    "            pip_mirror = \"\"\n",
    "        else:\n",
    "            echo(f\"未知操作: {type}\")\n",
    "            return\n",
    "        echo(f\"执行操作: pip {func} {pkg} {args} {pip_mirror}\")\n",
    "        !pip {func} {pkg} {args} {pip_mirror}\n",
    "\n",
    "\n",
    "    # 配置内存优化\n",
    "    def tcmalloc(self):\n",
    "        echo(\"配置内存优化\")\n",
    "        import os\n",
    "        os.environ[\"LD_PRELOAD\"] = \"/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4\"\n",
    "\n",
    "\n",
    "\n",
    "# MANAGER\n",
    "class MANAGER:\n",
    "    WORKSPACE = \"\"\n",
    "    WORKFOLDER = \"\"\n",
    "\n",
    "\n",
    "    def __init__(self, workspace, workfolder) -> None:\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    # 清理ipynb笔记的输出\n",
    "    def clear_up(self, opt):\n",
    "        from IPython.display import clear_output\n",
    "        clear_output(wait=opt)\n",
    "\n",
    "\n",
    "    # 检查gpu是否可用\n",
    "    def check_gpu(self):\n",
    "        echo(\"检测 GPU 是否可用\")\n",
    "        import tensorflow as tf\n",
    "        echo(f\"TensorFlow 版本: {tf.__version__}\")\n",
    "        if tf.test.gpu_device_name():\n",
    "            echo(\"GPU 可用\")\n",
    "        else:\n",
    "            echo(\"GPU 不可用\")\n",
    "            raise Exception(\"\\n没有使用GPU，请在代码执行程序-更改运行时类型-设置为GPU！\\n如果不能使用GPU，建议更换账号！\")\n",
    "\n",
    "\n",
    "\n",
    "class REPO_MANAGER:\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "    # 获取文件夹中所有的文件的绝对路径\n",
    "    def get_all_file(self, directory):\n",
    "        import os\n",
    "        file_list = []\n",
    "        for dirname, _, filenames in os.walk(directory):\n",
    "            for filename in filenames:\n",
    "                file_list.append(os.path.join(dirname, filename))\n",
    "        return file_list\n",
    "\n",
    "\n",
    "    # ModelScope\n",
    "    # 检测是否存在于仓库中\n",
    "    def is_file_exists_in_ms_repo(self, upload_file, work_path, repo):\n",
    "        import os\n",
    "        repo_file = os.path.join(work_path, repo.split(\"/\").pop(), upload_file)\n",
    "        if os.path.exists(repo_file):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    # 克隆仓库\n",
    "    def clone_modelscope_without_lfs(self, ms_access_token, repo, work_path):\n",
    "        import os\n",
    "        # 禁用 Git LFS\n",
    "        os.environ[\"GIT_LFS_SKIP_SMUDGE\"] = \"1\"\n",
    "        !git lfs uninstall\n",
    "\n",
    "        # 本地存在仓库时进行删除\n",
    "        repo_name = repo.split(\"/\").pop()\n",
    "        path = os.path.join(work_path, repo_name)\n",
    "        if os.path.exists(path):\n",
    "            !rm -rf \"{path}\"\n",
    "\n",
    "        # 下载仓库并启用 Git LFS\n",
    "        repo_url = f\"https://oauth2:{ms_access_token}@www.modelscope.cn/{repo}.git\"\n",
    "        !git clone \"{repo_url}\" \"{path}\"\n",
    "        os.environ[\"GIT_LFS_SKIP_SMUDGE\"] = \"0\"\n",
    "        !git lfs install\n",
    "\n",
    "\n",
    "    # 上传文件至 ModelScope\n",
    "    def push_file_to_modelscope(self, ms_access_token, repo, work_path, upload_path):\n",
    "        import os\n",
    "        from modelscope.hub.api import HubApi\n",
    "        if repo.split(\"/\").pop() == upload_path.split(\"/\").pop():\n",
    "            raise Exception(\"本地要上传的仓库名称与要上传到的仓库的名称相同, 这将导致本地要上传的仓库被自动删除\")\n",
    "\n",
    "        api = HubApi()\n",
    "        try:\n",
    "            ms_access_token = api.login(ms_access_token)[0] # 将 ModelScope Token 转为 ModelScope Git Token\n",
    "            echo(\"ModelScope Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"ModelScope Token 验证失败: \", e)\n",
    "\n",
    "        os.chdir(work_path)\n",
    "        count = 0\n",
    "        upload_file_lists = self.get_all_file(upload_path) # 原文件的路径列表\n",
    "\n",
    "        echo(f\"将文件上传至 ModelScope:: {upload_path} -> {os.path.join(work_path, repo.split('/').pop())}\")\n",
    "        count = 0\n",
    "        sum = len(upload_file_lists)\n",
    "        for upload_file in upload_file_lists:\n",
    "            count += 1\n",
    "\n",
    "            echo(f\"[{count}/{sum}]:: 克隆仓库到 {work_path}\")\n",
    "            self.clone_modelscope_without_lfs(ms_access_token, repo, work_path)\n",
    "            rel_upload_file = os.path.relpath(upload_file, upload_path) # 原文件相对路径\n",
    "            repo_path = os.path.join(work_path, repo.split(\"/\").pop()) # 仓库的绝对路径\n",
    "            echo(f\"[{count}/{sum}]:: 要上传的文件的相对路径: {rel_upload_file}\")\n",
    "            echo(f\"[{count}/{sum}]:: 绝对路径: {upload_file}\")\n",
    "            echo(f\"[{count}/{sum}]:: 仓库地址: {repo_path}\")\n",
    "\n",
    "            # 检测文件是否存在于仓库中\n",
    "            if self.is_file_exists_in_ms_repo(rel_upload_file, work_path, repo):\n",
    "                !rm -rf \"{repo_path}\"\n",
    "                echo(f\"[{count}/{sum}]:: {os.path.basename(upload_file)} 已存在于仓库中\")\n",
    "            else:\n",
    "                # 为仓库创建对应的文件夹\n",
    "                p_path = os.path.dirname(os.path.join(work_path, repo.split(\"/\").pop(), rel_upload_file)) # 原文件到仓库中后对应的父文件夹\n",
    "                if not os.path.exists(p_path):\n",
    "                    echo(f\"[{count}/{sum}]:: 创建文件对应的父文件夹: {p_path}\")\n",
    "                    os.makedirs(p_path, exist_ok=True)\n",
    "\n",
    "                echo(f\"[{count}/{sum}]:: {upload_file} -> {repo_path}\")\n",
    "                !cp \"{upload_file}\" \"{p_path}\"\n",
    "\n",
    "                os.chdir(repo_path)\n",
    "                file_name = rel_upload_file.split(\"/\").pop() # 文件名\n",
    "                echo(f\"[{count}/{sum}]:: 添加文件： {rel_upload_file}\")\n",
    "                !git add \"{rel_upload_file}\"\n",
    "                echo(f\"[{count}/{sum}]:: 提交信息: \\\"upload {file_name}\\\"\")\n",
    "                !git commit -m \"upload {file_name}\"\n",
    "                !git config lfs.https://oauth2:{ms_access_token}@www.modelscope.cn/{repo}.git/info/lfs.locksverify true\n",
    "                echo(f\"[{count}/{sum}]:: 上传 {file_name} 到 {repo} 中\")\n",
    "                !git push\n",
    "\n",
    "                os.chdir(work_path)\n",
    "                !rm -rf \"{repo_path}\"\n",
    "                echo(f\"[{count}/{sum}]:: 上传 {file_name} 完成\")\n",
    "\n",
    "        echo(f\"[{count}/{sum}]:: {repo} 仓库上传完成\")\n",
    "\n",
    "\n",
    "    # HuggingFace\n",
    "    # 获取 HuggingFace 仓库中的文件列表\n",
    "    def get_hf_repo_file_list(self, hf_access_token, repo, repo_type):\n",
    "        from huggingface_hub import HfApi\n",
    "        api = HfApi()\n",
    "        model_list = api.list_repo_files(\n",
    "            repo_id = repo,\n",
    "            repo_type = repo_type,\n",
    "            token = hf_access_token\n",
    "        )\n",
    "        return model_list\n",
    "\n",
    "\n",
    "    # 上传文件到 HuggingFace\n",
    "    def push_file_to_huggingface(self, hf_access_token, repo, repo_type, work_path, upload_path):\n",
    "        import os\n",
    "        from pathlib import Path\n",
    "        from huggingface_hub import HfApi, CommitOperationAdd\n",
    "        api = HfApi()\n",
    "\n",
    "        try:\n",
    "            api.whoami(token = hf_access_token)\n",
    "            echo(\"HuggingFace Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"HuggingFace Token 验证失败: \", e)\n",
    "\n",
    "        os.chdir(work_path)\n",
    "        count = 0\n",
    "        upload_file_lists = self.get_all_file(upload_path) # 原文件的路径列表\n",
    "\n",
    "        echo(f\"将文件上传至 HuggingFace:: {upload_path} -> {os.path.join(work_path, repo.split('/').pop())}\")\n",
    "        count = 0\n",
    "        sum = len(upload_file_lists)\n",
    "        hf_repo_flie_list = self.get_hf_repo_file_list(hf_access_token, repo, repo_type) # 获取仓库中的文件列表\n",
    "        for upload_file in upload_file_lists:\n",
    "            count += 1\n",
    "\n",
    "            echo(f\"[{count}/{sum}]:: 克隆仓库到 {work_path}\")\n",
    "            rel_upload_file = os.path.relpath(upload_file, upload_path) # 原文件相对路径\n",
    "            repo_path = os.path.join(work_path, repo.split(\"/\").pop()) # 仓库的绝对路径\n",
    "            echo(f\"[{count}/{sum}]:: 要上传的文件的相对路径: {rel_upload_file}\")\n",
    "            echo(f\"[{count}/{sum}]:: 绝对路径: {upload_file}\")\n",
    "            echo(f\"[{count}/{sum}]:: 仓库地址: {repo_path}\")\n",
    "\n",
    "            # 检测文件是否存在于仓库中\n",
    "            if rel_upload_file in hf_repo_flie_list:\n",
    "                echo(f\"[{count}/{sum}]:: {os.path.basename(upload_file)} 已存在于仓库中\")\n",
    "            else:\n",
    "                file_name = rel_upload_file.split(\"/\").pop() # 文件名\n",
    "                hf_path_in_repo = Path(rel_upload_file).as_posix()\n",
    "                local_file_obj = Path(upload_file).as_posix()\n",
    "                echo(f\"[{count}/{sum}]:: {local_file_obj} -> {repo}/{hf_path_in_repo}\")\n",
    "                operations = [ CommitOperationAdd(path_in_repo = hf_path_in_repo, path_or_fileobj = local_file_obj) ]\n",
    "                echo(f\"[{count}/{sum}]:: 上传 {file_name} 到 {repo} 中\")\n",
    "                api.create_commit(\n",
    "                    repo_id = repo,\n",
    "                    operations = operations,\n",
    "                    commit_message = f\"Upload {file_name}\",\n",
    "                    repo_type = repo_type,\n",
    "                    token = hf_access_token\n",
    "                )\n",
    "                echo(f\"[{count}/{sum}]:: 上传 {file_name} 完成\")\n",
    "\n",
    "        echo(f\"[{count}/{sum}]:: {repo} 仓库上传完成\")\n",
    "\n",
    "\n",
    "    # HuggingFace / ModelScope Token 验证\n",
    "    def verify_huggingface_token(self, hf_token):\n",
    "        from huggingface_hub import HfApi\n",
    "        api = HfApi()\n",
    "        try:\n",
    "            api.whoami(token = hf_token)\n",
    "            echo(\"HuggingFace Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"HuggingFace Token 验证失败: \", e)\n",
    "\n",
    "\n",
    "    def verify_modelscope_token(self, ms_token):\n",
    "        from modelscope.hub.api import HubApi\n",
    "        api = HubApi()\n",
    "        try:\n",
    "            api.login(ms_token)\n",
    "            echo(\"ModelScope Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"ModelScope Token 验证失败: \", e)\n",
    "\n",
    "\n",
    "    def get_modelscope_git_token(ms_token):\n",
    "        from modelscope.hub.api import HubApi\n",
    "        api = HubApi()\n",
    "        try:\n",
    "            token = api.login(ms_token)[0]\n",
    "            return token\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    # 配置 Git 信息\n",
    "    def set_git_config(self, email, username):\n",
    "        echo(\"配置 Git 信息中\")\n",
    "        !git config --global user.email \"{email}\"\n",
    "        !git config --global user.name \"{username}\"\n",
    "\n",
    "\n",
    "\n",
    "class DATASET(ARIA2):\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "    def get_dataset(self, dataset_path, url, name = None):\n",
    "        import os\n",
    "        path = \"/tmp\"\n",
    "        if name is None:\n",
    "            name = url.split(\"/\").pop()\n",
    "        super().aria2(url, path, name) # 下载文件\n",
    "        archive_format = name.split(\".\").pop()\n",
    "        origin_file_path = os.path.join(path, name)\n",
    "        echo(f\"尝试解压 {name}\")\n",
    "        if archive_format == \"7z\":\n",
    "            !7z x \"{origin_file_path}\" -o\"{dataset_path}\"\n",
    "        elif archive_format == \"zip\":\n",
    "            !unzip \"{origin_file_path}\" -d \"{dataset_path}\"\n",
    "        else:\n",
    "            echo(f\"{name} 的格式不支持解压\")\n",
    "\n",
    "\n",
    "\n",
    "# SD_SCRIPTS\n",
    "class SD_SCRIPTS(ARIA2, GIT, MANAGER, ENV):\n",
    "    WORKSPACE = \"\"\n",
    "    WORKFOLDER = \"\"\n",
    "\n",
    "    repo_manager = REPO_MANAGER()\n",
    "    dataset = DATASET()\n",
    "\n",
    "    def __init__(self, workspace, workfolder) -> None:\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    def get_sd_model(self, url, filename = None):\n",
    "        path = self.WORKSPACE + \"/\" + self.WORKFOLDER + \"/sd-models\"\n",
    "        filename = url.split(\"/\").pop() if filename is None else filename\n",
    "        super().aria2(url, path, filename)\n",
    "\n",
    "\n",
    "    def get_vae_model(self, url, filename = None):\n",
    "        path = self.WORKSPACE + \"/\" + self.WORKFOLDER + \"/sd-models\"\n",
    "        filename = url.split(\"/\").pop() if filename is None else filename\n",
    "        super().aria2(url, path, filename)\n",
    "\n",
    "\n",
    "    def get_sd_model_from_list(self, list):\n",
    "        for i in list:\n",
    "            if i != \"\":\n",
    "                self.get_sd_model(i, i.split(\"/\").pop())\n",
    "\n",
    "\n",
    "    def get_vae_model_from_list(self, list):\n",
    "        for i in list:\n",
    "            if i != \"\":\n",
    "                self.get_vae_model(i, i.split(\"/\").pop())\n",
    "\n",
    "\n",
    "    def install(self, torch_ver, xformers_ver, sd, vae, use_mirror):\n",
    "        import os\n",
    "        self.check_gpu()\n",
    "        self.prepare_env_depend(use_mirror)\n",
    "        self.clone(\"https://github.com/kohya-ss/sd-scripts\", self.WORKSPACE)\n",
    "        os.chdir(os.path.join(self.WORKSPACE, self.WORKFOLDER))\n",
    "        self.prepare_torch(torch_ver, xformers_ver)\n",
    "        req_file = os.path.join(self.WORKSPACE, self.WORKFOLDER, \"requirements.txt\")\n",
    "        self.install_requirements(req_file, use_mirror)\n",
    "        self.py_pkg_manager(\"lycoris-lora dadaptation open-clip-torch wandb\", \"install\", use_mirror)\n",
    "        self.tcmalloc()\n",
    "        self.get_sd_model_from_list(sd)\n",
    "        self.get_vae_model_from_list(vae)\n",
    "\n",
    "###################################\n",
    "echo(\"初始化功能完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参数配置\n",
    "2. [[← 上一个单元](#功能初始化)|[下一个单元 →](#安装)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE = \"/kaggle\" # 工作路径\n",
    "WORKFOLDER = \"sd-scripts\" # 工作路径中文件夹名称, 通常无需更改\n",
    "TORCH_VER = \"torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121\" # PyTorch 版本\n",
    "XFORMERS_VER = \"xformers==0.0.26.post1\" # xFormers 版本\n",
    "USE_MIRROR = False # 使用国内 Pip 镜像源, Kaggle 无需启用\n",
    "USE_HF_TO_SAVE_MODEL = False # 使用 HuggingFace 保存训练好的模型, 修改为 True 为启用\n",
    "USE_MS_TO_SAVE_MODEL = False # 使用 ModelScope 保存训练好的模型\n",
    "HF_TOKEN = \"\" # HuggingFace Token\n",
    "MS_TOKEN = \"\" # ModelScope Token\n",
    "HF_REPO_ID = \"username/reponame\" # HuggingFace 仓库的名称\n",
    "MS_REPO_ID = \"username/reponame\" # ModelScope 仓库的名称\n",
    "HF_REPO_TYPE = \"model\" # HuggingFace 仓库的种类\n",
    "GIT_USER_EMAIL = \"username@xxx.com\" # Git 的邮箱\n",
    "GIT_USER_NAME = \"username\" # Git 的用户名\n",
    "INPUT_DATASET_PATH = \"/kaggle/dataset\" # 训练集保存的路径\n",
    "OUTPUT_PATH = \"/kaggle/working/model\" # 训练时模型保存的路径\n",
    "SD_MODEL = [ # 前面为 Stable Diffusion 模型的下载链接, 后面为 1 时将会下载该模型\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/v1-5-pruned-emaonly.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/animefull-final-pruned.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/Counterfeit-V3.0_fp16.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/cetusMix_Whalefall2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/cuteyukimixAdorable_neochapter3.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/ekmix-pastel-fp16-no-ema.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/ex2K_sse2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/kohakuV5_rev2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/meinamix_meinaV11.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/oukaStar_10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/pastelMixStylizedAnime_pastelMixPrunedFP16.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/rabbit_v6.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/sweetSugarSyndrome_rev15.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/AnythingV5Ink_ink.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/bartstyledbBlueArchiveArtStyleFineTunedModel_v10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/meinapastel_v6Pastel.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/qteamixQ_omegaFp16.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/tmndMix_tmndMixSPRAINBOW.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/sd_xl_base_1.0_0.9vae.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animagine-xl-3.0.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/AnythingXL_xl.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/abyssorangeXLElse_v10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animaPencilXL_v200.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animagine-xl-3.1.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/heartOfAppleXL_v20.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/baxlBartstylexlBlueArchiveFlatCelluloid_xlv1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohaku-xl-delta-rev1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohakuXLEpsilon_rev1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohaku-xl-epsilon-rev3.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/nekorayxl_v06W3.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/CounterfeitXL-V1.0.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/ponyDiffusionV6XL_v6StartWithThisOne.safetensors\", 0]\n",
    "]\n",
    "VAE = [ # VAE 模型\n",
    "    [\"https://huggingface.co/licyk/sd-vae/resolve/main/sd_1.5/vae-ft-ema-560000-ema-pruned.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-vae/resolve/main/sd_1.5/vae-ft-mse-840000-ema-pruned.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-vae/resolve/main/sdxl_1.0/sdxl_fp16_fix_vae.safetensors\", 1]\n",
    "]\n",
    "echo(\"参数设置完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 安装\n",
    "3. [[← 上一个单元](#参数配置)|[下一个单元 →](#模型训练)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(WORKSPACE)\n",
    "sd_scripts = SD_SCRIPTS(WORKSPACE, WORKFOLDER)\n",
    "# 处理模型列表\n",
    "sd_model_list = []\n",
    "vae_list = []\n",
    "for i in SD_MODEL:\n",
    "    if i[1] == 1:\n",
    "        sd_model_list.append(i[0])\n",
    "\n",
    "for i in VAE:\n",
    "    if i[1] == 1:\n",
    "        vae_list.append(i[0])\n",
    "\n",
    "echo(f\"开始安装 sd-scripts\")\n",
    "sd_scripts.install(TORCH_VER, XFORMERS_VER, sd_model_list, vae_list, USE_MIRROR) # 安装 sd-scripts\n",
    "os.makedirs(os.path.join(WORKSPACE, \"working\", \"MS_REPO\"), exist_ok = True) # 为 ModelScope 仓库创建临时文件夹\n",
    "os.makedirs(OUTPUT_PATH, exist_ok = True) # 训练时保存模型的路径\n",
    "os.makedirs(INPUT_DATASET_PATH, exist_ok = True) # 创建 INPUT_DATASET_PATH 指定的路径\n",
    "\n",
    "# 将 /kaggle/input 内的文件移动到 INPUT_DATASET_PATH 指定的路径\n",
    "kaggle_input = \"/kaggle/input\"\n",
    "for i in os.listdir(kaggle_input):\n",
    "    f = os.path.join(kaggle_input, i)\n",
    "    !cp -r \"{f}\" \"{INPUT_DATASET_PATH}\"\n",
    "\n",
    "# 下载数据集\n",
    "# 使用格式:\n",
    "# sd_scripts.dataset.get_dataset(INPUT_DATASET_PATH, \"https://modelscope.cn/models/user/repo/resolve/master/data_1.7z\")\n",
    "# sd_scripts.dataset.get_dataset(INPUT_DATASET_PATH, \"https://modelscope.cn/models/user/repo/resolve/master/data_1.7z\", \"data_1.7z\")\n",
    "# 如果不需要该功能向 Kaggle 传入数据集, 可使用 Kaggle 的 DataSet 功能\n",
    "\n",
    "sd_scripts.clear_up(False)\n",
    "echo(\"sd-scripts 安装完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练\n",
    "需自行编写命令，下方有可参考的例子  \n",
    "4. [[← 上一个单元](#安装)|[下一个单元 →](#模型上传)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(WORKSPACE, WORKFOLDER))\n",
    "##########################################################################################\n",
    "# 运行前需要根据自己的需求更改参数\n",
    "# \n",
    "# 训练参数的设置可参考：\n",
    "# https://rentry.org/59xed3\n",
    "# https://github.com/kohya-ss/sd-scripts?tab=readme-ov-file#links-to-usage-documentation\n",
    "# https://github.com/bmaltais/kohya_ss/wiki/LoRA-training-parameters\n",
    "# \n",
    "# 下方被注释的代码选择后使用 Ctrl + / 取消注释\n",
    "# 训练使用的底模会被下载到 /kaggle/sd-scripts/sd-models\n",
    "# 填写底模路径时一般可以通过 --pretrained_model_name_or_path=\"sd-models/base_model.safetensors\" 指定\n",
    "# \n",
    "# 通过 Kaggle DataSet 导入的训练集保存在 /kaggle/input, 运行该笔记时将会把训练集复制进 /kaggle/dataset\n",
    "# 该路径可通过 INPUT_DATASET_PATH 调整\n",
    "# 如果使用 sd_scripts.dataset.get_dataset() 函数下载训练集, 数据集一般会解压到 /kaggle/dataset, 这取决于函数第一个参数传入的路径\n",
    "# 训练集的路径通常要这种结构\n",
    "# $ tree /kaggle\n",
    "# kaggle\n",
    "# └── dataset\n",
    "#     └── Nachoneko\n",
    "#         └── 1_gan_cheng\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "#             ├── 0(8).txt\n",
    "#             ├── 0(8).webp\n",
    "#             ├── 001_2.png\n",
    "#             ├── 001_2.txt\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "#             ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "#             └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "# 4 directories, 12 files\n",
    "# 在填写训练集路径时, 应使用 --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\"\n",
    "# \n",
    "# 模型保存的路径通常用 --output_dir=\"{OUTPUT_PATH}\" 指定, OUTPUT_PATH 默认设置为 /kaggle/working/model\n",
    "# 在 Kaggle 的 output 中可以看到保存的模型, 前提是使用 Kaggle 的 Save Version 运行 Kaggle\n",
    "# OUTPUT_PATH 也指定了保存模型到 HuggingFace / ModelScope 的功能的上传路径\n",
    "# \n",
    "# Kaggle 的实例最长可运行 12 h, 要注意训练时长不要超过 12 h, 否则将导致训练被意外中断, 并且最后的模型保存功能将不会得到运行\n",
    "# 如果需要在模型被保存后立即上传到 HuggingFace 进行保存, 可使用启动参数为 sd-scripts 设置自动保存, 具体可阅读 sd-scripts 的帮助信息\n",
    "# 使用 python train_network.py -h 命令可查询可使用的启动参数, 命令中的 train_network.py 可替换成 sdxl_train_network.py 等\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "# 测试\n",
    "# !accelerate launch \\\n",
    "#     --num_cpu_threads_per_process 1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     train_network.py \\\n",
    "#     --enable_bucket \\\n",
    "#     --optimizer_type Lion8bit \\\n",
    "#     --save_state \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=10000 \\\n",
    "#         conv_alpha=10000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --train_batch_size=4 \\\n",
    "#     --pretrained_model_name_or_path=sd-models/animefull-final-pruned.safetensors \\\n",
    "#     --output_dir=output \\\n",
    "#     --train_data_dir=/kaggle/input/dataset-style-rafa \\\n",
    "#     --logging_dir=./logs \\\n",
    "#     --log_prefix=kohaku-xl-delta-lyco \\\n",
    "#     --resolution=1024,1024 \\\n",
    "#     --network_module=lycoris.kohya \\\n",
    "#     --max_train_epochs=1 \\\n",
    "#     --save_every_n_steps=2000 \\\n",
    "#     --unet_lr=4e-5 \\\n",
    "#     --text_encoder_lr=1e-5 \\\n",
    "#     --lr_scheduler=constant_with_warmup \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --network_dim=10000 \\\n",
    "#     --network_alpha=10000 \\\n",
    "#     --output_name=kohaku-xl-delta-lyco \\\n",
    "#     --xformers \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# !accelerate launch \\\n",
    "#     --num_cpu_threads_per_process 1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     sdxl_train_network.py \\\n",
    "#     --pretrained_model_name_or_path=\"sd-models/animagine-xl-3.1.safetensors\" \\\n",
    "#     --vae=\"sd-models/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=1536 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}\" \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=50 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"./logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用单卡进行训练\n",
    "# !python sdxl_train_network.py \\\n",
    "#     --pretrained_model_name_or_path=\"sd-models/animagine-xl-3.1.safetensors\" \\\n",
    "#     --vae=\"sd-models/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/rafa\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=1536 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --output_name=\"rafa_1\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}\" \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=50 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00007 \\\n",
    "#     --unet_lr=0.00007 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"./logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型上传\n",
    "5. [← 上一个单元](#模型训练)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_HF_TO_SAVE_MODEL:\n",
    "    echo(\"使用 HuggingFace 保存模型\")\n",
    "    sd_scripts.repo_manager.push_file_to_huggingface(\n",
    "        hf_access_token = HF_TOKEN, # HuggingFace Token\n",
    "        repo = HF_REPO_ID, # HuggingFace 仓库地址\n",
    "        repo_type = HF_REPO_TYPE, # HuggingFace 仓库种类\n",
    "        work_path = os.path.join(WORKSPACE, \"working\", \"MS_REPO\"), # 脚本工作目录, 仓库将克隆至该文件夹中\n",
    "        upload_path = OUTPUT_PATH # 要上传文件的目录\n",
    "    )\n",
    "\n",
    "if USE_MS_TO_SAVE_MODEL:\n",
    "    echo(\"使用 ModelScope 保存模型\")\n",
    "    sd_scripts.repo_manager.set_git_config(GIT_USER_EMAIL, GIT_USER_NAME)\n",
    "    sd_scripts.repo_manager.push_file_to_modelscope(\n",
    "        ms_access_token = MS_TOKEN, # Modelscope Token\n",
    "        repo = MS_REPO_ID, # Modelscope 的仓库地址\n",
    "        work_path = os.path.join(WORKSPACE, \"working\", \"MS_REPO\"), # 脚本工作目录, 仓库将克隆至该文件夹中\n",
    "        upload_path = OUTPUT_PATH # 要上传文件的目录\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
