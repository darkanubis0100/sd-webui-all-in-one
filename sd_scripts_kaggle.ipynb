{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD Scripts Kaggle\n",
    "Created by [licyk](https://github.com/licyk)\n",
    "\n",
    "Jupyter Notebook 仓库：[licyk/sd-webui-all-in-one](https://github.com/licyk/sd-webui-all-in-one)\n",
    "\n",
    "\n",
    "## 简介\n",
    "一个在 [Kaggle](https://www.kaggle.com) 部署 [sd-scripts](https://github.com/kohya-ss/sd-scripts) 的 Jupyter Notebook，可用于 Stable Diffusion 模型的训练。\n",
    "\n",
    "\n",
    "## 不同运行单元的功能\n",
    "该 Notebook 分为以下几个单元：\n",
    "\n",
    "- [功能初始化](#功能初始化)\n",
    "- [参数配置](#参数配置)\n",
    "- [安装环境](#安装环境)\n",
    "- [模型训练](#模型训练)\n",
    "- [模型上传](#模型上传)\n",
    "\n",
    "使用时请按顺序运行笔记单元。\n",
    "\n",
    "通常情况下[功能初始化](#功能初始化)和[模型上传](#模型上传)单元的内容无需修改，其他单元包含不同功能的注释，可阅读注释获得帮助。\n",
    "\n",
    "[参数配置](#参数配置)单元用于修改安装，训练，上传模型时的配置。\n",
    "\n",
    "[安装](#安装)单元执行安装训练环境的命令和下载模型 / 训练集的命令，可根据需求进行修改。\n",
    "\n",
    "[模型训练](#模型训练)执行训练模型的命令，需要根据自己的需求进行修改，该单元也提供一些训练参数的例子，可在例子的基础上进行修改。\n",
    "\n",
    "如果需要快速取消注释，可以选中代码，按下`Ctrl + /`取消注释。\n",
    "\n",
    "\n",
    "## 提示\n",
    "1. 不同单元中包含注释, 可阅读注释获得帮助。\n",
    "2. 训练代码的部分需要根据自己的需求进行更改。\n",
    "3. 推荐使用 Kaggle 的 `Save Version` 的功能运行笔记，可让 Kaggle 笔记在无人值守下保持运行，直至所有单元运行完成。\n",
    "4. 如果有 [HuggingFace](https://huggingface.co) 账号或者 [ModelScope](https://modelscope.cn) 账号，可通过填写 Token 和仓库名后实现自动上传训练好的模型，仓库需要手动创建。\n",
    "5. 进入 Kaggle 笔记后，在 Kaggle 的右侧栏可以调整 kaggle 笔记的设置，也可以上传训练集等。注意，在 Kaggle 笔记的`Session options`->`ACCELERATOR`中，需要选择`GPU T4 x 2`，才能使用 GPU 进行模型训练。\n",
    "6. 使用 Kaggle 进行模型训练时，训练集中最好没有 NSFW 内容，否则可能会导致 Kaggle 账号被封禁。\n",
    "7. 不同单元的标题下方包含快捷跳转链接，可使用跳转链接翻阅 Notebook。\n",
    "8. 该 Notebook 的使用方法可阅读：</br>[使用 HuggingFace / ModelScope 保存和下载文件 - licyk的小窝](https://licyk.netlify.app/2025/01/16/use-huggingface-or-modelscope-to-save-file/)</br>[使用 Kaggle 进行模型训练 - licyk的小窝](https://licyk.netlify.app/2025/01/16/use-kaggle-to-training-sd-model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 功能初始化\n",
    "通常不需要修改该单元的内容  \n",
    "1. [[下一个单元 →](#参数配置)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化功能, 不需要修改\n",
    "# 建议直接看下一个单元的内容\n",
    "# 如果想要了解该 Notebook 功能的具体代码实现可阅读该部分的代码\n",
    "################################################################\n",
    "import time\n",
    "from typing import Union, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "def echo(*args) -> None:\n",
    "    \"\"\"格式化消息输出\n",
    "    \n",
    "    参数:\n",
    "        *args:\n",
    "            要输出的信息\n",
    "    \"\"\"\n",
    "    t = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "    for i in args:\n",
    "        print(f\"[{t}]:: {i}\")\n",
    "\n",
    "\n",
    "\n",
    "class ARIA2:\n",
    "    \"\"\"基于 Aria2 的文件下载工具\"\"\"\n",
    "\n",
    "    def __init__(self, workspace: Union[str, Path], workfolder: str) -> None:\n",
    "        \"\"\"基于 Aria2 的文件下载工具\n",
    "\n",
    "        参数:\n",
    "            workspace (`str`, `Path`):\n",
    "                工作区路径\n",
    "\n",
    "            workfolder (`str`):\n",
    "                工作区的文件夹名称\n",
    "        \"\"\"\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    def aria2(self, url: str, path: Union[str, Path], filename: str, retry: Optional[int] = 3) -> Union[str, None]:\n",
    "        \"\"\"调用 Aria2 下载文件\n",
    "\n",
    "        参数:\n",
    "            url (`str`):\n",
    "                文件的下载链接\n",
    "\n",
    "            path (`str`, `Path`):\n",
    "                将文件下载到本地的路径\n",
    "\n",
    "            filename (`str`):\n",
    "                将要下载的文件重命名\n",
    "\n",
    "        返回值:\n",
    "            `str`: 文件保存路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        count = 0\n",
    "        file_path = os.path.join(path, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            echo(f\"开始下载 {filename} ，路径: {file_path}\")\n",
    "            while count < retry:\n",
    "                count += 1\n",
    "                !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{url}\" -d \"{path}\" -o \"{filename}\"\n",
    "                if os.path.exists(file_path) and not os.path.exists(file_path + \".aria2\"):\n",
    "                    echo(f\"{filename} 下载完成\")\n",
    "                    return file_path\n",
    "                else:\n",
    "                    echo(f\"{filename} 下载中断\")\n",
    "                    if count < retry:\n",
    "                        echo(f\"重试下载 {filename} 中\")\n",
    "                    else:\n",
    "                        return None\n",
    "        else:\n",
    "            if os.path.exists(file_path + \".aria2\"):\n",
    "                echo(f\"开始下载 {filename} ，路径: {path}/{filename}\")\n",
    "                while count < retry:\n",
    "                    count += 1\n",
    "                    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{url}\" -d \"{path}\" -o \"{filename}\"\n",
    "                    if os.path.exists(file_path) and not os.path.exists(file_path + \".aria2\"):\n",
    "                        echo(f\"{filename} 下载完成\")\n",
    "                        return file_path\n",
    "                    else:\n",
    "                        echo(f\"{filename} 下载中断\")\n",
    "                        if count < retry:\n",
    "                            echo(f\"重试下载 {filename} 中\")\n",
    "                        else:\n",
    "                            return None\n",
    "            else:\n",
    "                echo(f\"{filename} 文件已存在，路径: {file_path}\")\n",
    "                return file_path\n",
    "\n",
    "\n",
    "\n",
    "class GIT:\n",
    "    \"\"\"基于 Git 命令的模块\"\"\"\n",
    "\n",
    "    def __init__(self, workspace: Union[str, Path], workfolder: str) -> None:\n",
    "        \"\"\"基于 Git 命令的模块\n",
    "\n",
    "        参数:\n",
    "            workspace (`str`, `Path`):\n",
    "                工作区路径\n",
    "\n",
    "            workfolder (`str`):\n",
    "                工作区的文件夹名称\n",
    "        \"\"\"\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    def exists(self, addr: Optional[str]= None, path: Optional[Union[str, Path]]= None, name: Optional[str]= None) -> bool:\n",
    "        \"\"\"检测要克隆的项目是否存在于指定路径\n",
    "\n",
    "        参数:\n",
    "            addr (`str`, `None`):\n",
    "                Git 仓库的地址\n",
    "\n",
    "            path (`str`, `Path`, `None`):\n",
    "                将 Git 仓库下载到本地的路径\n",
    "\n",
    "            name (`str`, `None`):\n",
    "                将 Git 仓库进行重命名\n",
    "\n",
    "        返回值:\n",
    "            `bool`: Git 仓库存在时则返回`True`, 否则返回`False`\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if addr is not None:\n",
    "            if path is None and name is None:\n",
    "                path = os.path.join(os.getcwd(), addr.split(\"/\").pop().split(\".git\", 1)[0])\n",
    "            elif path is None and name is not None:\n",
    "                path = os.path.join(os.getcwd(), name)\n",
    "            elif path is not None and name is None:\n",
    "                path = os.path.join(os.path.normpath(path), addr.split(\"/\").pop().split(\".git\", 1)[0])\n",
    "            elif path is not None and name is not None:\n",
    "                path = os.path.join(os.path.normpath(path), name)\n",
    "\n",
    "        if os.path.exists(path):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def clone(self, addr: str, path: Optional[Union[str, Path]]= None, name: Optional[str]= None, retry: Optional[int] = 3) -> Union[str, None]:\n",
    "        \"\"\"克隆 Git 仓库到本地\n",
    "\n",
    "        参数:\n",
    "            addr (`str`):\n",
    "                Git 仓库的地址\n",
    "\n",
    "            path (`str`, `Path`, `None`):\n",
    "                将 Git 仓库下载到本地的路径\n",
    "\n",
    "            name (`str`, `None`):\n",
    "                将 Git 仓库进行重命名\n",
    "\n",
    "            retry (`int`):\n",
    "                重试下载的次数, 默认为 3\n",
    "\n",
    "        返回值:\n",
    "            `str`: 下载的仓库地址\n",
    "        \"\"\"\n",
    "        import os\n",
    "        count = 0\n",
    "        repo = addr.split(\"/\").pop().split(\".git\", 1)[0]\n",
    "        if path is None and name is None:\n",
    "            path = os.getcwd()\n",
    "            name = repo\n",
    "        elif path is not None and name is None:\n",
    "            name = repo\n",
    "        elif path is None and name is not None:\n",
    "            path = os.getcwd()\n",
    "\n",
    "        repo_path = os.path.join(path, name)\n",
    "\n",
    "        if not self.exists(addr, path, name):\n",
    "            echo(f\"开始下载 {repo}\")\n",
    "            while count < retry:\n",
    "                count += 1\n",
    "                !git clone {addr} \"{repo_path}\" --recurse-submodules\n",
    "                if os.path.exists(repo_path):\n",
    "                    echo(f\"{repo} 下载成功, 路径: {repo_path}\")\n",
    "                    return repo_path\n",
    "                else:\n",
    "                    echo(f\"{repo} 下载失败\")\n",
    "                    if count < retry:\n",
    "                        echo(f\"重试下载 {repo} 中\")\n",
    "                    else:\n",
    "                        return None\n",
    "        else:\n",
    "            echo(f\"{repo} 已存在, 路径: {repo_path}\")\n",
    "            echo(f\"更新 {repo} 中\")\n",
    "            !git -C \"{repo_path}\" pull --recurse-submodules\n",
    "            return repo_path\n",
    "\n",
    "\n",
    "    def checkout(self, path: Union[str, Path], branch: str) -> None:\n",
    "        \"\"\"切换 Git 仓库到指定分支\n",
    "\n",
    "        参数:\n",
    "            path (`str`, `Path`):\n",
    "                Git 仓库的路径\n",
    "\n",
    "            branch (`str`):\n",
    "                指定要切换 Git 仓库分支\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if os.path.exists(os.path.join(path, \".git\")) and branch:\n",
    "            echo(f\"切换 {os.path.basename(path)} 的分支至 {branch}\")\n",
    "            !git -C \"{path}\" checkout \"{branch}\" --recurse-submodules\n",
    "\n",
    "\n",
    "    def reset(self, path: Union[str, Path], commit: str) -> None:\n",
    "        \"\"\"切换到指定的 Git 提交记录上\n",
    "\n",
    "        参数:\n",
    "            path (`str`, `Path`):\n",
    "                Git 仓库的路径\n",
    "\n",
    "            commmit (`str`):\n",
    "                指定要切换 Git 仓库的提交哈希值\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if os.path.exists(os.path.join(path, \".git\")) and commit:\n",
    "            echo(f\"切换 {os.path.basename(path)} 的分支至 {commit}\")\n",
    "            !git -C \"{path}\" reset \"{commit}\" --hard --recurse-submodules\n",
    "\n",
    "\n",
    "\n",
    "class ENV:\n",
    "    \"\"\"提供初始化环境的功能\"\"\"\n",
    "\n",
    "    def __init__(self, workspace: Union[str, Path], workfolder: str) -> None:\n",
    "        \"\"\"提供初始化环境的功能\n",
    "\n",
    "        参数:\n",
    "            workspace (`str`, `Path`):\n",
    "                工作区路径\n",
    "\n",
    "            workfolder (`str`):\n",
    "                工作区的文件夹名称\n",
    "        \"\"\"\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    def prepare_env_depend(self, use_uv: bool = False) -> None:\n",
    "        \"\"\"为 Notebook 的功能准备必须的环境依赖\n",
    "\n",
    "        参数:\n",
    "            use_uv (`bool`):\n",
    "                是否使用 uv 代替 Pip 安装 Python 软件包\n",
    "        \"\"\"\n",
    "        echo(\"安装自身组件依赖\")\n",
    "        !pip install uv -U\n",
    "        pkg = \"huggingface_hub modelscope\"\n",
    "        if use_uv:\n",
    "            !uv pip install {pkg} -U || pip install {pkg} -U\n",
    "        else:\n",
    "            !pip install {pkg} -U\n",
    "        !apt update\n",
    "        !apt install aria2 google-perftools p7zip-full unzip tree -y\n",
    "\n",
    "\n",
    "    def prepare_torch(self, torch_ver: Optional[str] = None, xformers_ver: Optional[str] = None, use_uv: bool = False) -> None:\n",
    "        \"\"\"安装 PyTorch 和 xFormers\n",
    "\n",
    "        参数:\n",
    "            torch_ver (`str`, `None`):\n",
    "                PyTorch 软件包名称和版本信息, 如`torch==2.0.0 torchvision==0.15.1`\n",
    "\n",
    "            xformers_ver (`str`, `None`):\n",
    "                xFormers 软件包名称和版本信息, 如`xformers==0.0.18`\n",
    "\n",
    "            use_uv (`bool`):\n",
    "                使用 uv 代替 Pip 进行 Python 软件包安装\n",
    "        \"\"\"\n",
    "        if use_uv:\n",
    "            if torch_ver:\n",
    "                echo(\"安装 PyTorch\")\n",
    "                !uv pip install {torch_ver} || pip install {torch_ver}\n",
    "            else:\n",
    "                echo(\"未指定 PyTorch 包名, 跳过安装\")\n",
    "\n",
    "            if xformers_ver:\n",
    "                echo(\"安装 xFormers\")\n",
    "                !uv pip install {xformers_ver} --no-deps  || pip install {xformers_ver} --no-deps\n",
    "            else:\n",
    "                echo(\"未指定 xFormers 包名, 跳过安装\")\n",
    "        else:\n",
    "            if torch_ver:\n",
    "                echo(\"安装 PyTorch\")\n",
    "                !pip install {torch_ver}\n",
    "            else:\n",
    "                echo(\"未指定 PyTorch 包名, 跳过安装\")\n",
    "\n",
    "            if xformers_ver:\n",
    "                echo(\"安装 xFormers\")\n",
    "                !pip install {xformers_ver} --no-deps\n",
    "            else:\n",
    "                echo(\"未指定 xFormers 包名, 跳过安装\")\n",
    "\n",
    "\n",
    "    def install_requirements(self, path: Union[str, Path], use_uv: bool = False) -> None:\n",
    "        \"\"\"从文件 (requirements.txt) 中安装 Python 软件包\n",
    "\n",
    "        参数:\n",
    "            path (`str`, `Path`):\n",
    "                依赖记录文件的路径\n",
    "\n",
    "            use_uv (`bool`):\n",
    "                使用 uv 代替 Pip 进行 Python 软件包安装\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if os.path.exists(path):\n",
    "            echo(\"安装依赖\")\n",
    "            if use_uv:\n",
    "                !uv pip install -r \"{path}\" || pip install -r \"{path}\"\n",
    "            else:\n",
    "                !pip install -r \"{path}\"\n",
    "        else:\n",
    "            echo(\"依赖文件路径为空\")\n",
    "\n",
    "\n",
    "    def py_pkg_manager(self, pkg: str, type: Optional[str] = None, use_uv: bool = False) -> None:\n",
    "        \"\"\"使用 Pip / uv 执行对 Python 软件包的操作\n",
    "\n",
    "        参数:\n",
    "            pkg (`str`):\n",
    "                指定 Python 软件包名\n",
    "\n",
    "            type (`str`, `None`):\n",
    "                指定对 Python 软件包的操作\n",
    "\n",
    "                可选的操作: (install / install_single / force_install / force_install_single / update / uninstall)\n",
    "\n",
    "            use_uv (bool):\n",
    "                使用 uv 代替 Pip 进行 Python 软件包安装\n",
    "\n",
    "        type 支持的操作和对应的命令行参数如下:\n",
    "            安装: install -> install\n",
    "\n",
    "            仅安装: install_single -> install --no-deps\n",
    "\n",
    "            强制重装: force_install -> install --force-reinstall\n",
    "\n",
    "            仅强制重装: force_install_single -> install --force-reinstall --no-deps\n",
    "\n",
    "            更新: update -> install --upgrade\n",
    "\n",
    "            卸载: uninstall -> uninstall -y\n",
    "        \"\"\"\n",
    "\n",
    "        if type == \"install\":\n",
    "            func = \"install\"\n",
    "            args = \"\"\n",
    "        elif type == \"install_single\":\n",
    "            func = \"install\"\n",
    "            args = \"--no-deps\"\n",
    "        elif type == \"force_install\":\n",
    "            func = \"install\"\n",
    "            args = \"--force-reinstall\"\n",
    "        elif type == \"force_install_single\":\n",
    "            func = \"install\"\n",
    "            args = \"install --force-reinstall --no-deps\"\n",
    "        elif type == \"update\":\n",
    "            func = \"install\"\n",
    "            args = \"--upgrade\"\n",
    "        elif type == \"uninstall\":\n",
    "            func = \"uninstall\"\n",
    "            args = \"-y\"\n",
    "        else:\n",
    "            echo(f\"未知操作: {type}\")\n",
    "            return\n",
    "\n",
    "        if use_uv:\n",
    "            echo(f\"执行操作: uv pip {func} {pkg} {args}\")\n",
    "            !uv pip {func} {pkg} {args}\n",
    "        else:\n",
    "            echo(f\"执行操作: pip {func} {pkg} {args}\")\n",
    "            !pip {func} {pkg} {args}\n",
    "\n",
    "\n",
    "    def tcmalloc(self) -> None:\n",
    "        \"\"\"使用 TCMalloc 优化内存的占用, 通过 LD_PRELOAD 环境变量指定 TCMalloc\"\"\"\n",
    "        echo(\"配置内存优化\")\n",
    "        import os\n",
    "        os.environ[\"LD_PRELOAD\"] = \"/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4\"\n",
    "\n",
    "\n",
    "\n",
    "class MANAGER:\n",
    "    \"\"\"环境管理\"\"\"\n",
    "\n",
    "    def __init__(self, workspace: Union[str, Path], workfolder: Union[str, Path]) -> None:\n",
    "        \"\"\"环境管理\n",
    "\n",
    "        参数:\n",
    "            workspace (`str`, `Path`):\n",
    "                工作区路径\n",
    "\n",
    "            workfolder (`str`):\n",
    "                工作区的文件夹名称\n",
    "        \"\"\"\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    def clear_up(self) -> None:\n",
    "        \"\"\"清理 Notebook 的内容输出\"\"\"\n",
    "        from IPython.display import clear_output\n",
    "        clear_output(wait=False)\n",
    "\n",
    "\n",
    "    def check_gpu(self) -> None:\n",
    "        \"\"\"检查环境中是否有可用的 GPU\"\"\"\n",
    "        echo(\"检测 GPU 是否可用\")\n",
    "        import tensorflow as tf\n",
    "        echo(f\"TensorFlow 版本: {tf.__version__}\")\n",
    "        if tf.test.gpu_device_name():\n",
    "            echo(\"GPU 可用\")\n",
    "        else:\n",
    "            echo(\"GPU 不可用\")\n",
    "            raise Exception(\"\\n没有可用的 GPU, 请在 kaggle -> Notebook -> Session options -> ACCELERATOR 选择 GPU T4 x 2\\n如果不能使用 GPU, 请检查 Kaggle 账号是否绑定了手机号或者尝试更换账号!\")\n",
    "\n",
    "\n",
    "\n",
    "class REPO_MANAGER:\n",
    "    \"\"\"基于 HuggingFace / ModelScope 的仓库管理工具\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "    def get_all_file(self, directory: Union[str, Path]) -> list:\n",
    "        \"\"\"获取文件夹中所有文件的绝对路径\n",
    "\n",
    "        参数:\n",
    "            directory (`str`, `Path`):\n",
    "                文件夹的路径\n",
    "\n",
    "        返回值:\n",
    "            `list`: 所有文件的绝对路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        file_list = []\n",
    "        for dirname, _, filenames in os.walk(directory):\n",
    "            for filename in filenames:\n",
    "                file_list.append(os.path.join(dirname, filename))\n",
    "        return file_list\n",
    "\n",
    "\n",
    "    def is_file_exists_in_ms_repo(self, upload_file: Union[str, Path], work_path: Union[str, Path], repo_id: str) -> bool:\n",
    "        \"\"\"检测指定文件是否存在于 ModelScope 仓库中\n",
    "\n",
    "        参数:\n",
    "            upload_file (`str`, `Path`):\n",
    "                文件在仓库中对应的路径\n",
    "\n",
    "            work_path (`str`, `Path`):\n",
    "                仓库在本地的父路径\n",
    "\n",
    "            repo_id (`str`):\n",
    "                ModelScope 仓库的 ID\n",
    "\n",
    "        返回值:\n",
    "            `bool`: 当文件存在时返回`True`, 否则为`False`\n",
    "        \"\"\"\n",
    "        import os\n",
    "\n",
    "        repo_file = os.path.join(work_path, repo_id.split(\"/\").pop(), upload_file)\n",
    "        if os.path.exists(repo_file):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def clone_modelscope_without_lfs(self, ms_access_token: str, repo_id: str, repo_type: str, work_path: Union[str, Path]) -> None:\n",
    "        \"\"\"将 ModelScope 仓库下载到本地中, 并且不包含 Git LFS 文件\n",
    "\n",
    "        参数:\n",
    "            ms_access_token (`str`):\n",
    "                ModelScope 账号的 Git Token\n",
    "\n",
    "            repo_id (`str`):\n",
    "                ModelScope 仓库 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                ModelScope 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 创空间仓库\n",
    "\n",
    "            work_path (`str`, `Path`):\n",
    "                将仓库下载到本地的路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "\n",
    "        # 禁用 Git LFS\n",
    "        os.environ[\"GIT_LFS_SKIP_SMUDGE\"] = \"1\"\n",
    "        !git lfs uninstall\n",
    "\n",
    "        # 本地存在仓库时进行删除\n",
    "        repo_name = repo_id.split(\"/\").pop()\n",
    "        path = os.path.join(work_path, repo_name)\n",
    "        if os.path.exists(path):\n",
    "            !rm -rf \"{path}\"\n",
    "\n",
    "        # 下载仓库并启用 Git LFS\n",
    "        if repo_type == \"model\":\n",
    "            repo_url = f\"https://oauth2:{ms_access_token}@www.modelscope.cn/{repo_id}.git\"\n",
    "        elif repo_type == \"dataset\":\n",
    "            repo_url = f\"https://oauth2:{ms_access_token}@www.modelscope.cn/datasets/{repo_id}.git\"\n",
    "        elif repo_type == \"space\":\n",
    "            repo_url = f\"https://oauth2:{ms_access_token}@www.modelscope.cn/studios/{repo_id}.git\"\n",
    "\n",
    "        !git clone \"{repo_url}\" \"{path}\"\n",
    "\n",
    "        # 启用 Git LFS\n",
    "        os.environ[\"GIT_LFS_SKIP_SMUDGE\"] = \"0\"\n",
    "        !git -C \"{path}\" lfs install\n",
    "\n",
    "\n",
    "    def push_file_to_modelscope_legacy(\n",
    "        self,\n",
    "        ms_access_token: str,\n",
    "        repo_id: str,\n",
    "        repo_type: str,\n",
    "        visibility: bool,\n",
    "        work_path: Union[str, Path],\n",
    "        upload_path: Union[str, Path]\n",
    "    ) -> None:\n",
    "        \"\"\"将指定路径中的文件上传到 ModelScope 中, 基于 Git 实现\n",
    "\n",
    "        参数:\n",
    "            ms_access_token (`str`):\n",
    "                ModelScope 账号的 Token\n",
    "\n",
    "            repo_id (`str`):\n",
    "                ModelScope 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                ModelScope 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 创空间仓库\n",
    "\n",
    "            work_path (`str`, `Path`):\n",
    "                将仓库下载到本地的路径\n",
    "\n",
    "            upload_path (`str`, `Path`):\n",
    "                要上传文件到 ModelScope 仓库的路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import string\n",
    "        import random\n",
    "        from modelscope.hub.api import HubApi\n",
    "        api = HubApi()\n",
    "\n",
    "        echo(\"验证 ModelScope Token 中\")\n",
    "        try:\n",
    "            ms_access_token = api.login(ms_access_token)[0] # 将 ModelScope Token 转为 ModelScope Git Token\n",
    "            echo(\"ModelScope Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"ModelScope Token 验证失败, 无法上传文件\", e)\n",
    "            return\n",
    "\n",
    "        repo_name = repo_id.split(\"/\").pop() # 仓库名称\n",
    "        tmp_random_name = ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(8)) # 随机名称\n",
    "        tmp_work_path = os.path.join(work_path, f\"__ms_repo_{repo_name}_{tmp_random_name}__\") # 临时的工作路径\n",
    "        repo_local_path = os.path.join(tmp_work_path, repo_name) # 仓库对应的本地绝对路径\n",
    "        upload_file_lists = self.get_all_file(upload_path) # 原文件的绝对路径列表\n",
    "        # 统计信息\n",
    "        count = 0\n",
    "        sum = len(upload_file_lists)\n",
    "\n",
    "        # 检查 ModelScope 仓库\n",
    "        if not self.check_ms_repo(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type,\n",
    "            visibility=visibility,\n",
    "            token=ms_access_token\n",
    "        ):\n",
    "            echo(f\"{repo_id} (类型: {repo_type}) 不存在, 无法上传文件\")\n",
    "            return\n",
    "\n",
    "        echo(f\"将文件上传至 ModelScope: {upload_path} -> {repo_local_path}\")\n",
    "        echo(f\"使用的 ModelScope 仓库: {repo_id}, 类型: {repo_type}\")\n",
    "\n",
    "        for upload_file in upload_file_lists:\n",
    "            count += 1\n",
    "            rel_upload_file = os.path.relpath(upload_file, upload_path) # 原文件相对路径\n",
    "            upload_file_name = os.path.basename(upload_file)\n",
    "            # Git 仓库的配置信息\n",
    "            if repo_type == \"model\":\n",
    "                git_repo_config = f\"lfs.https://oauth2:{ms_access_token}@www.modelscope.cn/{repo_id}.git/info/lfs.locksverify\"\n",
    "            elif repo_type == \"dataset\":\n",
    "                git_repo_config = f\"lfs.https://oauth2:{ms_access_token}@www.modelscope.cn/datasets/{repo_id}.git/info/lfs.locksverify\"\n",
    "            elif repo_type == \"space\":\n",
    "                git_repo_config = f\"lfs.https://oauth2:{ms_access_token}@www.modelscope.cn/studios/{repo_id}.git/info/lfs.locksverify\"\n",
    "\n",
    "            # 下载仓库到本地\n",
    "            echo(f\"[{count}/{sum}] 克隆仓库到 {tmp_work_path}\")\n",
    "            self.clone_modelscope_without_lfs(\n",
    "                ms_access_token=ms_access_token,\n",
    "                repo_id=repo_id,\n",
    "                repo_type=repo_type,\n",
    "                work_path=tmp_work_path\n",
    "            )\n",
    "\n",
    "            echo(f\"[{count}/{sum}] 要上传的文件的相对路径: {rel_upload_file}\")\n",
    "            echo(f\"[{count}/{sum}] 要上传的文件的绝对路径: {upload_file}\")\n",
    "            echo(f\"[{count}/{sum}] 仓库本地绝对路径: {repo_local_path}\")\n",
    "\n",
    "            # 检测文件是否存在于仓库中\n",
    "            if self.is_file_exists_in_ms_repo(\n",
    "                upload_file=rel_upload_file,\n",
    "                work_path=tmp_work_path,\n",
    "                repo_id=repo_id\n",
    "            ):\n",
    "                !rm -rf \"{repo_local_path}\"\n",
    "                echo(f\"[{count}/{sum}] {upload_file_name} 已存在于仓库中\")\n",
    "                continue\n",
    "\n",
    "            # 为仓库创建文件对应的父文件夹\n",
    "            p_path = os.path.dirname(os.path.join(tmp_work_path, repo_name, rel_upload_file)) # 原文件到仓库中后对应的父文件夹\n",
    "            if not os.path.exists(p_path):\n",
    "                echo(f\"[{count}/{sum}] 为 {upload_file_name} 创建对应的父文件夹: {p_path}\")\n",
    "                os.makedirs(p_path, exist_ok=True)\n",
    "\n",
    "            # 复制文件到仓库中\n",
    "            echo(f\"[{count}/{sum}] {upload_file} -> {repo_local_path}/{rel_upload_file}\")\n",
    "            !cp -f \"{upload_file}\" \"{p_path}\"\n",
    "\n",
    "            # 对文件进行追踪\n",
    "            file_name = os.path.basename(rel_upload_file) # 文件名\n",
    "            echo(f\"[{count}/{sum}] 添加文件： {rel_upload_file}\")\n",
    "            !git -C \"{repo_local_path}\" add \"{rel_upload_file}\"\n",
    "\n",
    "            # 创建提交信息\n",
    "            echo(f\"[{count}/{sum}] 提交信息: \\\"Upload {file_name}\\\"\")\n",
    "            !git -C \"{repo_local_path}\" commit -m \"Upload {file_name}\"\n",
    "            !git -C \"{repo_local_path}\" config \"{git_repo_config}\" true\n",
    "\n",
    "            # 推送文件到 ModelScope\n",
    "            echo(f\"[{count}/{sum}] 上传 {file_name} 到 {repo_id} 中\")\n",
    "            !git -C \"{repo_local_path}\" push\n",
    "\n",
    "            # 清理仓库文件\n",
    "            !rm -rf \"{repo_local_path}\"\n",
    "            echo(f\"[{count}/{sum}] 上传 {file_name} 完成\")\n",
    "\n",
    "        # 清理临时工作路径\n",
    "        !rm -rf \"{tmp_work_path}\"\n",
    "        echo(f\"{repo_id} 仓库上传完成\")\n",
    "\n",
    "\n",
    "    def check_ms_repo(self, repo_id: str, repo_type: str, visibility: bool, token: str) -> bool:\n",
    "        \"\"\"检查 ModelScope 仓库是否存在并创建\n",
    "\n",
    "        参数:\n",
    "            repo_id (`str`):\n",
    "                ModelScope 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                ModelScope 仓库类型 (model / dataset/ space)\n",
    "\n",
    "            visibility (`bool`):\n",
    "                在创建 ModelScope 仓库时设置仓库的可见性, `True`则设置仓库为公开仓库, `False`则设置仓库为私有仓库\n",
    "\n",
    "            token (`str`):\n",
    "                ModelScope 账号 Token\n",
    "\n",
    "        返回值:\n",
    "            `bool`: 当仓库存在时 / 仓库不存在但尝试创建成功返回`True`, 否则返回`False`\n",
    "        \"\"\"\n",
    "        from modelscope.hub.api import (\n",
    "            HubApi,\n",
    "            ModelVisibility,\n",
    "            DatasetVisibility,\n",
    "            REPO_TYPE_MODEL,\n",
    "            REPO_TYPE_DATASET,\n",
    "            DEFAULT_DATASET_REVISION,\n",
    "        )\n",
    "        api = HubApi()\n",
    "        repo_exists = False\n",
    "        repo_type_init = None\n",
    "        repo_visibility = None\n",
    "\n",
    "        # 检查仓库是否存在\n",
    "        echo(f\"检查 {repo_id} 仓库是否存在, 类型: {repo_type}\")\n",
    "        if repo_type == \"model\":\n",
    "            try:\n",
    "                api.get_model(repo_id)\n",
    "                repo_exists = True\n",
    "            except:\n",
    "                repo_type_init = REPO_TYPE_MODEL\n",
    "                # repo_visibility = ModelVisibility.PUBLIC if visibility else ModelVisibility.PRIVATE\n",
    "                repo_visibility = \"public\" if visibility else \"private\"\n",
    "        elif repo_type == \"dataset\":\n",
    "            try:\n",
    "                api.get_dataset_infos(\n",
    "                    dataset_hub_id=repo_id,\n",
    "                    revision=DEFAULT_DATASET_REVISION\n",
    "                )\n",
    "                # dataset_namespace = repo_id.split(\"/\")[0]\n",
    "                # api.get_dataset_id_and_type(\n",
    "                #     dataset_name=repo_id,\n",
    "                #     namespace=dataset_namespace\n",
    "                # )\n",
    "                repo_exists = True\n",
    "            except:\n",
    "                repo_type_init = REPO_TYPE_DATASET\n",
    "                # repo_visibility = DatasetVisibility.PUBLIC if visibility else DatasetVisibility.PRIVATE\n",
    "                repo_visibility = \"public\" if visibility else \"private\"\n",
    "        elif repo_type == \"space\":\n",
    "            # TODO: 支持 ModelScope 创空间\n",
    "            repo_exists = True\n",
    "            repo_type_init = \"studio\"\n",
    "            repo_visibility = 5\n",
    "\n",
    "        # 创建仓库\n",
    "        if not repo_exists:\n",
    "            echo(f\"{repo_id} 不存在, 尝试创建中, 类型: {repo_type}, 可见性: {'公开' if visibility else '私有'}\")\n",
    "            try:\n",
    "                api.create_repo(\n",
    "                    repo_id=repo_id,\n",
    "                    repo_type=repo_type_init,\n",
    "                    visibility=repo_visibility,\n",
    "                    token=token\n",
    "                )\n",
    "                echo(f\"{repo_id} 创建成功\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                echo(f\"{repo_id} 创建失败\", e)\n",
    "                return False\n",
    "        else:\n",
    "            echo(f\"{repo_id} 已存在, 类型: {repo_type}\")\n",
    "            return True\n",
    "\n",
    "\n",
    "    def push_file_to_modelscope(\n",
    "        self,\n",
    "        ms_access_token: str,\n",
    "        repo_id: str,\n",
    "        repo_type: str,\n",
    "        visibility: bool,\n",
    "        upload_path: Union[str, Path]\n",
    "    ) -> None:\n",
    "        \"\"\"上传文件到 ModelScope 中\n",
    "\n",
    "        参数:\n",
    "            ms_access_token (`str`):\n",
    "                ModelScope 账号 Token\n",
    "\n",
    "            repo_id (`str`):\n",
    "                ModelScope 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                ModelScope 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            upload_path (`str`, `Path`):\n",
    "                要上传到 ModelScope 仓库的文件本地路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        from pathlib import Path\n",
    "        from modelscope.hub.api import HubApi\n",
    "        api = HubApi()\n",
    "\n",
    "        echo(\"验证 ModelScope Token 中\")\n",
    "        try:\n",
    "            api.login(ms_access_token) # 将 ModelScope Token 转为 ModelScope Git Token\n",
    "            echo(\"ModelScope Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"ModelScope Token 验证失败, 无法上传文件\", e)\n",
    "            return\n",
    "\n",
    "        upload_file_lists = self.get_all_file(upload_path) # 原文件的路径列表\n",
    "        \n",
    "        # 统计信息\n",
    "        count = 0\n",
    "        sum = len(upload_file_lists)\n",
    "\n",
    "        # 检查 ModelScope 仓库\n",
    "        if not self.check_ms_repo(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type,\n",
    "            visibility=visibility,\n",
    "            token=ms_access_token\n",
    "        ):\n",
    "            echo(f\"{repo_id} (类型: {repo_type}) 不存在, 无法上传文件\")\n",
    "            return\n",
    "\n",
    "        echo(f\"将文件上传至 ModelScope: {upload_path} -> {repo_id}\")\n",
    "        echo(f\"使用的 ModelScope 仓库: {repo_id}, 类型: {repo_type}\")\n",
    "\n",
    "        ms_repo_file_list = self.get_ms_repo_file_list(ms_access_token, repo_id, repo_type) # 获取仓库中的文件列表\n",
    "\n",
    "        for upload_file in upload_file_lists:\n",
    "            count += 1\n",
    "            rel_upload_file = os.path.relpath(upload_file, upload_path) # 原文件相对路径\n",
    "            file_name = os.path.basename(upload_file) # 文件名\n",
    "            hf_path_in_repo = Path(rel_upload_file).as_posix() # 文件在仓库中的路径\n",
    "            local_file_obj = Path(upload_file).as_posix() # 文件在本地的绝对路径\n",
    "\n",
    "            echo(f\"[{count}/{sum}] 要上传的文件的相对路径: {rel_upload_file}\")\n",
    "            echo(f\"[{count}/{sum}] 绝对路径: {upload_file}\")\n",
    "\n",
    "            if rel_upload_file in ms_repo_file_list:\n",
    "                echo(f\"[{count}/{sum}] {file_name} 已存在于仓库中\")\n",
    "                continue\n",
    "\n",
    "            # 上传文件到 ModelScope\n",
    "            echo(f\"[{count}/{sum}] {local_file_obj} -> {repo_id}/{hf_path_in_repo}\")\n",
    "            echo(f\"[{count}/{sum}] 上传 {file_name} 到 {repo_id} 中\")\n",
    "            try:\n",
    "                api.upload_file(\n",
    "                    repo_id=repo_id,\n",
    "                    repo_type=repo_type,\n",
    "                    path_in_repo=hf_path_in_repo,\n",
    "                    path_or_fileobj=local_file_obj,\n",
    "                    commit_message=f\"Upload {file_name}\",\n",
    "                    token=ms_access_token\n",
    "                )\n",
    "                echo(f\"[{count}/{sum}] 上传 {file_name} 完成\")\n",
    "            except Exception as e:\n",
    "                echo(f\"[{count}/{sum}] 上传 {file_name} 失败\", e)\n",
    "\n",
    "        echo(f\"{repo_id} 仓库上传完成\")\n",
    "\n",
    "\n",
    "    def get_hf_repo_file_list(self, hf_access_token: str, repo_id: str, repo_type: str) -> list:\n",
    "        \"\"\"从 HuggingFace 获取仓库中所有文件路径\n",
    "\n",
    "        参数:\n",
    "            hf_access_token (`str`):\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "            repo_id (`str`):\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "        返回值:\n",
    "            `list`: 所有文件在 HuggingFace 仓库中的路径\n",
    "        \"\"\"\n",
    "        from huggingface_hub import HfApi\n",
    "        api = HfApi()\n",
    "        try:\n",
    "            model_list = api.list_repo_files(\n",
    "                repo_id=repo_id,\n",
    "                repo_type=repo_type,\n",
    "                token=hf_access_token\n",
    "            )\n",
    "        except:\n",
    "            model_list = []\n",
    "\n",
    "        return model_list\n",
    "\n",
    "\n",
    "    def get_ms_repo_file_list(self, ms_access_token: str, repo_id: str, repo_type: str) -> list:\n",
    "        \"\"\"从 ModelScope 获取仓库中所有文件路径\n",
    "\n",
    "        参数:\n",
    "            ms_access_token (`str`):\n",
    "                ModelScope 账号 Token\n",
    "\n",
    "            repo_id (`str`):\n",
    "                ModelScope 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                ModelScope 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "        返回值:\n",
    "            `list`: 所有文件在 ModelScope 仓库中的路径\n",
    "        \"\"\"\n",
    "        from modelscope.hub.api import HubApi, DEFAULT_DATASET_REVISION\n",
    "        from modelscope.hub.snapshot_download import fetch_repo_files\n",
    "        api = HubApi()\n",
    "        file_list = []\n",
    "\n",
    "\n",
    "        def _get_file_path(repo_files: list) -> list:\n",
    "            \"\"\"获取 ModelScope Api 返回的仓库列表中的模型路径\"\"\"\n",
    "            file_list = []\n",
    "            for file in repo_files:\n",
    "                    if file['Type'] != 'tree':\n",
    "                        file_list.append(file[\"Path\"])\n",
    "            return file_list\n",
    "\n",
    "\n",
    "        try:\n",
    "            api.login(ms_access_token)\n",
    "        except Exception as e:\n",
    "            echo(\"ModelScope Token 验证失败, 无法获取文件列表\", e)\n",
    "            return file_list\n",
    "\n",
    "        if repo_type == \"model\":\n",
    "            try:\n",
    "                repo_files = api.get_model_files(\n",
    "                    model_id=repo_id,\n",
    "                    recursive=True\n",
    "                )\n",
    "                file_list = _get_file_path(repo_files)\n",
    "            except Exception as e:\n",
    "                echo(f\"获取 {repo_id} (类型: {repo_type}) 仓库的文件列表出现错误\", e)\n",
    "        elif repo_type == \"dataset\":\n",
    "            user = repo_id.split(\"/\")[0]\n",
    "            name = repo_id.split(\"/\")[1]\n",
    "            try:\n",
    "                repo_files = fetch_repo_files(\n",
    "                    _api=api,\n",
    "                    group_or_owner=user,\n",
    "                    name=name,\n",
    "                    revision=DEFAULT_DATASET_REVISION\n",
    "                )\n",
    "                file_list = _get_file_path(repo_files)\n",
    "            except Exception as e:\n",
    "                echo(f\"获取 {repo_id} (类型: {repo_type}) 仓库的文件列表出现错误\", e)\n",
    "        elif repo_type == \"space\":\n",
    "            # TODO: 支持创空间\n",
    "            echo(f\"{repo_id} 仓库类型为创空间, 不支持获取文件列表\")\n",
    "        else:\n",
    "            echo(f\"未知的 {repo_type} 仓库类型\")\n",
    "\n",
    "        return file_list\n",
    "\n",
    "\n",
    "    def check_hf_repo(self, repo_id: str, repo_type: str, visibility: bool, token: str) -> bool:\n",
    "        \"\"\"检查 HuggingFace 仓库是否存在并创建\n",
    "\n",
    "        参数:\n",
    "            repo_id (`str`):\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                HuggingFace 仓库类型 (model / dataset/ space)\n",
    "\n",
    "            visibility (`bool`):\n",
    "                在创建 HuggingFace 仓库时设置仓库的可见性, `True`则设置仓库为公开仓库, `False`则设置仓库为私有仓库\n",
    "\n",
    "            token (`str`):\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "        返回值:\n",
    "            `bool`: 当仓库存在时 / 仓库不存在但尝试创建成功返回`True`, 否则返回`False`\n",
    "        \"\"\"\n",
    "        from huggingface_hub import repo_exists, create_repo\n",
    "\n",
    "        # 检查仓库是否存在\n",
    "        echo(f\"检查 {repo_id} 仓库是否存在, 类型: {repo_type}\")\n",
    "        if repo_exists(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type,\n",
    "            token=token\n",
    "        ):\n",
    "            echo(f\"{repo_id} 已存在, 类型: {repo_type}\")\n",
    "            return True\n",
    "        else:\n",
    "            echo(f\"{repo_id} 不存在, 尝试创建中, 类型: {repo_type}, 可见性: {'公开' if visibility else '私有'}\")\n",
    "            try:\n",
    "                create_repo(\n",
    "                    repo_id=repo_id,\n",
    "                    repo_type=repo_type,\n",
    "                    private=False if visibility else True,\n",
    "                    token=token\n",
    "                )\n",
    "                echo(f\"{repo_id} 创建成功\")\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                echo(f\"{repo_id} 创建失败\", e)\n",
    "                return False\n",
    "\n",
    "\n",
    "    def push_file_to_huggingface(\n",
    "        self,\n",
    "        hf_access_token: str,\n",
    "        repo_id: str,\n",
    "        repo_type: str,\n",
    "        visibility: bool,\n",
    "        upload_path: Union[str, Path]\n",
    "    ) -> None:\n",
    "        \"\"\"上传文件到 HuggingFace 中\n",
    "\n",
    "        参数:\n",
    "            hf_access_token (`str`):\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "            repo_id (`str`):\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            upload_path (`str`, `Path`):\n",
    "                要上传到 HuggingFace 仓库的文件本地路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        from pathlib import Path\n",
    "        from huggingface_hub import HfApi, CommitOperationAdd\n",
    "        api = HfApi()\n",
    "\n",
    "        try:\n",
    "            api.whoami(token=hf_access_token)\n",
    "            echo(\"HuggingFace Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"HuggingFace Token 验证失败, 无法上传文件\", e)\n",
    "\n",
    "        upload_file_lists = self.get_all_file(upload_path) # 原文件的路径列表\n",
    "\n",
    "        # 统计信息\n",
    "        count = 0\n",
    "        sum = len(upload_file_lists)\n",
    "\n",
    "        # 检查 HuggingFace 仓库\n",
    "        if not self.check_hf_repo(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type,\n",
    "            visibility=visibility,\n",
    "            token=hf_access_token\n",
    "        ):\n",
    "            echo(f\"{repo_id} (类型: {repo_type}) 不存在, 无法上传文件\")\n",
    "            return\n",
    "\n",
    "        hf_repo_file_list = self.get_hf_repo_file_list(hf_access_token, repo_id, repo_type) # 获取仓库中的文件列表\n",
    "\n",
    "        echo(f\"将文件上传至 HuggingFace: {upload_path} -> {repo_id}\")\n",
    "        echo(f\"使用的 HuggingFace 仓库: {repo_id}, 种类: {repo_type}\")\n",
    "\n",
    "        for upload_file in upload_file_lists:\n",
    "            count += 1\n",
    "            rel_upload_file = os.path.relpath(upload_file, upload_path) # 原文件相对路径\n",
    "            file_name = os.path.basename(upload_file) # 文件名\n",
    "            hf_path_in_repo = Path(rel_upload_file).as_posix() # 文件在仓库中的路径\n",
    "            local_file_obj = Path(upload_file).as_posix() # 文件在本地的绝对路径\n",
    "\n",
    "            echo(f\"[{count}/{sum}] 要上传的文件的相对路径: {rel_upload_file}\")\n",
    "            echo(f\"[{count}/{sum}] 绝对路径: {upload_file}\")\n",
    "\n",
    "            # 检测文件是否存在于仓库中\n",
    "            if rel_upload_file in hf_repo_file_list:\n",
    "                echo(f\"[{count}/{sum}] {file_name} 已存在于仓库中\")\n",
    "                continue\n",
    "\n",
    "            # 对文件进行追踪\n",
    "            echo(f\"[{count}/{sum}] {local_file_obj} -> {repo_id}/{hf_path_in_repo}\")\n",
    "            operations = [\n",
    "                CommitOperationAdd(\n",
    "                    path_in_repo=hf_path_in_repo,\n",
    "                    path_or_fileobj=local_file_obj\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # 上传文件到 HuggingFace\n",
    "            echo(f\"[{count}/{sum}] 上传 {file_name} 到 {repo_id} 中\")\n",
    "            try:\n",
    "                api.create_commit(\n",
    "                    repo_id=repo_id,\n",
    "                    operations=operations,\n",
    "                    commit_message=f\"Upload {file_name}\",\n",
    "                    repo_type=repo_type,\n",
    "                    token=hf_access_token\n",
    "                )\n",
    "                echo(f\"[{count}/{sum}] 上传 {file_name} 完成\")\n",
    "            except Exception as e:\n",
    "                echo(f\"[{count}/{sum}] 上传 {file_name} 失败\", e)\n",
    "\n",
    "        echo(f\"{repo_id} 仓库上传完成\")\n",
    "\n",
    "\n",
    "    def set_git_config(self, email: str, username: str) -> None:\n",
    "        \"\"\"配置 Git 信息\n",
    "\n",
    "        参数:\n",
    "            email (`str`):\n",
    "                邮箱地址\n",
    "\n",
    "            username (`str`):\n",
    "                用户名\n",
    "        \"\"\"\n",
    "        echo(\"配置 Git 信息中\")\n",
    "        !git config --global user.email \"{email}\"\n",
    "        !git config --global user.name \"{username}\"\n",
    "\n",
    "\n",
    "\n",
    "class HF_DATASET():\n",
    "    \"HuggingFace 数据集处理\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def get_hf_file_list(self, repo_id: str, repo_type: str, hf_token: str) -> list:\n",
    "        \"\"\"从 HuggingFace 仓库中获取所有文件的路径\n",
    "\n",
    "        参数:\n",
    "            repo_id (`str`):\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            hf_token (`str`):\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "        返回值:\n",
    "            `list`: 所有文件在 HuggingFace 仓库中的路径\n",
    "        \"\"\"\n",
    "        from huggingface_hub import HfApi\n",
    "        echo(f\"获取 {repo_id} (类型: {repo_type}) 中所有的文件列表中\")\n",
    "        api = HfApi()\n",
    "        try:\n",
    "            model_list = api.list_repo_files(\n",
    "                repo_id=repo_id,\n",
    "                repo_type=repo_type,\n",
    "                token=hf_token\n",
    "            )\n",
    "            echo(f\"{repo_id} 中所有文件的数量: {len(model_list)}\")\n",
    "        except Exception as e:\n",
    "            echo(f\"获取 {repo_id} 中所有文件的数量时出现了错误\", e)\n",
    "            model_list = []\n",
    "\n",
    "        return model_list\n",
    "\n",
    "\n",
    "    def download_hf_file(self, repo_id: str, repo_type: str, filename: str, local_dir: Union[str, Path], hf_token: str, retry: Optional[int] = 3) -> None:\n",
    "        \"\"\"从 HuggingFace 仓库下载文件到本地路径\n",
    "\n",
    "        参数:\n",
    "            repo_id (`str`):\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            filename (`str`):\n",
    "                文件在 HuggingFace 仓库中的路径\n",
    "\n",
    "            local_dir (`str`, `Path`):\n",
    "                将文件下载到的本地路径\n",
    "\n",
    "            hf_token (`str`):\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "            retry (`int`):\n",
    "                重试下载次数, 默认为 3\n",
    "        \"\"\"\n",
    "        from huggingface_hub import hf_hub_download\n",
    "        count = 0\n",
    "        while count < retry:\n",
    "            count += 1\n",
    "            try:\n",
    "                hf_hub_download(\n",
    "                    repo_id=repo_id,\n",
    "                    repo_type=repo_type,\n",
    "                    filename=filename,\n",
    "                    local_dir=local_dir,\n",
    "                    token=hf_token\n",
    "                )\n",
    "                break\n",
    "            except Exception as e:\n",
    "                echo(f\"{filename} 下载失败\", e)\n",
    "                if count < retry:\n",
    "                    echo(f\"重试下载 {filename} 中\")\n",
    "\n",
    "\n",
    "    def filter_file(self, file_list: list, start_dir: str) -> list:\n",
    "        \"\"\"从文件列表中过滤出指定的文件列表\n",
    "\n",
    "        参数:\n",
    "            file_list (`list`):\n",
    "                所有文件列表\n",
    "\n",
    "            start_dir (`str`):\n",
    "                指定文件所在的路径, 并过滤出新的文件列表\n",
    "\n",
    "        返回值:\n",
    "            `list`: 过滤后的文件列表\n",
    "        \"\"\"\n",
    "        filter_file_list = []\n",
    "        for f in file_list:\n",
    "            if f.startswith(start_dir):\n",
    "                filter_file_list.append(f)\n",
    "\n",
    "        echo(f\"{start_dir} 中的文件数量: {len(filter_file_list)}\")\n",
    "        return filter_file_list\n",
    "\n",
    "\n",
    "\n",
    "class HFDatasetDownloader:\n",
    "    \"\"\"HuggingFace 数据集下载器\"\"\"\n",
    "\n",
    "    def __init__(self, urls: list) -> None:\n",
    "        \"\"\"HuggingFace 文件下载器创建\n",
    "\n",
    "        参数:\n",
    "            urls (`list`):\n",
    "                下载队列\n",
    "\n",
    "        下载队列使用`HF_DATASET().download_hf_file()`处理, 下载队列的格式如下:\n",
    "        ```python\n",
    "        urls = [\n",
    "            [\"repo_id\", \"repo_type\", \"filename\", \"local_dir\", \"hf_token\"],\n",
    "            [\"repo_id\", \"repo_type\", \"filename\", \"local_dir\", \"hf_token\"],\n",
    "            [\"repo_id\", \"repo_type\", \"filename\", \"local_dir\", \"hf_token\"],\n",
    "        ]\n",
    "        ```\n",
    "        \"\"\"\n",
    "        import threading\n",
    "        import datetime\n",
    "        from queue import Queue\n",
    "        self.hf_dataset = HF_DATASET()\n",
    "        self.urls = urls\n",
    "        self.datetime = datetime\n",
    "        self.queue = Queue()\n",
    "        self.total_urls = len(urls)  # 记录总的 URL 数\n",
    "        self.downloaded_count = 0  # 记录已下载的数量\n",
    "        self.lock = threading.Lock()  # 创建锁以保护对下载计数器的访问\n",
    "\n",
    "\n",
    "    def worker(self) -> None:\n",
    "        \"\"\"调用文件下载工具\"\"\"\n",
    "        while True:\n",
    "            url = self.queue.get()\n",
    "            if url is None:\n",
    "                break\n",
    "            self.hf_dataset.download_hf_file(\n",
    "                repo_id=url[0],\n",
    "                repo_type=url[1],\n",
    "                filename=url[2],\n",
    "                local_dir=url[3],\n",
    "                hf_token=url[4],\n",
    "                retry=self.retry\n",
    "            )\n",
    "            self.queue.task_done()\n",
    "            with self.lock:  # 访问共享资源时加锁\n",
    "                self.downloaded_count += 1\n",
    "                self.print_progress()  # 打印进度\n",
    "\n",
    "\n",
    "    def print_progress(self) -> None:\n",
    "        \"\"\"进度条显示\"\"\"\n",
    "        progress = (self.downloaded_count / self.total_urls) * 100\n",
    "        current_time = self.datetime.datetime.now()\n",
    "        time_interval = current_time - self.start_time\n",
    "        hours = time_interval.seconds // 3600\n",
    "        minutes = (time_interval.seconds // 60) % 60\n",
    "        seconds = time_interval.seconds % 60\n",
    "        formatted_time = f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "\n",
    "        if self.downloaded_count > 0:\n",
    "            speed = self.downloaded_count / time_interval.total_seconds()\n",
    "        else:\n",
    "            speed = 0\n",
    "\n",
    "        remaining_urls = self.total_urls - self.downloaded_count\n",
    "\n",
    "        if speed > 0:\n",
    "            estimated_remaining_time_seconds = remaining_urls / speed\n",
    "            estimated_remaining_time = self.datetime.timedelta(seconds=estimated_remaining_time_seconds)\n",
    "            estimated_hours = estimated_remaining_time.seconds // 3600\n",
    "            estimated_minutes = (estimated_remaining_time.seconds // 60) % 60\n",
    "            estimated_seconds = estimated_remaining_time.seconds % 60\n",
    "            formatted_estimated_time = f\"{estimated_hours:02}:{estimated_minutes:02}:{estimated_seconds:02}\"\n",
    "        else:\n",
    "            formatted_estimated_time = \"N/A\"\n",
    "\n",
    "        echo(f\"下载进度: {progress:.2f}% | {self.downloaded_count}/{self.total_urls} [{formatted_time}<{formatted_estimated_time}, {speed:.2f}it/s]\")\n",
    "\n",
    "\n",
    "    def start_threads(self, num_threads: int = 16, retry: Optional[int] = 3) -> None:\n",
    "        \"\"\"启动多线程下载器\n",
    "\n",
    "        参数:\n",
    "            num_threads (`int`):\n",
    "                下载线程, 默认为 16\n",
    "\n",
    "            retry (`int`):\n",
    "                重试下载次数, 默认为 3\n",
    "        \"\"\"\n",
    "        import threading\n",
    "        import time\n",
    "        threads = []\n",
    "        self.retry = retry\n",
    "        self.start_time = self.datetime.datetime.now()\n",
    "        time.sleep(0.1) # 避免 print_progress() 计算时间时出现 division by zero\n",
    "        for _ in range(num_threads):\n",
    "            thread = threading.Thread(target=self.worker)\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for url in self.urls:\n",
    "            self.queue.put(url)\n",
    "\n",
    "        self.queue.join()\n",
    "\n",
    "        for _ in range(num_threads):\n",
    "            self.queue.put(None)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "\n",
    "\n",
    "class DATASET():\n",
    "    \"\"\"数据集下载工具\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self.hf_dataset = HF_DATASET()\n",
    "        self.aria2 = ARIA2(None, None)\n",
    "\n",
    "\n",
    "    def get_dataset(\n",
    "        self,\n",
    "        dataset_path: Union[str, Path],\n",
    "        url: str,\n",
    "        name: Optional[str] = None,\n",
    "        retry: Optional[int] = 3\n",
    "    ) -> Union[str, None]:\n",
    "        \"\"\"从下载链接获取数据集\n",
    "\n",
    "        参数:\n",
    "            dataset_path (`str`, `Path`):\n",
    "                数据集的存放路径\n",
    "\n",
    "            url (`str`):\n",
    "                数据集的下载链接\n",
    "\n",
    "            name (`str`):\n",
    "                将下载的文件进行重命名\n",
    "\n",
    "        返回值:\n",
    "            `str`: 解压的文件路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        path = \"/tmp\"\n",
    "        if name is None:\n",
    "            name = url.split(\"/\").pop()\n",
    "\n",
    "        archive_format = name.split(\".\").pop() # 压缩包格式\n",
    "        origin_file_path = self.aria2.aria2( # 下载文件\n",
    "            url=url,\n",
    "            path=path,\n",
    "            filename=name,\n",
    "            retry=retry\n",
    "        )\n",
    "\n",
    "        if origin_file_path is not None:\n",
    "            # 解压文件\n",
    "            echo(f\"尝试解压 {name}\")\n",
    "            if archive_format == \"7z\":\n",
    "                !7z x \"{origin_file_path}\" -o\"{dataset_path}\"\n",
    "                echo(f\"{name} 解压完成, 路径: {dataset_path}\")\n",
    "                return dataset_path\n",
    "            elif archive_format == \"zip\":\n",
    "                !unzip \"{origin_file_path}\" -d \"{dataset_path}\"\n",
    "                echo(f\"{name} 解压完成, 路径: {dataset_path}\")\n",
    "                return dataset_path\n",
    "            elif archive_format == \"tar\":\n",
    "                !tar -xvf \"{origin_file_path}\" -C \"{dataset_path}\"\n",
    "                echo(f\"{name} 解压完成, 路径: {dataset_path}\")\n",
    "                return dataset_path\n",
    "            else:\n",
    "                echo(f\"{name} 的格式不支持解压\")\n",
    "                return None\n",
    "        else:\n",
    "            echo(f\"{name} 下载失败\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    def get_dataset_from_hf(\n",
    "        self,\n",
    "        local_path: Union[str, Path],\n",
    "        repo_id: str,\n",
    "        repo_type: str,\n",
    "        folder: Optional[str] = None,\n",
    "        hf_token: Optional[str] = None,\n",
    "        retry: Optional[int] = 3\n",
    "    ) -> Union[str, None]:\n",
    "        \"\"\"从 HuggingFace 下载训练集\n",
    "\n",
    "        参数:\n",
    "            local_path (`str`, `Path`):\n",
    "                将数据集下载到本地的路径\n",
    "\n",
    "            repo_id (`str`):\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            folder (`str`, `None`):\n",
    "                指定要下载 HuggingFace 中指定的文件夹, 例如:\n",
    "\n",
    "            hf_token (`str`, `None`):\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "            retry (`int`):\n",
    "                重试下载的次数, 默认为 3\n",
    "\n",
    "        返回值:\n",
    "            `str`: 下载到本地的路径\n",
    "\n",
    "        说明:\n",
    "            folder 未指定时, 则下载 HuggingFace 仓库中的所有文件, 如果 folder 指定了, 例如指定的是`aaaki`\n",
    "            \n",
    "            而仓库的文件结构如下:\n",
    "\n",
    "            ```markdown\n",
    "            HuggingFace Repo\n",
    "            ├── Nachoneko\n",
    "            │   ├── 1_nachoneko\n",
    "            │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "            │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "            │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "            │   │       └── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "            │   ├── 2_nachoneko\n",
    "            │   │       ├── 0(8).txt\n",
    "            │   │       ├── 0(8).webp\n",
    "            │   │       ├── 001_2.png\n",
    "            │   │       └── 001_2.txt\n",
    "            │   └── 4_nachoneko\n",
    "            │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "            │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "            │           ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "            │           └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "            └ aaaki\n",
    "                ├── 1_aaaki\n",
    "                │   ├── 1.png\n",
    "                │   ├── 1.txt\n",
    "                │   ├── 11.png\n",
    "                │   ├── 11.txt\n",
    "                │   ├── 12.png\n",
    "                │   └── 12.txt\n",
    "                └── 3_aaaki\n",
    "                    ├── 14.png\n",
    "                    ├── 14.txt\n",
    "                    ├── 16.png\n",
    "                    └── 16.txt\n",
    "            ```\n",
    "\n",
    "            则使用该函数下载 HuggingFace 仓库的文件时将下载`aaaki`文件夹中的所有文件, 而`Nachoneko`文件夹中的文件不会被下载\n",
    "        \"\"\"\n",
    "        import os\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        echo(f\"从 {repo_id} (类型: {repo_type}) 下载数据集\")\n",
    "        # 从 HuggingFace 仓库中获取所有文件列表\n",
    "        hf_file_list = self.hf_dataset.get_hf_file_list(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type,\n",
    "            hf_token=hf_token\n",
    "        )\n",
    "\n",
    "        # 指定 folder 时过滤出新的文件列表\n",
    "        if folder is None:\n",
    "            filter_file_list = hf_file_list\n",
    "            folder_path = local_path\n",
    "        else:\n",
    "            echo(f\"指定下载 {folder} 中的文件\")\n",
    "            filter_file_list = self.hf_dataset.filter_file(hf_file_list, folder)\n",
    "            folder_path = os.path.join(local_path, folder)\n",
    "\n",
    "        # 创建下载任务\n",
    "        task = []\n",
    "        for file in tqdm(filter_file_list, desc=\"创建下载任务\"):\n",
    "            task.append([repo_id, repo_type, file, local_path, hf_token])\n",
    "\n",
    "        # 从 HuggingFace 仓库下载文件\n",
    "        echo(f\"下载 {repo_id} 中的文件中\")\n",
    "        dataset_downloader = HFDatasetDownloader(task)\n",
    "        dataset_downloader.start_threads(num_threads=32, retry=retry)\n",
    "        if os.path.exists(folder_path):\n",
    "            echo(f\"从 {repo_id} 下载数据集文件完成, 路径: {folder_path}\")\n",
    "            return folder_path\n",
    "        else:\n",
    "            echo(f\"从 {repo_id} 下载数据集文件失败\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    def get_dataset_from_ms(\n",
    "        self,\n",
    "        local_path: Union[str, Path],\n",
    "        repo_id: str,\n",
    "        repo_type: str,\n",
    "        folder: Optional[str] = None,\n",
    "        ms_token: Optional[str] = None,\n",
    "        retry: Optional[int] = 3\n",
    "    ) -> Union[str, None]:\n",
    "        \"\"\"从 ModelScope 下载训练集\n",
    "\n",
    "        参数:\n",
    "            local_path (`str`, `Path`):\n",
    "                将数据集下载到本地的路径\n",
    "\n",
    "            repo_id (`str`):\n",
    "                ModelScope 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                ModelScope 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            folder (`str`, `None`):\n",
    "                指定要下载 ModelScope 中指定的文件夹, 例如:\n",
    "\n",
    "            ms_token (`str`, `None`):\n",
    "                ModelScope 账号 Token\n",
    "\n",
    "            retry (`int`):\n",
    "                重试下载的次数, 默认为 3\n",
    "\n",
    "        返回值:\n",
    "            `str`: 下载到本地的路径\n",
    "\n",
    "        说明:\n",
    "            folder 未指定时, 则下载 ModelScope 仓库中的所有文件, 如果 folder 指定了, 例如指定的是`aaaki`\n",
    "            \n",
    "            而仓库的文件结构如下:\n",
    "\n",
    "            ```markdown\n",
    "            ModelScope Repo\n",
    "            ├── Nachoneko\n",
    "            │   ├── 1_nachoneko\n",
    "            │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "            │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "            │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "            │   │       └── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "            │   ├── 2_nachoneko\n",
    "            │   │       ├── 0(8).txt\n",
    "            │   │       ├── 0(8).webp\n",
    "            │   │       ├── 001_2.png\n",
    "            │   │       └── 001_2.txt\n",
    "            │   └── 4_nachoneko\n",
    "            │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "            │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "            │           ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "            │           └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "            └ aaaki\n",
    "                ├── 1_aaaki\n",
    "                │   ├── 1.png\n",
    "                │   ├── 1.txt\n",
    "                │   ├── 11.png\n",
    "                │   ├── 11.txt\n",
    "                │   ├── 12.png\n",
    "                │   └── 12.txt\n",
    "                └── 3_aaaki\n",
    "                    ├── 14.png\n",
    "                    ├── 14.txt\n",
    "                    ├── 16.png\n",
    "                    └── 16.txt\n",
    "            ```\n",
    "\n",
    "            则使用该函数下载 ModelScope 仓库的文件时将下载`aaaki`文件夹中的所有文件, 而`Nachoneko`文件夹中的文件不会被下载\n",
    "        \"\"\"\n",
    "        import os\n",
    "        from modelscope import snapshot_download\n",
    "        from modelscope.hub.api import HubApi\n",
    "        api = HubApi()\n",
    "        count = 0\n",
    "\n",
    "        echo(\"验证 ModelScope Token 中\")\n",
    "        try:\n",
    "            api.login(ms_token)\n",
    "            echo(\"ModelScope Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"ModelScope Token 验证失败, 无法下载文件\", e)\n",
    "            return\n",
    "\n",
    "        # TODO: 支持创空间\n",
    "        if repo_type not in [\"model\", \"dataset\"]:\n",
    "            echo(f\"{repo_id} 的类型暂不支持下载文件\")\n",
    "            return None\n",
    "\n",
    "        # 选择下载模式\n",
    "        if folder is None:\n",
    "            folder_path = local_path\n",
    "            echo(f\"下载 {repo_id} (类型: {repo_type}) 仓库中, 路径: {folder_path}\")\n",
    "            while count < retry:\n",
    "                count += 1\n",
    "                try:\n",
    "                    snapshot_download(\n",
    "                        repo_id=repo_id,\n",
    "                        repo_type=repo_type,\n",
    "                        local_dir=local_path\n",
    "                    )\n",
    "                    echo(f\"下载 {repo_id} (类型: {repo_type}) 仓库成功, 路径: {folder_path}\")\n",
    "                    return folder_path\n",
    "                except Exception as e:\n",
    "                    echo(f\"下载 {repo_id} (类型: {repo_type}) 仓库时出现错误\", e)\n",
    "                    if count < retry:\n",
    "                        echo(f\"重试下载 {repo_id} (类型: {repo_type}) 仓库中\")\n",
    "                    else:\n",
    "                        return None\n",
    "        else:\n",
    "            folder_path = os.path.join(local_path, folder)\n",
    "            echo(f\"从 {repo_id} (类型: {repo_type}) 下载 {folder} 中, 路径: {folder_path}\")\n",
    "            while count < retry:\n",
    "                count += 1\n",
    "                try:\n",
    "                    snapshot_download(\n",
    "                        repo_id=repo_id,\n",
    "                        repo_type=repo_type,\n",
    "                        local_dir=local_path,\n",
    "                        allow_file_pattern=f\"{folder}/*\"\n",
    "                    )\n",
    "                    echo(f\"从 {repo_id} (类型: {repo_type}) 下载 {folder} 成功, 路径: {folder_path}\")\n",
    "                    return folder_path\n",
    "                except Exception as e:\n",
    "                    echo(f\"从 {repo_id} (类型: {repo_type}) 下载 {folder} 时出现错误\", e)\n",
    "                    if count <retry:\n",
    "                        echo(f\"重试从 {repo_id} (类型: {repo_type}) 下载 {folder} 中\")\n",
    "                    else:\n",
    "                        return None\n",
    "\n",
    "\n",
    "    def get_single_file_from_hf(\n",
    "        self,\n",
    "        repo_id: str,\n",
    "        repo_type: str,\n",
    "        filename: str,\n",
    "        local_dir: str,\n",
    "        token: Optional[str] = None,\n",
    "        retry: Optional[int] = 3\n",
    "    ) -> Union[str, None]:\n",
    "        \"\"\"从 HuggingFace 仓库下载单个文件\n",
    "\n",
    "        参数:\n",
    "            repo_id (`str`):\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            filename (`str`):\n",
    "                文件在 HuggingFace 仓库中的路径\n",
    "\n",
    "            local_dir (`str`):\n",
    "                将文件下载到本地的路径\n",
    "\n",
    "            token (`str`, `None`):\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "            retry (`int`):\n",
    "                重试下载的次数, 默认为 3\n",
    "\n",
    "        返回值:\n",
    "            `str`: 下载的文件路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        from huggingface_hub import hf_hub_download\n",
    "\n",
    "        repo_name = repo_id.split(\"/\").pop()\n",
    "        tmp = \"/tmp\"\n",
    "        tmp_path = os.path.join(tmp, f\"__hf_file_downloader_{repo_name}_tmp__\") # 临时文件路径\n",
    "        file_path = os.path.join(local_dir, filename.split(\"/\").pop()) # 下载文件到本地的路径\n",
    "        count = 0\n",
    "\n",
    "        # 从 HuggingFace 下载文件\n",
    "        echo(f\"从 {repo_id} (类型: {repo_type}) 下载 {filename} 中, 路径: {file_path}\")\n",
    "        if count < retry:\n",
    "            count += 1\n",
    "            try:\n",
    "                hf_file_path = hf_hub_download(\n",
    "                    repo_id=repo_id,\n",
    "                    repo_type=repo_type,\n",
    "                    filename=filename,\n",
    "                    local_dir=tmp_path,\n",
    "                    token=token\n",
    "                )\n",
    "\n",
    "                os.makedirs(local_dir, exist_ok=True)\n",
    "                !mv -f \"{hf_file_path}\" \"{local_dir}\"\n",
    "                echo(f\"{filename} 下载完成, 路径: {file_path}\")\n",
    "                return file_path\n",
    "            except Exception as e:\n",
    "                echo(f\"从 {repo_id} 下载 {filename} 失败\", e)\n",
    "                if count < retry:\n",
    "                    echo(f\"重试从 {repo_id} (类型: {repo_type}) 下载 {filename} 中\")\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "\n",
    "    def get_single_file_from_ms(\n",
    "        self,\n",
    "        repo_id: str,\n",
    "        repo_type: str,\n",
    "        filename: str,\n",
    "        local_dir: Union[str, Path],\n",
    "        token: Optional[str] = None,\n",
    "        retry: Optional[int] = 3\n",
    "    ) -> Union[str, None]:\n",
    "        \"\"\"从 ModelScope 仓库下载单个文件\n",
    "\n",
    "        参数:\n",
    "            repo_id (`str`):\n",
    "                ModelScope 仓库的 ID\n",
    "\n",
    "            repo_type (`str`):\n",
    "                ModelScope 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            filename (`str`):\n",
    "                文件在 ModelScope 仓库中的路径\n",
    "\n",
    "            local_dir (`str`):\n",
    "                将文件下载到本地的路径\n",
    "\n",
    "            token (`str`, `None`):\n",
    "                ModelScope 账号 Token\n",
    "\n",
    "            retry (`int`):\n",
    "                重试下载的次数, 默认为 3\n",
    "\n",
    "        返回值:\n",
    "            `str`: 下载的文件路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        from pathlib import Path\n",
    "        from modelscope import model_file_download, dataset_file_download\n",
    "        from modelscope.hub.api import HubApi\n",
    "        api = HubApi()\n",
    "\n",
    "        repo_name = repo_id.split(\"/\").pop()\n",
    "        tmp = \"/tmp\"\n",
    "        tmp_path = os.path.join(tmp, f\"__hf_file_downloader_{repo_name}_tmp__\") # 临时文件路径\n",
    "        file_path = os.path.join(local_dir, filename.split(\"/\").pop()) # 下载文件到本地的路径\n",
    "        download_status = False\n",
    "        count = 0\n",
    "\n",
    "        echo(\"验证 ModelScope Token 中\")\n",
    "        try:\n",
    "            api.login(token)\n",
    "            echo(\"ModelScope Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"ModelScope Token 验证失败, 无法下载文件\", e)\n",
    "            return\n",
    "\n",
    "        echo(f\"从 {repo_id} (类型: {repo_type}) 下载 {filename} 中, 路径: {file_path}\")\n",
    "        if repo_type == \"model\":\n",
    "            while count < retry:\n",
    "                count += 1\n",
    "                try:\n",
    "                    ms_file_path = model_file_download(\n",
    "                        model_id=repo_id,\n",
    "                        file_path=filename,\n",
    "                        local_dir=tmp_path\n",
    "                    )\n",
    "                    download_status = True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    echo(f\"从 {repo_id} (类型: {repo_type}) 下载 {filename} 时出现错误\", e)\n",
    "                    if count < retry:\n",
    "                        echo(f\"重试从 {repo_id} (类型: {repo_type}) 下载 {filename} 中\")\n",
    "        elif repo_type == \"dataset\":\n",
    "            while count < retry:\n",
    "                count += 1\n",
    "                try:\n",
    "                    ms_file_path = dataset_file_download(\n",
    "                        dataset_id=repo_id,\n",
    "                        file_path=filename,\n",
    "                        local_dir=tmp_path,\n",
    "                    )\n",
    "                    download_status = True\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    echo(f\"从 {repo_id} (类型: {repo_type}) 下载 {filename} 时出现错误\", e)\n",
    "                    if count < retry:\n",
    "                        echo(f\"重试从 {repo_id} (类型: {repo_type}) 下载 {filename} 中\")\n",
    "        elif repo_type == \"space\":\n",
    "            echo(f\"{repo_id} 类型为 {repo_type}, 暂不支持下载文件\")\n",
    "\n",
    "        if download_status:\n",
    "            ms_file_path = Path(ms_file_path)\n",
    "            os.makedirs(local_dir, exist_ok=True)\n",
    "            !mv -f \"{ms_file_path}\" \"{local_dir}\"\n",
    "            echo(f\"{filename} 下载完成, 路径: {file_path}\")\n",
    "            return file_path\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "class MIRROR:\n",
    "    \"\"\"PyPI, HuggingFace, Github 镜像管理工具\"\"\"\n",
    "\n",
    "    def __init__(self, workspace: Union[str, Path]) -> None:\n",
    "        \"\"\"设置镜像测试缓存目录和 Git 配置文件目录\"\"\"\n",
    "        self.WORKSPACE = workspace\n",
    "\n",
    "\n",
    "    def set_pypi_index_mirror(self, mirror: Optional[str] = None) -> None:\n",
    "        \"\"\"设置 PyPI Index 镜像源\n",
    "\n",
    "        参数:\n",
    "            mirror (`str`, `None`):\n",
    "                PyPI 镜像源链接, 当不传入镜像源链接时则清除镜像源\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if mirror:\n",
    "            echo(\"使用 PIP_INDEX_URL, UV_INDEX_URL 环境变量设置 PyPI Index 镜像源\")\n",
    "            os.environ[\"PIP_INDEX_URL\"] = mirror\n",
    "            os.environ[\"UV_INDEX_URL\"] = mirror\n",
    "        else:\n",
    "            echo(\"清除 PIP_INDEX_URL, UV_INDEX_URL 环境变量, 取消使用 PyPI Index 镜像源\")\n",
    "            if \"PIP_INDEX_URL\" in os.environ:\n",
    "                del os.environ[\"PIP_INDEX_URL\"]\n",
    "\n",
    "            if \"UV_INDEX_URL\" in os.environ:\n",
    "                del os.environ[\"UV_INDEX_URL\"]\n",
    "\n",
    "\n",
    "    def set_pypi_extra_index_mirror(self, mirror: Optional[str] = None) -> None:\n",
    "        \"\"\"设置 PyPI Extra Index 镜像源\n",
    "\n",
    "        参数:\n",
    "            mirror (`str`, `None`):\n",
    "                PyPI 镜像源链接, 当不传入镜像源链接时则清除镜像源\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if mirror:\n",
    "            echo(\"使用 PIP_EXTRA_INDEX_URL, UV_EXTRA_INDEX_URL 环境变量设置 PyPI Extra Index 镜像源\")\n",
    "            os.environ[\"PIP_EXTRA_INDEX_URL\"] = mirror\n",
    "            os.environ[\"UV_EXTRA_INDEX_URL\"] = mirror\n",
    "        else:\n",
    "            echo(\"清除 PIP_EXTRA_INDEX_URL, UV_EXTRA_INDEX_URL 环境变量, 取消使用 PyPI Extra Index 镜像源\")\n",
    "            if \"PIP_EXTRA_INDEX_URL\" in os.environ:\n",
    "                del os.environ[\"PIP_EXTRA_INDEX_URL\"]\n",
    "\n",
    "            if \"UV_EXTRA_INDEX_URL\" in os.environ:\n",
    "                del os.environ[\"UV_EXTRA_INDEX_URL\"]\n",
    "\n",
    "\n",
    "    def set_pypi_find_links_mirror(self, mirror: Optional[str] = None) -> None:\n",
    "        \"\"\"设置 PyPI Find Links 镜像源\n",
    "\n",
    "        参数:\n",
    "            mirror (`str`, `None`):\n",
    "                PyPI 镜像源链接, 当不传入镜像源链接时则清除镜像源\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if mirror:\n",
    "            echo(\"使用 PIP_FIND_LINKS, UV_FIND_LINKS 环境变量设置 PyPI Find Links 镜像源\")\n",
    "            os.environ[\"PIP_FIND_LINKS\"] = mirror\n",
    "            os.environ[\"UV_FIND_LINKS\"] = mirror\n",
    "        else:\n",
    "            echo(\"清除 PIP_FIND_LINKS, UV_FIND_LINKS 环境变量, 取消使用 PyPI Find Links 镜像源\")\n",
    "            if \"PIP_FIND_LINKS\" in os.environ:\n",
    "                del os.environ[\"PIP_FIND_LINKS\"]\n",
    "\n",
    "            if \"UV_FIND_LINKS\" in os.environ:\n",
    "                del os.environ[\"UV_FIND_LINKS\"]\n",
    "\n",
    "\n",
    "    def set_github_mirror(self, mirror: Optional[Union[str, list]] = None) -> None:\n",
    "        \"\"\"设置 Github 镜像源\n",
    "\n",
    "        参数:\n",
    "            mirror (`str`, `list`, `None`):\n",
    "                Github 镜像源地址, 当传入的是 Github 镜像源地址, 则直接设置 GIT_CONFIG_GLOBAL 环境变量并直接使用该镜像源地址\n",
    "\n",
    "                如果传入的是镜像源列表, 则自动测试可用的 Github 镜像源并设置 GIT_CONFIG_GLOBAL 环境变量\n",
    "\n",
    "                当不传入参数时则清除 GIT_CONFIG_GLOBAL 环境变量并删除 GIT_CONFIG_GLOBAL 环境变量对应的 Git 配置文件\n",
    "\n",
    "        使用:\n",
    "        ```python\n",
    "        set_github_mirror() # 不传入参数时则清除 Github 镜像源\n",
    "\n",
    "        set_github_mirror(\"https://ghfast.top/https://github.com\") # 只设置一个 Github 镜像源时将直接使用该 Github 镜像源\n",
    "\n",
    "        set_github_mirror( # 传入 Github 镜像源列表时将自动测试可用的 Github 镜像源并设置\n",
    "            [\n",
    "                \"https://ghfast.top/https://github.com\",\n",
    "                \"https://mirror.ghproxy.com/https://github.com\",\n",
    "                \"https://ghproxy.net/https://github.com\",\n",
    "                \"https://gh.api.99988866.xyz/https://github.com\",\n",
    "                \"https://gitclone.com/github.com\",\n",
    "                \"https://gh-proxy.com/https://github.com\",\n",
    "                \"https://ghps.cc/https://github.com\",\n",
    "                \"https://gh.idayer.com/https://github.com\",\n",
    "            ]\n",
    "        )\n",
    "        ```\n",
    "        \"\"\"\n",
    "        import os\n",
    "        import subprocess\n",
    "        if not mirror:\n",
    "            echo(\"清除 GIT_CONFIG_GLOBAL 环境变量, 取消使用 Github 镜像源\")\n",
    "            if \"GIT_CONFIG_GLOBAL\" in os.environ:\n",
    "                # 删除对应的配置文件\n",
    "                if os.path.exists(os.environ[\"GIT_CONFIG_GLOBAL\"]):\n",
    "                    path = os.environ[\"GIT_CONFIG_GLOBAL\"]\n",
    "                    !rm -rf \"{path}\"\n",
    "\n",
    "                del os.environ[\"GIT_CONFIG_GLOBAL\"]\n",
    "\n",
    "            return\n",
    "\n",
    "        git_config_path = os.path.join(self.WORKSPACE, \".gitconfig\")\n",
    "        os.environ[\"GIT_CONFIG_GLOBAL\"] = git_config_path\n",
    "\n",
    "        if isinstance(mirror, str):\n",
    "            echo(\"通过 GIT_CONFIG_GLOBAL 环境变量设置 Github 镜像源\")\n",
    "            !git config --global url.\"{mirror}\".insteadOf \"https://github.com\"\n",
    "        elif isinstance(mirror, list):\n",
    "            mirror_test_path = os.path.join(self.WORKSPACE, \"__github_mirror_test__\")\n",
    "            for gh in mirror:\n",
    "                echo(f\"测试 Github 镜像源: {gh}\")\n",
    "                test_repo = f\"{gh}/licyk/empty\"\n",
    "                if os.path.exists(mirror_test_path):\n",
    "                    !rm -rf \"{mirror_test_path}\"\n",
    "                result = subprocess.run(f'git clone {test_repo} \"{mirror_test_path}\"')\n",
    "                if os.path.exists(mirror_test_path):\n",
    "                    !rm -rf \"{mirror_test_path}\"\n",
    "                if result.returncode == 0:\n",
    "                    echo(\"该镜像源可用\")\n",
    "                    !git config --global url.\"{gh}\".insteadOf \"https://github.com\"\n",
    "                    return\n",
    "                else:\n",
    "                    echo(\"镜像源不可用\")\n",
    "\n",
    "            echo(\"无可用的 Github 镜像源, 取消使用 Github 镜像源\")\n",
    "            if os.path.exists(git_config_path):\n",
    "                !rm -rf \"{git_config_path}\"\n",
    "            if \"GIT_CONFIG_GLOBAL\" in os.environ:\n",
    "                del os.environ[\"GIT_CONFIG_GLOBAL\"]\n",
    "        else:\n",
    "            echo(f\"未知镜像源参数类型: {type(mirror)}\")\n",
    "            return\n",
    "\n",
    "\n",
    "    def set_huggingface_mirror(self, mirror: Optional[str] = None) -> None:\n",
    "        \"\"\"设置 HuggingFace 镜像源\n",
    "\n",
    "        参数:\n",
    "            mirror (`str`, `None`):\n",
    "                HuggingFace 镜像源链接, 当不传入镜像源链接时则清除镜像源\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if mirror:\n",
    "            echo(\"使用 HF_ENDPOINT 环境变量设置 HuggingFace 镜像源\")\n",
    "            os.environ[\"HF_ENDPOINT\"] = mirror\n",
    "        else:\n",
    "            echo(\"清除 HF_ENDPOINT 环境变量, 取消使用 HuggingFace 镜像源\")\n",
    "            if \"HF_ENDPOINT\" in os.environ:\n",
    "                del os.environ[\"HF_ENDPOINT\"]\n",
    "\n",
    "\n",
    "    def set_mirror(\n",
    "        self,\n",
    "        pypi_index_mirror: Optional[str] = None,\n",
    "        pypi_extra_index_mirror: Optional[str] = None,\n",
    "        pypi_find_links_mirror: Optional[str] = None,\n",
    "        github_mirror: Optional[Union[str, list]] = None,\n",
    "        huggingface_mirror: Optional[str] = None\n",
    "    ) -> None:\n",
    "        \"\"\"镜像源设置\n",
    "\n",
    "        参数:\n",
    "            pypi_index_mirror (`str`, `None`):\n",
    "                PyPI Index 镜像源链接\n",
    "\n",
    "            pypi_extra_index_mirror (`str`, `None`):\n",
    "                PyPI Extra Index 镜像源链接\n",
    "\n",
    "            pypi_find_links_mirror (`str`, `None`):\n",
    "                PyPI Find Links 镜像源链接\n",
    "\n",
    "            github_mirror (`str`, `list`, `None`):\n",
    "                Github 镜像源链接或者镜像源链接列表\n",
    "\n",
    "            huggingface_mirror (`str`, `None`):\n",
    "                HuggingFace 镜像源链接\n",
    "        \"\"\"\n",
    "        echo(\"配置镜像源中\")\n",
    "        self.set_pypi_index_mirror(pypi_index_mirror)\n",
    "        self.set_pypi_extra_index_mirror(pypi_extra_index_mirror)\n",
    "        self.set_pypi_find_links_mirror(pypi_find_links_mirror)\n",
    "        self.set_github_mirror(github_mirror)\n",
    "        self.set_huggingface_mirror(huggingface_mirror)\n",
    "        echo(\"镜像源配置完成\")\n",
    "\n",
    "\n",
    "    def configure_pip(self) -> None:\n",
    "        \"\"\"使用环境变量配置 Pip / uv\"\"\"\n",
    "        echo(\"配置 Pip / uv\")\n",
    "        import os\n",
    "        import sys\n",
    "        os.environ[\"UV_HTTP_TIMEOUT\"] = \"30\"\n",
    "        os.environ[\"UV_CONCURRENT_DOWNLOADS\"] = \"50\"\n",
    "        os.environ[\"UV_INDEX_STRATEGY\"] = \"unsafe-best-match\"\n",
    "        os.environ[\"UV_PYTHON\"] = sys.executable\n",
    "        os.environ[\"UV_NO_PROGRESS\"] = \"1\"\n",
    "        os.environ[\"PIP_DISABLE_PIP_VERSION_CHECK\"] = \"1\"\n",
    "        os.environ[\"PIP_NO_WARN_SCRIPT_LOCATION\"] = \"0\"\n",
    "        os.environ[\"PIP_TIMEOUT\"] = \"30\"\n",
    "        os.environ[\"PIP_RETRIES\"] = \"5\"\n",
    "        os.environ[\"PYTHONUTF8\"] = \"1\"\n",
    "        os.environ[\"PYTHONIOENCODING\"] = \"utf8\"\n",
    "\n",
    "\n",
    "\n",
    "class SD_SCRIPTS(ARIA2, GIT, MANAGER, ENV):\n",
    "    \"\"\"sd-scripts 管理工具\"\"\"\n",
    "\n",
    "    def __init__(self, workspace: Union[str, Path], workfolder: str) -> None:\n",
    "        \"\"\"sd-scripts 管理工具\n",
    "\n",
    "        参数:\n",
    "            workspace (`str`, `Path`):\n",
    "                工作区路径\n",
    "\n",
    "            workfolder (`str`):\n",
    "                工作区的文件夹名称\n",
    "        \"\"\"\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "        self.mirror = MIRROR(self.WORKSPACE)\n",
    "        self.repo_manager = REPO_MANAGER()\n",
    "        self.dataset = DATASET()\n",
    "\n",
    "\n",
    "    def get_model(self, url: str, path: Union[str, Path], filename: Optional[str] = None, retry: Optional[int] = 3) -> str:\n",
    "        \"\"\"下载模型文件到本地中\n",
    "\n",
    "        参数:\n",
    "            url (`str`):\n",
    "                模型文件的下载链接\n",
    "\n",
    "            path (`str`, `Path`):\n",
    "                模型文件下载到本地的路径\n",
    "\n",
    "            filename (`str`):\n",
    "                指定下载的模型文件名称\n",
    "\n",
    "            retry (`int`):\n",
    "                重试下载的次数, 默认为 3\n",
    "        \n",
    "        返回值:\n",
    "            `str`: 下载的文件路径\n",
    "        \"\"\"\n",
    "        filename = url.split(\"/\").pop() if filename is None else filename\n",
    "        file_path = super().aria2(\n",
    "            url=url,\n",
    "            path=path,\n",
    "            filename=filename,\n",
    "            retry=retry\n",
    "        )\n",
    "        return file_path\n",
    "\n",
    "\n",
    "    def get_model_from_list(self, path: Union[str, Path], model_list: list, retry: Optional[int] = 3) -> None:\n",
    "        \"\"\"从模型列表下载模型\n",
    "\n",
    "        参数:\n",
    "            path (`str`, `Path`):\n",
    "                将模型下载到的本地路径\n",
    "\n",
    "            model_list (`list`):\n",
    "                模型列表\n",
    "\n",
    "            retry (`int`):\n",
    "                重试下载的次数, 默认为 3\n",
    "\n",
    "        使用:\n",
    "            model_list (`list`) 需要指定模型下载的链接和下载状态, 例如\n",
    "\n",
    "            ```python\n",
    "            model_list = [\n",
    "                [\"url1\", 0],\n",
    "                [\"url2\", 1],\n",
    "                [\"url3\", 0],\n",
    "                [\"url4\", 1, \"file.safetensors\"]\n",
    "            ]\n",
    "            ```\n",
    "\n",
    "            在这个例子中, 第一个参数指定了模型的下载链接, 第二个参数设置了是否要下载这个模型, 当这个值为 1 时则下载该模型\n",
    "\n",
    "            第三个参数是可选参数, 用于指定下载到本地后的文件名称\n",
    "\n",
    "            则上面的例子中`url2`和`url4`下载链接所指的文件将被下载, 并且`url4`所指的文件将被重命名为`file.safetensors`\n",
    "        \"\"\"\n",
    "        for model in model_list:\n",
    "            url = model[0]\n",
    "            status = model[1]\n",
    "            filename = model[2] if len(model) > 2 else None\n",
    "            if status == 1:\n",
    "                if filename is None:\n",
    "                    self.get_model(\n",
    "                        url=url,\n",
    "                        path=path,\n",
    "                        retry=retry\n",
    "                    )\n",
    "                else:\n",
    "                    self.get_model(\n",
    "                        url=url,\n",
    "                        path=path,\n",
    "                        filename=filename,\n",
    "                        retry=retry\n",
    "                    )\n",
    "\n",
    "\n",
    "    def install(\n",
    "        self,\n",
    "        torch_ver: Optional[str] = None,\n",
    "        xformers_ver: Optional[str] = None,\n",
    "        git_branch: Optional[str] = None,\n",
    "        git_commit: Optional[str] = None,\n",
    "        model_path: Optional[Union[str, Path]] = None,\n",
    "        model_list: Optional[list] = None,\n",
    "        use_uv: bool = False,\n",
    "        pypi_index_mirror: Optional[str] = None,\n",
    "        pypi_extra_index_mirror: Optional[str] = None,\n",
    "        pypi_find_links_mirror: Optional[str] = None,\n",
    "        github_mirror: Optional[Union[str, list]] = None,\n",
    "        huggingface_mirror: Optional[str] = None,\n",
    "        sd_scripts_repo: Optional[str] = None,\n",
    "        sd_scripts_requirment: Optional[str] = None,\n",
    "        retry: Optional[int] = 3,\n",
    "    ) -> None:\n",
    "        \"\"\"安装 sd-scripts 和其余环境\n",
    "\n",
    "        参数:\n",
    "            torch_ver (`str`, `None`):\n",
    "                指定的 PyTorch 软件包包名, 并包括版本号\n",
    "\n",
    "            xformers_ver (`str`, `None`):\n",
    "                指定的 xFormers 软件包包名, 并包括版本号\n",
    "\n",
    "            git_branch (`str`, `None`):\n",
    "                指定要切换 sd-scripts 的分支\n",
    "\n",
    "            git_commit (`str`, `None`):\n",
    "                指定要切换到 sd-scripts 的提交记录\n",
    "\n",
    "            model_path (`str`, `Path`, `None`):\n",
    "                指定模型下载的路径\n",
    "\n",
    "            model_list (`list`, `None`):\n",
    "                模型下载列表\n",
    "\n",
    "            use_uv (`bool`):\n",
    "                使用 uv 替代 Pip 进行 Python 软件包的安装\n",
    "\n",
    "            pypi_index_mirror (`str`, `None`):\n",
    "                PyPI Index 镜像源链接\n",
    "\n",
    "            pypi_extra_index_mirror (`str`, `None`):\n",
    "                PyPI Extra Index 镜像源链接\n",
    "\n",
    "            pypi_find_links_mirror (`str`, `None`):\n",
    "                PyPI Find Links 镜像源链接\n",
    "\n",
    "            github_mirror (`str`, `list`, `None`):\n",
    "                Github 镜像源链接或者镜像源链接列表\n",
    "\n",
    "            huggingface_mirror (`str`, `None`):\n",
    "                HuggingFace 镜像源链接\n",
    "\n",
    "            sd_scripts_repo (`str`, `None`):\n",
    "                sd-scripts 仓库地址, 未指定时默认为`https://github.com/kohya-ss/sd-scripts`\n",
    "\n",
    "            sd_scripts_requirment (`str`, `None`):\n",
    "                sd-scripts 的依赖文件名, 未指定时默认为`requirements.txt`\n",
    "\n",
    "            retry (`int`, `None`):\n",
    "                设置下载模型失败时重试次数\n",
    "        \"\"\"\n",
    "        import os\n",
    "        sd_scripts_path = os.path.join(self.WORKSPACE, self.WORKFOLDER)\n",
    "        req_file = os.path.join(sd_scripts_path, sd_scripts_requirment if sd_scripts_requirment else \"requirements.txt\")\n",
    "        sd_scripts_repo = sd_scripts_repo if sd_scripts_repo else \"https://github.com/kohya-ss/sd-scripts\"\n",
    "        model_path = model_path if model_path else os.path.join(self.WORKSPACE, \"sd-models\")\n",
    "        model_list = model_list if model_list else []\n",
    "\n",
    "        self.check_gpu() # 检查是否有可用的 GPU\n",
    "        # 配置镜像源\n",
    "        self.mirror.set_mirror(\n",
    "            pypi_index_mirror=pypi_index_mirror,\n",
    "            pypi_extra_index_mirror=pypi_extra_index_mirror,\n",
    "            pypi_find_links_mirror=pypi_find_links_mirror,\n",
    "            github_mirror=github_mirror,\n",
    "            huggingface_mirror=huggingface_mirror\n",
    "        )\n",
    "        self.mirror.configure_pip() # 配置 Pip / uv\n",
    "        self.prepare_env_depend(use_uv=use_uv) # 准备 Notebook 的运行依赖\n",
    "        # 下载 sd-scripts\n",
    "        self.clone(\n",
    "            addr=sd_scripts_repo,\n",
    "            path=self.WORKSPACE,\n",
    "            name=self.WORKFOLDER\n",
    "        )\n",
    "        # 切换指定的 sd-scripts 分支\n",
    "        self.checkout(\n",
    "            path=sd_scripts_path,\n",
    "            branch=git_branch\n",
    "        )\n",
    "        # 切换到指定的 sd-scripts 提交记录\n",
    "        self.reset(\n",
    "            path=sd_scripts_path,\n",
    "            commit=git_commit\n",
    "        )\n",
    "        # 安装 PyTorch 和 xFormers\n",
    "        self.prepare_torch(\n",
    "            torch_ver=torch_ver,\n",
    "            xformers_ver=xformers_ver,\n",
    "            use_uv=use_uv\n",
    "        )\n",
    "        # 安装 sd-scripts 的依赖\n",
    "        os.chdir(sd_scripts_path)\n",
    "        self.install_requirements(\n",
    "            path=req_file,\n",
    "            use_uv=use_uv\n",
    "        )\n",
    "        os.chdir(self.WORKSPACE)\n",
    "        # 安装使用 sd-scripts 进行训练所需的其他软件包\n",
    "        self.py_pkg_manager(\n",
    "            pkg=\"lycoris-lora dadaptation open-clip-torch wandb\",\n",
    "            type=\"install\",\n",
    "            use_uv=use_uv\n",
    "        )\n",
    "        # 更新 urllib3\n",
    "        self.py_pkg_manager(\n",
    "            pkg=\"urllib3\",\n",
    "            type=\"update\",\n",
    "            use_uv=False\n",
    "        )\n",
    "        self.tcmalloc() # 设置 TCMalloc 内存优化\n",
    "        self.get_model_from_list(\n",
    "            path=model_path,\n",
    "            model_list=model_list,\n",
    "            retry=retry\n",
    "        )\n",
    "\n",
    "\n",
    "###################################\n",
    "echo(\"初始化功能完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数配置\n",
    "设置必要的参数, 根据注释说明进行修改  \n",
    "2. [[← 上一个单元](#功能初始化)|[下一个单元 →](#安装环境)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境设置\n",
    "WORKSPACE = \"/kaggle\" # 工作路径, 通常不需要修改\n",
    "WORKFOLDER = \"sd-scripts\" # 工作路径中文件夹名称, 通常不需要修改\n",
    "SD_SCRIPTS_PATH = \"/kaggle/sd-scripts\" # sd-scripts 的路径\n",
    "SD_SCRIPTS_REPO = \"https://github.com/kohya-ss/sd-scripts\" # sd-scripts 仓库地址\n",
    "SD_SCRIPTS_REQUIREMENT = \"requirements.txt\" # sd-scripts 依赖文件名\n",
    "TORCH_VER = \"torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124\" # PyTorch 版本\n",
    "XFORMERS_VER = \"xformers==0.0.28.post3\" # xFormers 版本\n",
    "USE_UV = True # 使用 uv 加速 Python 软件包安装, 修改为 True 为启用, False 为禁用\n",
    "PIP_INDEX_MIRROR = \"https://pypi.python.org/simple\" # PyPI 主镜像源\n",
    "PIP_EXTRA_INDEX_MIRROR = \"https://download.pytorch.org/whl/cu124\" # PyPI 扩展镜像源\n",
    "# PIP_FIND_LINKS_MIRROR = \"https://download.pytorch.org/whl/cu124/torch_stable.html\" # PyPI 扩展镜像源\n",
    "HUGGINGFACE_MIRROR = \"https://hf-mirror.com\" # HuggingFace 镜像源\n",
    "GITHUB_MIRROR = [ # Github 镜像源\n",
    "    \"https://ghfast.top/https://github.com\",\n",
    "    \"https://mirror.ghproxy.com/https://github.com\",\n",
    "    \"https://ghproxy.net/https://github.com\",\n",
    "    \"https://gh.api.99988866.xyz/https://github.com\",\n",
    "    \"https://gitclone.com/github.com\",\n",
    "    \"https://gh-proxy.com/https://github.com\",\n",
    "    \"https://ghps.cc/https://github.com\",\n",
    "    \"https://gh.idayer.com/https://github.com\"\n",
    "]\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# sd-scripts 版本设置\n",
    "SD_SCRIPTS_BRANCH = \"dev\" # sd-scripts 分支, 可切换成 main / dev 或者其它分支, 留空则不进行切换\n",
    "SD_SCRIPTS_COMMIT = \"\" # 切换 sd-scripts 的版本到某个 Git 提交记录上, 留空则不进行切换\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# 模型上传设置, 使用 HuggingFace / ModelScope 上传训练好的模型\n",
    "# HuggingFace: https://huggingface.co\n",
    "# ModelScope: https://modelscope.cn\n",
    "USE_HF_TO_SAVE_MODEL = False # 使用 HuggingFace 保存训练好的模型, 修改为 True 为启用, False 为禁用 (True / False)\n",
    "USE_MS_TO_SAVE_MODEL = False # 使用 ModelScope 保存训练好的模型, 修改为 True 为启用, False 为禁用 (True / False)\n",
    "\n",
    "# 设置使用 ModelScope 上传文件时使用的文件上传方式, 使用新版方式上传速度更快, 通常保持默认即可\n",
    "# 旧版上传方式基于 Git, 新版上传方式基于 ModelScope API\n",
    "USE_NEW_MS_UPLOADER = True # 修改为 True 设置为新版, False 为旧版 (True / False)\n",
    "\n",
    "# HuggingFace Token 在 Account -> Settings -> Access Tokens 中获取\n",
    "HF_TOKEN = \"\" # HuggingFace Token\n",
    "# ModelScope Token 在 首页 -> 访问令牌 -> SDK 令牌 中获取\n",
    "MS_TOKEN = \"\" # ModelScope Token\n",
    "\n",
    "# HuggingFace 模型仓库的 ID, 当仓库不存在时则尝试新建一个\n",
    "HF_REPO_ID = \"username/reponame\" # HuggingFace 仓库的 ID (格式: \"用户名/仓库名\")\n",
    "HF_REPO_TYPE = \"model\" # HuggingFace 仓库的种类 (可选的类型为: model / dataset / space), 如果在 HuggingFace 新建的仓库为模型仓库则不需要修改\n",
    "# HuggingFace 仓库类型和对应名称:\n",
    "# model: 模型仓库\n",
    "# dataset: 数据集仓库\n",
    "# space: 在线运行空间仓库\n",
    "\n",
    "# ModelScope 模型仓库的 ID, 当仓库不存在时则尝试新建一个\n",
    "MS_REPO_ID = \"username/reponame\" # ModelScope 仓库的 ID (格式: \"用户名/仓库名\")\n",
    "MS_REPO_TYPE = \"model\" # ModelScope 仓库的种类 (model / dataset / space), 如果在 ModelScope 新建的仓库为模型仓库则不需要修改\n",
    "# ModelScope 仓库类型和对应名称:\n",
    "# model: 模型仓库\n",
    "# dataset: 数据集仓库\n",
    "# space: 创空间仓库\n",
    "\n",
    "# 设置自动创建仓库时仓库的可见性, False 为私有仓库(不可见), True 为公有仓库(可见), 通常保持默认即可\n",
    "HF_REPO_VISIBILITY = False # 设置新建的 HuggingFace 仓库可见性 (True / False)\n",
    "MS_REPO_VISIBILITY = False # 设置新建的 ModelScope 仓库可见性 (True / False)\n",
    "\n",
    "# Git 信息设置, 用于上传模型至 ModelScope 时使用, 可以使用默认值\n",
    "GIT_USER_EMAIL = \"username@example.com\" # Git 的邮箱\n",
    "GIT_USER_NAME = \"username\" # Git 的用户名\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# 训练日志设置, 可使用 TensorBoard / WandB 记录训练日志, 使用 WandB 可远程查看实时训练日志\n",
    "# 使用 WandB 需要填写 WANDB_TOKEN\n",
    "# 如果 TensorBoard 和 WandB 同时使用, 可以改成 all\n",
    "LOG_MODULE = \"tensorboard\" # 使用的日志记录工具 (tensorboard / wandb / all)\n",
    "\n",
    "# WandB Token 设置\n",
    "# WandB Token 可在 https://wandb.ai/authorize 中获取\n",
    "WANDB_TOKEN = \"\" # WandB Token\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# 路径设置, 通常保持默认即可\n",
    "INPUT_DATASET_PATH = \"/kaggle/dataset\" # 训练集保存的路径\n",
    "OUTPUT_PATH = \"/kaggle/working/model\" # 训练时模型保存的路径\n",
    "SD_MODEL_PATH = \"/kaggle/sd-models\" # 模型下载到的路径\n",
    "KAGGLE_INPUT_PATH = \"/kaggle/input\" # Kaggle Input 的路径\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# 训练模型设置, 在安装时将会下载选择的模型\n",
    "# 下面举个例子:\n",
    "# SD_MODEL = [\n",
    "#     [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/v1-5-pruned-emaonly.safetensors\", 0],\n",
    "#     [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/animefull-final-pruned.safetensors\", 1],\n",
    "#     [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/Counterfeit-V3.0_fp16.safetensors\", 0],\n",
    "#     [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v0.1.safetensors\", 1, \"Illustrious.safetensors\"]\n",
    "# ]\n",
    "# \n",
    "# 在这个例子中, 第一个参数指定了模型的下载链接, 第二个参数设置了是否要下载这个模型, 当这个值为 1 时则下载该模型\n",
    "# 第三个参数是可选参数, 用于指定下载到本地后的文件名称\n",
    "# \n",
    "# 则上面的例子中\n",
    "# https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/animefull-final-pruned.safetensors 和 \n",
    "# https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v0.1.safetensors 下载链接所指的文件将被下载\n",
    "# https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/animefull-final-pruned.safetensors 的文件下载到本地后名称为 animefull-final-pruned.safetensors\n",
    "# 并且 https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v0.1.safetensors 所指的文件将被重命名为 Illustrious.safetensors\n",
    "\n",
    "SD_MODEL = [\n",
    "    # Stable Diffusion 模型\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/v1-5-pruned-emaonly.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/animefull-final-pruned.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/Counterfeit-V3.0_fp16.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/cetusMix_Whalefall2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/cuteyukimixAdorable_neochapter3.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/ekmix-pastel-fp16-no-ema.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/ex2K_sse2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/kohakuV5_rev2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/meinamix_meinaV11.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/oukaStar_10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/pastelMixStylizedAnime_pastelMixPrunedFP16.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/rabbit_v6.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/sweetSugarSyndrome_rev15.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/AnythingV5Ink_ink.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/bartstyledbBlueArchiveArtStyleFineTunedModel_v10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/meinapastel_v6Pastel.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/qteamixQ_omegaFp16.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/tmndMix_tmndMixSPRAINBOW.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/sd_xl_base_1.0_0.9vae.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/sd_xl_refiner_1.0_0.9vae.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/sd_xl_turbo_1.0_fp16.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animagine-xl-3.0-base.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animagine-xl-3.0.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animagine-xl-3.1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animagine-xl-4.0.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animagine-xl-4.0-opt.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/holodayo-xl-2.1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kivotos-xl-2.0.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/clandestine-xl-1.0.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/UrangDiffusion-1.1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/RaeDiffusion-XL-v2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/sd_xl_anime_V52.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohaku-xl-delta-rev1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohakuXLEpsilon_rev1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohaku-xl-epsilon-rev2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohaku-xl-epsilon-rev3.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohaku-xl-zeta.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/starryXLV52_v52.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/heartOfAppleXL_v20.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/heartOfAppleXL_v30.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/baxlBartstylexlBlueArchiveFlatCelluloid_xlv1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/baxlBlueArchiveFlatCelluloidStyle_xlv3.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/sanaexlAnimeV10_v10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/sanaexlAnimeV10_v11.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/SanaeXL-Anime-v1.2-aesthetic.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/SanaeXL-Anime-v1.3-aesthetic.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v0.1.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v0.1-GUIDED.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v1.0.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v1.1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/jruTheJourneyRemains_v25XL.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/PVCStyleModelMovable_illustriousxl10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/miaomiaoHarem_v15a.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/waiNSFWIllustrious_v80.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/tIllunai3_v4.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_earlyAccessVersion.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_epsilonPred05Version.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_epsilonPred075.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_epsilonPred077.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_epsilonPred10Version.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_epsilonPred11Version.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPredTestVersion.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred05Version.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred06Version.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred065SVersion.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred075SVersion.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred09RVersion.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred10Version.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/PVCStyleModelMovable_nbxl12.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/PVCStyleModelMovable_nbxlVPredV10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/ponyDiffusionV6XL_v6StartWithThisOne.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/pdForAnime_v20.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/tPonynai3_v51WeightOptimized.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/omegaPonyXLAnime_v20.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animeIllustDiffusion_v061.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/artiwaifuDiffusion_v10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/artiwaifu-diffusion-v2.safetensors\", 0],\n",
    "\n",
    "    # VAE 模型\n",
    "    [\"https://huggingface.co/licyk/sd-vae/resolve/main/sd_1.5/vae-ft-ema-560000-ema-pruned.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-vae/resolve/main/sd_1.5/vae-ft-mse-840000-ema-pruned.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-vae/resolve/main/sdxl_1.0/sdxl_fp16_fix_vae.safetensors\", 1],\n",
    "]\n",
    "\n",
    "##############################################################################\n",
    "echo(\"参数设置完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装环境\n",
    "安装环境和下载模型和训练集, 根据注释的说明进行修改  \n",
    "3. [[← 上一个单元](#参数配置)|[下一个单元 →](#模型训练)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化部分参数并执行安装命令, 这一小部分不需要修改\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "echo(\"初始化 sd-scripts 安装参数\")\n",
    "os.makedirs(WORKSPACE, exist_ok=True)\n",
    "os.chdir(WORKSPACE)\n",
    "sd_scripts = SD_SCRIPTS(WORKSPACE, WORKFOLDER)\n",
    "echo(\"开始安装 sd-scripts\")\n",
    "\n",
    "\n",
    "# 安装 sd-scripts\n",
    "sd_scripts.install(\n",
    "    torch_ver=TORCH_VER,\n",
    "    xformers_ver=XFORMERS_VER,\n",
    "    git_branch=SD_SCRIPTS_BRANCH,\n",
    "    git_commit=SD_SCRIPTS_COMMIT,\n",
    "    model_path=SD_MODEL_PATH,\n",
    "    model_list=SD_MODEL,\n",
    "    use_uv=USE_UV,\n",
    "    pypi_index_mirror=PIP_INDEX_MIRROR,\n",
    "    pypi_extra_index_mirror=PIP_EXTRA_INDEX_MIRROR,\n",
    "    # pypi_find_links_mirror=PIP_FIND_LINKS_MIRROR, # Kaggle 的环境暂不需要以下镜像源\n",
    "    # github_mirror=GITHUB_MIRROR,\n",
    "    # huggingface_mirror=HUGGINGFACE_MIRROR\n",
    "    sd_scripts_repo=SD_SCRIPTS_REPO,\n",
    "    sd_scripts_requirment=SD_SCRIPTS_REQUIREMENT,\n",
    "    retry=3,\n",
    ")\n",
    "# sd_scripts.install() 将会以下几件事\n",
    "# 1. 安装 PyTorch / xFormers\n",
    "# 2. 安装 sd-scripts\n",
    "# 3. 安装 sd-scripts 的依赖\n",
    "# 4. 下载模型\n",
    "# 模型将会下载到 SD_MODEL_PATH 中, 即 /kaggle/sd-models\n",
    "\n",
    "\n",
    "# 根据预设参数创建其他目录\n",
    "echo(\"创建其他目录\")\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True) # 创建训练时保存模型的路径(由 OUTPUT_PATH 变量设定)\n",
    "os.makedirs(INPUT_DATASET_PATH, exist_ok=True) # 创建存放训练集的路径(由 INPUT_DATASET_PATH 变量设定)\n",
    "\n",
    "\n",
    "# 将 KAGGLE_INPUT_PATH 内的文件移动到 INPUT_DATASET_PATH 指定的路径\n",
    "if os.path.exists(KAGGLE_INPUT_PATH) and len(os.listdir(KAGGLE_INPUT_PATH)) > 0:\n",
    "    echo(\"从 Kaggle Input 导入文件中\")\n",
    "    for i in tqdm(os.listdir(KAGGLE_INPUT_PATH), desc=\"Kaggle Input 文件导入\"):\n",
    "        f = os.path.join(KAGGLE_INPUT_PATH, i)\n",
    "        !cp -rf \"{f}\" \"{INPUT_DATASET_PATH}\"\n",
    "# 在 Kaggle 界面右侧中有 Kaggle Input 的功能, 可用于导入训练集 / 模型\n",
    "# 如果使用了 Kaggle Input 导入了训练集 / 模型, 则 KAGGLE_INPUT_PATH 中的所有文件将被复制到 INPUT_DATASET_PATH 中\n",
    "# 即将 /kaggle/input 中的所有文件复制到 /kaggle/dataset 中\n",
    "\n",
    "\n",
    "# 配置 Token 环境变量\n",
    "if HF_TOKEN:\n",
    "    echo(\"为 HuggingFace 配置 HF_TOKEN 环境变量\")\n",
    "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "if MS_TOKEN:\n",
    "    echo(\"为 ModelScope 配置 MODELSCOPE_API_TOKEN 环境变量\")\n",
    "    os.environ[\"MODELSCOPE_API_TOKEN\"] = MS_TOKEN\n",
    "\n",
    "if WANDB_TOKEN:\n",
    "    echo(\"为 WandB 配置 WANDB_API_KEY 环境变量\")\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_TOKEN\n",
    "##########################################################################################\n",
    "# 下方可自行编写命令\n",
    "# 下方的命令示例可以根据自己的需求进行修改\n",
    "\n",
    "\n",
    "##### 1. 关于运行环境 #####\n",
    "\n",
    "# 如果需要安装某个软件包, 可以使用 sd_scripts.py_pkg_manager() 函数\n",
    "# 使用参数:\n",
    "# sd_scripts.py_pkg_manager(\n",
    "#     pkg=\"python packages name\", # Python 软件包名称, 可写多个\n",
    "#     type=\"pip operate type\" ,   # 对 Python 软件包的操作 (install / install_single / force_install / force_install_single / update / uninstall)\n",
    "# )\n",
    "# \n",
    "# 以下是 type 可以指定的操作和对应的命令行参数\n",
    "# 安装: install -> install\n",
    "# 仅安装: install_single -> install --no-deps\n",
    "# 强制重装: force_install -> install --force-reinstall\n",
    "# 仅强制重装: force_install_single -> install --force-reinstall --no-deps\n",
    "# 更新: update -> install --upgrade\n",
    "# 卸载: uninstall -> uninstall -y\n",
    "# \n",
    "# 下面是几个使用例子:\n",
    "# 1.\n",
    "# sd_scripts.py_pkg_manager(\n",
    "#     pkg=\"lycoris-lora==2.1.0.post3 dadaptation==3.1\",\n",
    "#     type=\"install\",\n",
    "# )\n",
    "# 这将安装 lycoris-lora==2.1.0.post3 和 dadaptation==3.1\n",
    "# \n",
    "# 2.\n",
    "# sd_scripts.py_pkg_manager(\n",
    "#     pkg=\"tensorboard\",\n",
    "#     type=\"uninstall\",\n",
    "# )\n",
    "# 这将卸载 tensorboard\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "##### 2. 关于模型导入 #####\n",
    "\n",
    "# 该 Kaggle 训练脚本支持 4 种方式导入模型, 如下:\n",
    "# 1. 使用 Kaggle Input 导入\n",
    "# 2. 使用模型下载链接导入\n",
    "# 3. 从 HuggingFace 仓库导入\n",
    "# 4. 从 ModelScope 仓库导入\n",
    "\n",
    "\n",
    "### 2.1. 使用 Kaggle Input 导入 ###\n",
    "# 在 Kaggle 右侧面板中, 点击 Notebook -> Input -> Upload -> New Model, 从此处导入模型\n",
    "\n",
    "\n",
    "### 2.2 使用模型下载链接导入 ###\n",
    "# 如果需要通过链接下载额外的模型, 可以使用 sd_scripts.get_model()\n",
    "# 使用参数:\n",
    "# sd_scripts.get_model(\n",
    "#     url=\"model_url\",                    # 模型下载链接\n",
    "#     path=SD_MODEL_PATH,                 # 模型下载到本地的路径\n",
    "#     filename=\"filename.safetensors\",    # 模型的名称\n",
    "#     retry=5,                            # 重试下载的次数, 默认为 3\n",
    "# )\n",
    "# \n",
    "# 下面是几个使用例子:\n",
    "# 1.\n",
    "# sd_scripts.get_model(\n",
    "#     url=\"https://modelscope.cn/models/user/repo/resolve/master/your_model.safetensors\",\n",
    "#     path=SD_MODEL_PATH,\n",
    "# )\n",
    "# 这将从 https://modelscope.cn/models/user/repo/resolve/master/your_model.safetensors 下载模型并保存到 SD_MODEL_PATH 中\n",
    "# \n",
    "# sd_scripts.get_model(\n",
    "#     url=\"https://modelscope.cn/models/user/repo/resolve/master/your_model.safetensors\",\n",
    "#     path=SD_MODEL_PATH,\n",
    "#     filename=\"rename_model.safetensors\",\n",
    "# )\n",
    "# 这将从 https://modelscope.cn/models/user/repo/resolve/master/your_model.safetensors 下载模型并保存到 SD_MODEL_PATH 中, 并且重命名为 rename_model.safetensors\n",
    "\n",
    "\n",
    "### 2.3. 从 HuggingFace 仓库导入 ###\n",
    "# 如果需要从 HuggingFace 仓库下载模型, 可以使用 sd_scripts.dataset.get_single_file_from_hf()\n",
    "# 使用参数:\n",
    "# sd_scripts.dataset.get_single_file_from_hf(\n",
    "#     repo_id=\"usename/repo_id\",          # HuggingFace 仓库 ID\n",
    "#     repo_type=\"model\",                  # HuggingFace 仓库种类 (model / dataset / space)\n",
    "#     filename=\"abc/file.safetensors\",    # 文件在 HuggingFace 仓库中的路径\n",
    "#     local_dir=SD_MODEL_PATH,            # 模型下载到本地的路径\n",
    "#     token=\"your_huggingface_token\",     # HuggingFace Token\n",
    "#     retry=5,                            # 重试下载的次数, 默认为 3\n",
    "# )\n",
    "# \n",
    "# 例如要从 stabilityai/stable-diffusion-xl-base-1.0 (类型为 model) 下载 sd_xl_base_1.0_0.9vae.safetensors\n",
    "# sd_scripts.dataset.get_single_file_from_hf(\n",
    "#     repo_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "#     repo_type=\"model\",\n",
    "#     filename=\"sd_xl_base_1.0_0.9vae.safetensors\",\n",
    "#     local_dir=SD_MODEL_PATH,\n",
    "# )\n",
    "# 则上述的命令将会从 stabilityai/stable-diffusion-xl-base-1.0 下载 sd_xl_base_1.0_0.9vae.safetensors 模型\n",
    "# 并将模型保存到 SD_MODEL_PATH 中\n",
    "# 如果仓库的为私有仓库, 需要 HuggingFace Token 才能访问, 则加上 token 参数, 填上自己的 Token (比如是 abcde)\n",
    "# sd_scripts.dataset.get_single_file_from_hf(\n",
    "#     repo_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "#     repo_type=\"model\",\n",
    "#     filename=\"sd_xl_base_1.0_0.9vae.safetensors\",\n",
    "#     local_dir=SD_MODEL_PATH,\n",
    "#     token=\"abcde\",\n",
    "# )\n",
    "# 这样就可以正常从仓库中下载文件\n",
    "\n",
    "\n",
    "### 2.4. 从 ModelScope 仓库导入 ###\n",
    "# 如果需要从 ModelScope 仓库下载模型, 可以使用 sd_scripts.dataset.get_single_file_from_ms()\n",
    "# 使用参数:\n",
    "# sd_scripts.dataset.get_single_file_from_ms(\n",
    "#     repo_id=\"usename/repo_id\",          # ModelScope 仓库 ID\n",
    "#     repo_type=\"model\",                  # ModelScope 仓库种类 (model / dataset / space)\n",
    "#     filename=\"abc/file.safetensors\",    # 文件在 ModelScope 仓库中的路径\n",
    "#     local_dir=SD_MODEL_PATH,            # 模型下载到本地的路径\n",
    "#     token=\"your_modelscope_token\",      # ModelScope Token\n",
    "#     retry=5,                            # 重试下载的次数, 默认为 3\n",
    "# )\n",
    "# \n",
    "# 例如要从 stabilityai/stable-diffusion-xl-base-1.0 (类型为 model) 下载 sd_xl_base_1.0_0.9vae.safetensors\n",
    "# sd_scripts.dataset.get_single_file_from_ms(\n",
    "#     repo_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "#     repo_type=\"model\",\n",
    "#     filename=\"sd_xl_base_1.0_0.9vae.safetensors\",\n",
    "#     local_dir=SD_MODEL_PATH,\n",
    "# )\n",
    "# 则上述的命令将会从 stabilityai/stable-diffusion-xl-base-1.0 下载 sd_xl_base_1.0_0.9vae.safetensors 模型\n",
    "# 并将模型保存到 SD_MODEL_PATH 中\n",
    "# 如果仓库的为私有仓库, 需要 ModelScope Token 才能访问, 则加上 token 参数, 填上自己的 Token (比如是 abcde)\n",
    "# sd_scripts.dataset.get_single_file_from_ms(\n",
    "#     repo_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "#     repo_type=\"model\",\n",
    "#     filename=\"sd_xl_base_1.0_0.9vae.safetensors\",\n",
    "#     local_dir=SD_MODEL_PATH,\n",
    "#     token=\"abcde\",\n",
    "# )\n",
    "# 这样就可以正常从仓库中下载文件\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "##### 3. 关于训练集导入 #####\n",
    "\n",
    "# 该 Kaggle 训练脚本支持 4 种方式导入训练集, 如下:\n",
    "# 1. 使用 Kaggle Input 导入\n",
    "# 2. 使用训练集下载链接导入\n",
    "# 3. 从 HuggingFace 仓库导入\n",
    "# 4. 从 ModelScope 仓库导入\n",
    "\n",
    "\n",
    "### 3.1. 使用 Kaggle Input 导入 ###\n",
    "# 在 Kaggle 右侧面板中, 点击 Notebook -> Input -> Upload -> New Dataset, 从此处导入模型\n",
    "\n",
    "\n",
    "### 3.2. 使用训练集下载链接导入 ###\n",
    "# 如果将训练集压缩后保存在某个平台, 如 HuggingFace, ModelScope, 并且有下载链接, 可以使用 sd_scripts.dataset.get_dataset() 函数下载训练集\n",
    "# 使用参数:\n",
    "# sd_scripts.dataset.get_dataset(\n",
    "#     dataset_path=\"path_to_local\",   # 下载数据集到本地的路径\n",
    "#     url=\"download_url\",             # 训练集压缩包的下载链接\n",
    "#     name=\"filename.zip\",            # 将数据集压缩包进行重命名\n",
    "#     retry=5,                        # 重试下载的次数, 默认为 3\n",
    "# )\n",
    "# \n",
    "# 该函数在下载训练集压缩包完成后将解压到指定的本地路径\n",
    "# 压缩包格式仅支持 7z, zip, tar\n",
    "# \n",
    "# 下面是几个使用的例子:\n",
    "# 1.\n",
    "# sd_scripts.dataset.get_dataset(\n",
    "#     dataset_path=INPUT_DATASET_PATH,\n",
    "#     url=\"https://modelscope.cn/models/user/repo/resolve/master/data_1.7z\",\n",
    "# )\n",
    "# 这将从 https://modelscope.cn/models/user/repo/resolve/master/data_1.7z 下载训练集压缩包并解压到 INPUT_DATASET_PATH 中\n",
    "# \n",
    "# 2.\n",
    "# sd_scripts.dataset.get_dataset(\n",
    "#     dataset_path=INPUT_DATASET_PATH,\n",
    "#     url=\"https://modelscope.cn/models/user/repo/resolve/master/data_1.7z\",\n",
    "#     name=\"training_dataset.7z\",\n",
    "# )\n",
    "# 这将从 https://modelscope.cn/models/user/repo/resolve/master/data_1.7z 下载训练集压缩包并重命名成 training_dataset.7z\n",
    "# 再将 training_dataset.7z 中的文件解压到 INPUT_DATASET_PATH 中\n",
    "# \n",
    "# \n",
    "# 训练集的要求:\n",
    "# 需要将图片进行打标, 并调整训练集为指定的目结构, 例如:\n",
    "# Nachoneko\n",
    "#     └── 1_nachoneko\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "#             ├── 0(8).txt\n",
    "#             ├── 0(8).webp\n",
    "#             ├── 001_2.png\n",
    "#             ├── 001_2.txt\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "#             ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "#             └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "# \n",
    "# 在 Nachoneko 文件夹新建一个文件夹, 格式为 <数字>_<名称>, 如 1_nachoneko, 前面的数字代表这部分的训练集的重复次数, 1_nachoneko 文件夹内则放图片和打标文件\n",
    "# \n",
    "# 训练集也可以分成多个部分组成, 例如:\n",
    "# Nachoneko\n",
    "#     ├── 1_nachoneko\n",
    "#     │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "#     │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "#     │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "#     │       └── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "#     ├── 2_nachoneko\n",
    "#     │       ├── 0(8).txt\n",
    "#     │       ├── 0(8).webp\n",
    "#     │       ├── 001_2.png\n",
    "#     │       └── 001_2.txt\n",
    "#     └── 4_nachoneko\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "#             ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "#             └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "# \n",
    "# 处理好训练集并调整好目录结构后可以将 Nachoneko 文件夹进行压缩了, 使用 zip / 7z / tar 格式进行压缩\n",
    "# 例如将上述的训练集压缩成 Nachoneko.7z, 此时需要检查一下压缩后在压缩包的目录结果是否和原来的一致(有些压缩软件在部分情况下会破坏原来的目录结构)\n",
    "# 确认没有问题后将该训练集上传到网盘, 推荐使用 HuggingFace / ModelScope\n",
    "\n",
    "\n",
    "### 3.3. 从 HuggingFace 仓库导入 ###\n",
    "# 如果训练集保存在 HuggingFace, 可以使用 sd_scripts.dataset.get_dataset_from_hf() 函数从 HuggingFace 下载数据集\n",
    "# 使用格式:\n",
    "# sd_scripts.dataset.get_dataset_from_hf(\n",
    "#     local_path=INPUT_DATASET_PATH,    # 下载数据集到哪个路径\n",
    "#     repo_id=\"username/train_data\",    # HuggingFace 仓库 ID\n",
    "#     repo_type=\"dataset\",              # HuggingFace 仓库的类型 (model / dataset / space)\n",
    "#     folder=\"folder_in_repo\",          # 指定要从 HuggingFace 仓库里下载哪个文件夹的内容\n",
    "#     hf_token=\"hf_token\",              # HuggingFace Token, 用于访问私有仓库\n",
    "#     retry=5,                          # 重试下载的次数, 默认为 3\n",
    "# )\n",
    "# \n",
    "# 比如在 HuggingFace 的仓库为 username/train_data, 仓库类型为 dataset\n",
    "# 仓库的文件结构如下:\n",
    "# ├── Nachoneko\n",
    "# │   ├── 1_nachoneko\n",
    "# │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "# │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "# │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "# │   │       └── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "# │   ├── 2_nachoneko\n",
    "# │   │       ├── 0(8).txt\n",
    "# │   │       ├── 0(8).webp\n",
    "# │   │       ├── 001_2.png\n",
    "# │   │       └── 001_2.txt\n",
    "# │   └── 4_nachoneko\n",
    "# │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "# │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "# │           ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "# │           └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "# └ aaaki\n",
    "#   ├── 1_aaaki\n",
    "#   │   ├── 1.png\n",
    "#   │   ├── 1.txt\n",
    "#   │   ├── 11.png\n",
    "#   │   ├── 11.txt\n",
    "#   │   ├── 12.png\n",
    "#   │   └── 12.txt\n",
    "#   └── 3_aaaki\n",
    "#       ├── 14.png\n",
    "#       ├── 14.txt\n",
    "#       ├── 16.png\n",
    "#       └── 16.txt\n",
    "#\n",
    "# 此时想要下载这个仓库中的 Nachoneko 文件夹的内容, 则下载命令为\n",
    "# sd_scripts.dataset.get_dataset_from_hf(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     folder=\"Nachoneko\",\n",
    "# )\n",
    "# \n",
    "# 如果想下载整个仓库, 则命令修改为\n",
    "# sd_scripts.dataset.get_dataset_from_hf(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "# )\n",
    "# \n",
    "# 如果仓库为私有仓库, 需要使用 HuggingFace Token 进行访问 \n",
    "# sd_scripts.dataset.get_dataset_from_hf(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     hf_token=\"xxxxxxx\",\n",
    "# )\n",
    "# \n",
    "# 既是私有仓库, 又需要下载里面的某个文件夹中的内容, 则命令修改为\n",
    "# sd_scripts.dataset.get_dataset_from_hf(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     folder=\"Nachoneko\",\n",
    "#     hf_token=\"xxxxxxx\",\n",
    "# )\n",
    "\n",
    "\n",
    "# 4. 从 ModelScope 仓库导入\n",
    "# 如果训练集保存在 ModelScope, 可以使用 sd_scripts.dataset.get_dataset_from_ms() 函数从 ModelScope 下载数据集\n",
    "# 使用格式:\n",
    "# sd_scripts.dataset.get_dataset_from_ms(\n",
    "#     local_path=INPUT_DATASET_PATH,  # 下载数据集到哪个路径\n",
    "#     repo_id=\"usename/repo_id\",      # ModelScope 仓库 ID\n",
    "#     repo_type=\"model\",              # ModelScope 仓库的类型 (model / dataset / space)\n",
    "#     folder=\"folder_in_repo\",        # 指定要从 ModelScope 仓库里下载哪个文件夹的内容\n",
    "#     ms_token=\"ms_token\",            # ModelScope Token, 用于访问私有仓库\n",
    "#     retry=5,                        # 重试下载的次数, 默认为 3\n",
    "# )\n",
    "# \n",
    "# 比如在 ModelScope 的仓库为 username/train_data, 仓库类型为 dataset\n",
    "# 仓库的文件结构如下:\n",
    "# ├── Nachoneko\n",
    "# │   ├── 1_nachoneko\n",
    "# │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "# │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "# │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "# │   │       └── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "# │   ├── 2_nachoneko\n",
    "# │   │       ├── 0(8).txt\n",
    "# │   │       ├── 0(8).webp\n",
    "# │   │       ├── 001_2.png\n",
    "# │   │       └── 001_2.txt\n",
    "# │   └── 4_nachoneko\n",
    "# │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "# │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "# │           ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "# │           └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "# └ aaaki\n",
    "#   ├── 1_aaaki\n",
    "#   │   ├── 1.png\n",
    "#   │   ├── 1.txt\n",
    "#   │   ├── 11.png\n",
    "#   │   ├── 11.txt\n",
    "#   │   ├── 12.png\n",
    "#   │   └── 12.txt\n",
    "#   └── 3_aaaki\n",
    "#       ├── 14.png\n",
    "#       ├── 14.txt\n",
    "#       ├── 16.png\n",
    "#       └── 16.txt\n",
    "#\n",
    "# 此时想要下载这个仓库中的 Nachoneko 文件夹的内容, 则下载命令为\n",
    "# sd_scripts.dataset.get_dataset_from_ms(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     folder=\"Nachoneko\",\n",
    "# )\n",
    "# \n",
    "# 如果想下载整个仓库, 则命令修改为\n",
    "# sd_scripts.dataset.get_dataset_from_ms(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "# )\n",
    "# \n",
    "# 如果仓库为私有仓库, 需要使用 HuggingFace Token 进行访问 \n",
    "# sd_scripts.dataset.get_dataset_from_ms(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     ms_token=\"xxxxxxx\",\n",
    "# )\n",
    "# \n",
    "# 既是私有仓库, 又需要下载里面的某个文件夹中的内容, 则命令修改为\n",
    "# sd_scripts.dataset.get_dataset_from_ms(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     folder=\"Nachoneko\",\n",
    "#     ms_token=\"xxxxxxx\",\n",
    "# )\n",
    "\n",
    "\n",
    "# 下载训练集的技巧\n",
    "# 如果有个 character_aaaki 训练集上传到 HuggingFace 上时结构如下：\n",
    "# \n",
    "#\n",
    "# HuggingFace_Repo (licyk/sd_training_dataset)\n",
    "# ├── character_aaaki\n",
    "# │   ├── 1_aaaki\n",
    "# │   │   ├── 1.png\n",
    "# │   │   ├── 1.txt\n",
    "# │   │   ├── 3.png\n",
    "# │   │   └── 3.txt\n",
    "# │   └── 2_aaaki\n",
    "# │       ├── 4.png\n",
    "# │       └── 4.txt\n",
    "# ├── character_robin\n",
    "# │   └── 1_xxx\n",
    "# │       ├── 11.png\n",
    "# │       └── 11.txt\n",
    "# └── style_pvc\n",
    "#     └── 5_aaa\n",
    "#         ├── test.png\n",
    "#         └── test.txt\n",
    "#\n",
    "# \n",
    "# 可能有时候不想为训练集中每个子训练集设置不同的重复次数，又不想上传的时候再多套一层文件夹，就把训练集结构调整成了下面的：\n",
    "# \n",
    "#\n",
    "# HuggingFace_Repo (licyk/sd_training_dataset)\n",
    "# ├── character_aaaki\n",
    "# │   ├── 1.png\n",
    "# │   ├── 1.txt\n",
    "# │   ├── 3.png\n",
    "# │   ├── 3.txt\n",
    "# │   ├── 4.png\n",
    "# │   └── 4.txt\n",
    "# ├── character_robin\n",
    "# │   └── 1_xxx\n",
    "# │       ├── 11.png\n",
    "# │       └── 11.txt\n",
    "# └── style_pvc\n",
    "#     └── 5_aaa\n",
    "#         ├── test.png\n",
    "#         └── test.txt\n",
    "#\n",
    "# \n",
    "# 此时这个状态的训练集是缺少子训练集和重复次数的，如果直接使用 sd_scripts.dataset.get_dataset_from_hf() 去下载训练集并用于训练将会导致报错\n",
    "# 不过可以自己再编写一个函数对 sd_scripts.dataset.get_dataset_from_hf() 函数再次封装，自动加上子训练集并设置重复次数\n",
    "# \n",
    "#\n",
    "# def make_dataset(\n",
    "#     local_path: Union[str, Path],\n",
    "#     repo_id: str,\n",
    "#     repo_type: str,\n",
    "#     repeat: int,\n",
    "#     folder: str,\n",
    "#     hf_token: Optional[str] = None\n",
    "# ) -> None:\n",
    "#     import os\n",
    "#     import shutil\n",
    "#     origin_dataset_path = os.path.join(local_path, folder)\n",
    "#     tmp_dataset_path = os.path.join(local_path, f\"{repeat}_{folder}\")\n",
    "#     new_dataset_path = os.path.join(origin_dataset_path, f\"{repeat}_{folder}\")\n",
    "#     sd_scripts.dataset.get_dataset_from_hf(\n",
    "#         local_path=local_path,\n",
    "#         repo_id=repo_id,\n",
    "#         repo_type=repo_type,\n",
    "#         folder=folder,\n",
    "#         hf_token=hf_token\n",
    "#     )\n",
    "#     if os.path.exists(origin_dataset_path):\n",
    "#         echo(f\"设置 {folder} 训练集的重复次数为 {repeat}\")\n",
    "#         shutil.move(origin_dataset_path, tmp_dataset_path)\n",
    "#         shutil.move(tmp_dataset_path, new_dataset_path)\n",
    "#     else:\n",
    "#         echo(f\"从 {repo_id} 下载 {folder} 失败\")\n",
    "#\n",
    "# \n",
    "# 编写好后，可以去调用这个函数\n",
    "# \n",
    "#\n",
    "# make_dataset(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"licyk/sd_training_dataset\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     repeat=3,\n",
    "#     folder=\"character_aaaki\",\n",
    "#     hf_token=HF_TOKEN,\n",
    "# )\n",
    "#\n",
    "# \n",
    "# 该函数将会把 character_aaaki 训练集下载到 {INPUT_DATASET_PATH} 中，即 /kaggle/dataset\n",
    "# 文件夹名称为 character_aaaki，并且 character_aaaki 文件夹内继续创建了一个子文件夹作为子训练集，根据 repeat=3 将子训练集的重复次数设置为 3\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# sd_scripts.clear_up() # 清理输出\n",
    "echo(\"sd-scripts 安装完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "需自行编写命令，下方有可参考的例子  \n",
    "4. [[← 上一个单元](#安装环境)|[下一个单元 →](#模型上传)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo(\"进入 sd-scripts 目录\")\n",
    "os.chdir(SD_SCRIPTS_PATH)\n",
    "print(\"=\" * 50)\n",
    "echo(\"训练集目录中的文件列表\")\n",
    "if os.path.exists(INPUT_DATASET_PATH):\n",
    "    print(f\"训练集路径: {INPUT_DATASET_PATH}\")\n",
    "    for i in os.listdir(INPUT_DATASET_PATH):\n",
    "        print(f\":: {i}\")\n",
    "print(\"=\" * 50)\n",
    "echo(\"模型目录中的文件列表\")\n",
    "if os.path.exists(SD_MODEL_PATH):\n",
    "    print(f\"模型路径: {SD_MODEL_PATH}\")\n",
    "    for i in os.listdir(SD_MODEL_PATH):\n",
    "        print(f\":: {i}\")\n",
    "print(\"=\" * 50)\n",
    "echo(\"使用 sd-scripts 进行模型训练\")\n",
    "##########################################################################################\n",
    "# 1.\n",
    "# 运行前需要根据自己的需求更改参数\n",
    "# \n",
    "# 训练参数的设置可参考：\n",
    "# https://rentry.org/59xed3\n",
    "# https://github.com/kohya-ss/sd-scripts?tab=readme-ov-file#links-to-usage-documentation\n",
    "# https://github.com/bmaltais/kohya_ss/wiki/LoRA-training-parameters\n",
    "# \n",
    "# \n",
    "# 2.\n",
    "# 下方被注释的代码选择后使用 Ctrl + / 取消注释\n",
    "# \n",
    "# \n",
    "# 3.\n",
    "# 训练使用的底模会被下载到 SD_MODEL_PATH, 即 /kaggle/sd-models\n",
    "# 填写底模路径时一般可以通过 --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/base_model.safetensors\" 指定\n",
    "# 如果需要外挂 VAE 模型可以通过 --vae=\"{SD_MODEL_PATH}/vae.safetensors\" 指定\n",
    "# \n",
    "# 通过 Kaggle Inout 导入的训练集保存在 KAGGLE_INPUT_PATH, 即 /kaggle/input, 运行该笔记时将会把训练集复制进 INPUT_DATASET_PATH, 即 /kaggle/dataset\n",
    "# 该路径可通过 INPUT_DATASET_PATH 调整\n",
    "# 如果使用 sd_scripts.dataset.get_dataset() 函数下载训练集, 数据集一般会解压到 INPUT_DATASET_PATH, 这取决于函数第一个参数传入的路径\n",
    "# 训练集的路径通常要这种结构\n",
    "# $ tree /kaggle\n",
    "# kaggle\n",
    "# └── dataset\n",
    "#     └── Nachoneko\n",
    "#         └── 1_gan_cheng\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "#             ├── 0(8).txt\n",
    "#             ├── 0(8).webp\n",
    "#             ├── 001_2.png\n",
    "#             ├── 001_2.txt\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "#             ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "#             └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "# 4 directories, 12 files\n",
    "# 在填写训练集路径时, 应使用 --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\"\n",
    "# \n",
    "# 模型保存的路径通常用 --output_dir=\"{OUTPUT_PATH}\" 指定, 如 --output_dir=\"{OUTPUT_PATH}/Nachoneko\", OUTPUT_PATH 默认设置为 /kaggle/working/model\n",
    "# 在 Kaggle 的 Output 中可以看到保存的模型, 前提是使用 Kaggle 的 Save Version 运行 Kaggle\n",
    "# OUTPUT_PATH 也指定了保存模型到 HuggingFace / ModelScope 的功能的上传路径\n",
    "# \n",
    "# --output_name 用于指定保存的模型名字, 如 --output_name=\"Nachoneko\"\n",
    "# \n",
    "# \n",
    "# 4.\n",
    "# Kaggle 的实例最长可运行 12 h, 要注意训练时长不要超过 12 h, 否则将导致训练被意外中断, 并且最后的模型保存功能将不会得到运行\n",
    "# 如果需要在模型被保存后立即上传到 HuggingFace 进行保存, 可使用启动参数为 sd-scripts 设置自动保存, 具体可阅读 sd-scripts 的帮助信息\n",
    "# 使用 python train_network.py -h 命令可查询可使用的启动参数, 命令中的 train_network.py 可替换成 sdxl_train_network.py 等\n",
    "# \n",
    "# \n",
    "# 5.\n",
    "# 训练命令的开头为英文的感叹号, 也就是 !, 后面就是 Shell Script 风格的命令\n",
    "# 每行的最后为反斜杠用于换行, 也就是用 \\ 来换行, 并且反斜杠的后面不允许有其他符号, 比如空格等\n",
    "# 训练命令的每一行之间不能有任何换行空出来, 最后一行不需要反斜杠, 因为最后一行的下一行已经没有训练参数\n",
    "# \n",
    "# \n",
    "# 6.\n",
    "# 如果训练参数是 toml 格式的, 比如从 Akegarasu/lora-scripts 训练器复制来的训练参数\n",
    "# 可以转换成对应的训练命令中的参数\n",
    "# 下面列举几种转换例子:\n",
    "# \n",
    "# (1)\n",
    "# toml 格式:\n",
    "# pretrained_model_name_or_path = \"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\"\n",
    "# 训练命令格式:\n",
    "# --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\"\n",
    "# \n",
    "# (2)\n",
    "# toml 格式:\n",
    "# unet_lr = 0.0001\n",
    "# 训练命令格式:\n",
    "# --unet_lr=0.0001\n",
    "# \n",
    "# (3)\n",
    "# toml 格式:\n",
    "# network_args = [\n",
    "#     \"conv_dim=100000\",\n",
    "#     \"conv_alpha=100000\",\n",
    "#     \"algo=lokr\",\n",
    "#     \"dropout=0\",\n",
    "#     \"factor=8\",\n",
    "#     \"train_norm=True\",\n",
    "#     \"preset=full\",\n",
    "# ]\n",
    "# 训练命令格式:\n",
    "# --network_args \\\n",
    "#     conv_dim=100000 \\\n",
    "#     conv_alpha=100000 \\\n",
    "#     algo=lokr \\\n",
    "#     dropout=0 \\\n",
    "#     factor=8 \\\n",
    "#     train_norm=True \\\n",
    "#     preset=full \\\n",
    "# \n",
    "# (4)\n",
    "# toml 格式:\n",
    "# enable_bucket = true\n",
    "# 训练命令格式:\n",
    "# --enable_bucket\n",
    "# \n",
    "# (5)\n",
    "# toml 格式:\n",
    "# lowram = false\n",
    "# 训练命令格式:\n",
    "# 无对应的训练命令, 也就是不需要填, 因为这个参数的值为 false, 也就是无对应的参数, 如果值为 true, 则对应训练命令中的 --lowram\n",
    "# \n",
    "# 可以根据这个例子去转换 toml 格式的训练参数成训练命令的格式\n",
    "# \n",
    "# \n",
    "# 7.\n",
    "# 如果需要 toml 格式的配置文件来配置训练参数可以使用下面的代码来保存 toml 格式的训练参数\n",
    "# \n",
    "# toml_file_path = os.path.join(WORKSPACE, \"train_config.toml\")\n",
    "# toml_content = f\"\"\"\n",
    "# 这里使用 toml 格式编写训练参数, \n",
    "# 还可以结合 Python F-Strings 的用法使用前面配置好的变量\n",
    "# Python F-Strings 的说明: https://docs.python.org/zh-cn/3.13/reference/lexical_analysis.html#f-strings\n",
    "# toml 的语法可参考: https://toml.io/cn/v1.0.0\n",
    "# 下面展示训练命令里参数对应的 toml 格式转换\n",
    "# \n",
    "# \n",
    "# pretrained_model_name_or_path = \"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\"\n",
    "# 对应训练命令中的 --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\"\n",
    "# \n",
    "# unet_lr = 0.0001\n",
    "# 对应训练命令中的 --unet_lr=0.0001\n",
    "# \n",
    "# network_args = [\n",
    "#     \"conv_dim=100000\",\n",
    "#     \"conv_alpha=100000\",\n",
    "#     \"algo=lokr\",\n",
    "#     \"dropout=0\",\n",
    "#     \"factor=8\",\n",
    "#     \"train_norm=True\",\n",
    "#     \"preset=full\",\n",
    "# ]\n",
    "# 对应下面训练命令中的\n",
    "# --network_args \\\n",
    "#     conv_dim=100000 \\\n",
    "#     conv_alpha=100000 \\\n",
    "#     algo=lokr \\\n",
    "#     dropout=0 \\\n",
    "#     factor=8 \\\n",
    "#     train_norm=True \\\n",
    "#     preset=full \\\n",
    "# \n",
    "# enable_bucket = true\n",
    "# 对应训练命令中的 --enable_bucket\n",
    "# \n",
    "# lowram = false\n",
    "# 这个参数的值为 false, 也就是无对应的参数, 如果值为 true, 则对应训练命令中的 --lowram\n",
    "# \"\"\".strip()\n",
    "# if not os.path.exists(os.path.dirname(toml_file_path)):\n",
    "#     os.makedirs(toml_file_path, exist_ok=True)\n",
    "# with open(toml_file_path, \"w\", encoding=\"utf8\") as file:\n",
    "#     file.write(toml_content)\n",
    "# \n",
    "# 使用上面的代码将会把训练参数的 toml 配置文件保存在 toml_file_path 路径中, 也就是 {WORKSPACE}/train_config.toml, 即 /kaggle/train_config.toml\n",
    "# 而原来的训练命令无需再写上训练参数, 只需指定该训练配置文件的路径即可\n",
    "# 使用 --config_file=\"{WORKSPACE}/train_config.toml\" 来指定\n",
    "# \n",
    "# \n",
    "# 8. \n",
    "# 如果要查看 sd-script 的命令行参数, 可以加上 -h 后再运行, 此时 sd-script 将显示所有可用的参数\n",
    "# \n",
    "# \n",
    "# 9.\n",
    "# 下方提供了一些训练参数, 可以直接使用, 使用时取消注释后根据需求修改部分参数即可\n",
    "# \n",
    "#              .,@@@@@@@@@].                                          ./@[`....`[\\\\.                 \n",
    "#             //\\`..  . ...,\\@].       .,]]]/O@@@@@@@@\\]...       .,]//............\\@`               \n",
    "#           .O`........ .......\\\\.]]@@@@@@@@[..........,[@@@@\\`.*/....=^............/@@`             \n",
    "#          .O........    .......@@/@@@/`.....               . ,\\@\\....\\`............O@`@             \n",
    "#          =^...`....          .O@@`.........            .........\\@`...[`.,@`....,@^/.@^            \n",
    "#         .OO`..\\....          =/..... ......            ..[@]....,\\@@]]]].@@]`..//..@=\\^            \n",
    "#          @O/@`,............=O/......    ...   ....       ...\\\\.....,@@@`=\\@\\@@[...=O`/^.           \n",
    "#          @@\\.,@]..]]//[,/@^O=@.............   .\\@^...........,@`.....\\@@/*\\o*O@\\.=/.@`             \n",
    "#          ,@/O`...[OOO`.,@O,\\/....././\\^....   ..@O` ..\\`.......=\\.....=\\\\@@@@@/\\@@//               \n",
    "#            ,@`\\].......O^o,/.....@`/=^.....,\\...,@^ ...=\\...    =\\.....,@,@@@@[/@@@/               \n",
    "#            ..,\\@\\]]]]O/@.*@.....=^/\\^......=@....\\O..^..@@`..  ..\\@.....,@.\\@@\\[[O`                \n",
    "#                .*=@@\\@@^.O^...../o^O.......O=^...=@..@..\\.\\\\.   . @@`....,@.\\@@@@`                 \n",
    "# .              ..=@O^=@`,@ .....@@=`......=^.O....@..@^.=^.=@.....=@@.....,\\.\\@@@@.                \n",
    "#                .,@@`,O@./^.....=@O/......./^.O... \\`.=^.=^..=@...  O=\\.....=^.\\@@@@`.              \n",
    "#                ./@`.=^@=@......=@O`....@,/@@.=^...=^.=^.=^.[[\\@....=^\\^.....@@.\\@@@@`              \n",
    "#               .,@^. @^O/@......=@O.]O`OO.=`\\^.....,^.=@.=^....=@...=\\.O.....@^\\`@@/`               \n",
    "#                =@ .=@..@^ .....=@/.../@^,/.=@......* =@.=^.....=\\..=@`=^....=^ \\/\\                 \n",
    "#                /^..=@.,@^ /`...=@.../O@.O...@........O=^=` ,`...@^.=@\\=^..] =@..@O`.               \n",
    "#               ,@...@/.=@. @^...=@../@\\@/OOO.=^......=^,O@[.]]@\\]/@ =^@`O..O.=@^ =@^                \n",
    "#               =^...@@.=@..O\\....@ //.O@O@@]..@....../^.OO@@@[[@@@@\\/^@^O .O.=@@ .@^                \n",
    "#               @^..=@@.,@.=^@....@@\\@@@[[[[[[[\\^@^..,/..O..,@@@\\..=@@//OO..O./^@. =@                \n",
    "#               @...=^@^.@.=^=^...=@@`/@@@@@`...*O\\..@...[.=@`,@@@`.@`=^@=`.O.@.@. =@.               \n",
    "#               @^..O.@^ \\^=@,\\..=@@ @\\,@@/@@`..=^..@`.....@@\\@@/@@...O.@=^,O=^.@^./@                \n",
    "#               @@..O.=@.,\\=@^O..=`\\/@^/@@OO@^..,`,O`.. .. @@/@@\\@@..=`=@../^O..@^/O^                \n",
    "#              .=@^ @..@`=@o@@=^..,.O@@/@@oO@........... ...@^.\\/@..=^=@/ =@O. .@\\@`.                \n",
    "#               .@@.@^.@^@^\\@@O^..=^,O@@*.................  .......=^/@@^=@@^ .=@`.                  \n",
    "#               .=O@O^,@^=^.\\@^o..=/\\,\\ .....   .... .....    ...]@O`=@O/@@^   =@                    \n",
    "#                .=O@O/^==@@`O@O^.=@.\\`\\`....      .  ........ ......//@.@`.   =^                    \n",
    "#                  ,O@@^.O..\\@@@^.=@...[O@`..      .  ........ .....//.@@,\\   .@^                    \n",
    "#                   .@/@@@]../@@^..@@\\........     ..,/`=@/@`.....,@^..=^ =` .=@.                    \n",
    "#                   =/..O... @^=\\. O@@@@\\....... ...//.,@..@O].,/@`=\\..=@..@..@^                     \n",
    "#                  ,/..O....=/=/@ .=@@@@@@@@].....//.,O@`.//.@@@@@..@^..@`.=\\/O`.                    \n",
    "#                 ,@../`....O=/.@...@@@@@@@@@@@@@/../\\@..//.=@@@@\\. @@..=\\..@^/.                     \n",
    "#                ,@`.=`....=@/..@...\\@@@@@@@@.. O..,@/..=@ .O=@@@^. @/@..@^..@`.                     \n",
    "#               ,@`.=^....,@/..=O^..,@@.[@@@@,@]@../^..=@../^=@@@...@.,\\.=@`..@`                     \n",
    "#              ,@..=/.   .@/...O=@...@@....,@@...,[@\\.,@`..@..@@/..,@..,\\.@@...@..                   \n",
    "#              @`.,/.....@/...=`O@^..,@...../`.......,\\@]..@..O@\\]]/\\`..,\\,@^..,@`                   \n",
    "#             =^..@...../@...,^/O@@...=@`...@............\\@` /`,\\,@`.=\\.,\\@=@`..,@.                  \n",
    "#            ,@../`....@\\`/@``,`]/@^...O,\\/\\@]..............\\\\..=@`\\\\ ,@@@@@@@....@`.                \n",
    "#            O`.=^....@^O@^.@@@@@@@\\....\\@^=@@@@@\\] ..........,@`\\@\\.@`=@@@@@@\\....@`..              \n",
    "#           =/..O...,@O/@^.@@@@@@@@@`...=/.@@@@@@@@@@@].........,@@/@`,@/@@@@O\\^....@`..             \n",
    "#           /^.O.../@O^@^./@@@@@@@@@\\...@`=@@@@@@@@@@@@@\\.......@`=\\//@`,@@@@@.@`....\\`...           \n",
    "#         .,@.=^../`@@\\@.=@@@@@@@@@@@^.=@.@@@@@@@@@@@@@@@@@`...@` =\\\\==`@`\\@@@^.@.....\\^...          \n",
    "#       ../\\^,@.,/.=@/=/,@@@@@@@@@@@@\\ @^=@@@@@@@@@@@@@@@@@@@]@@@@@@@@@o\\@`.@@\\.,@.....\\\\...         \n",
    "#       =/.@^@`/`..@@^@^=@@@@@@@@@@@@@\\@.@@@@@@@@@@@@@@@@@@@@@@@@O@@@@@\\/.,/.@@\\.,@.....,@`..        \n",
    "#     ,O`.,@=@/...=@@.@^O@@@@@@@@@@@@@@^=@@@@@@@@@@@@@@@@@@@@@@@@@@O@@@^ /@@.,@/@`.@`.....\\\\...      \n",
    "#  ..=^...=^@^....@OO,@^/@@@@@@@@@@@@\\@.@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\\@@@@@`=\\.\\^.\\`.....,@`..    \n",
    "# \n",
    "# 炼丹就不存在什么万能参数的, 可能下面给的参数里有的参数训练出来的效果很好, 有的效果就一般\n",
    "# 训练参数还看训练集呢, 同一套参数在不同训练集上效果都不一样, 可能好可能坏 (唉, 被这训练参数折磨过好多次)\n",
    "# 虽然说一直用同个效果不错的参数可能不会出现特别坏的结果吧\n",
    "# 还有好的训练集远比好的训练参数更重要\n",
    "# 好的训练集真的, 真的, 真的非常重要\n",
    "# 再好的参数, 训练集烂也救不回来\n",
    "# \n",
    "# \n",
    "# 10.\n",
    "# 建议先改改训练集路径的参数就开始训练, 跑通训练了再试着改其他参数\n",
    "# 还有我编写的训练参数不一定是最好的, 所以需要自己去摸索这些训练参数是什么作用的, 再去修改\n",
    "# 其实有些参数我自己也调不明白, 但是很多时候跑出来效果还不错\n",
    "# 为什么效果好, 分からない, 这东西像个黑盒, 有时候就觉得神奇呢\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数在 animagine-xl-3.1.safetensors 测试, 大概在 30 ~ 40 Epoch 有比较好的效果 (在 36 Epoch 出好效果的概率比较高)\n",
    "#\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animagine-xl-3.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=50 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "#\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 在 --network_args 设置了 preset，可以调整训练网络的大小\n",
    "# 该值默认为 full，而使用 attn-mlp 可以得到更小的 LoRA 但几乎不影响 LoRA 效果\n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#         preset=\"attn-mlp\" \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 在 --network_args 设置了 preset，可以调整训练网络的大小\n",
    "# 该值默认为 full，而使用 attn-mlp 可以得到更小的 LoRA 但几乎不影响 LoRA 效果\n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# 使用 --optimizer_args 设置 weight_decay 和 betas, 更高的 weight_decay 可以降低拟合程度, 减少过拟合\n",
    "# 如果拟合程度不够高, 可以提高 --max_train_epochs 的值, 或者适当降低 weight_decay 的值, 可自行测试\n",
    "# 较小的训练集适合使用较小的值, 如 0.05, 较大的训练集适合用 0.1\n",
    "# 当 weight_decay 设置为 0.05 时, 大概在 38 Epoch 有比较好的效果\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#         preset=\"attn-mlp\" \\\n",
    "#     --optimizer_args \\\n",
    "#         weight_decay=0.1 \\\n",
    "#         betas=\"0.9,0.95\" \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# (自己在用的)\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "# \n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 在 --network_args 设置了 preset, 可以调整训练网络的大小\n",
    "# 该值默认为 full, 如果使用 attn-mlp 可以得到更小的 LoRA, 但对于难学的概念使用 full 效果会更好\n",
    "# \n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# 使用 --optimizer_args 设置 weight_decay 和 betas, 更高的 weight_decay 可以降低拟合程度, 减少过拟合\n",
    "# 如果拟合程度不够高, 可以提高 --max_train_epochs 的值, 或者适当降低 weight_decay 的值, 可自行测试\n",
    "# 较小的训练集适合使用较小的值, 如 0.05, 较大的训练集适合用 0.1\n",
    "# 大概 34 Epoch 会有比较好的效果吧, 不过不好说, 看训练集\n",
    "# 自己测的时候大概在 26~40 Epoch 之间会出现好结果, 测试了很多炉基本都在这个区间里, 但也不排除意外情况 (训练参数这东西好麻烦啊, 苦い)\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#         preset=\"full\" \\\n",
    "#     --optimizer_args \\\n",
    "#         weight_decay=0.05 \\\n",
    "#         betas=\"0.9,0.95\" \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# (自己在用的)\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "# \n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 在 --network_args 设置了 preset, 可以调整训练网络的大小\n",
    "# 该值默认为 full, 如果使用 attn-mlp 可以得到更小的 LoRA, 但对于难学的概念使用 full 效果会更好 (最好还是 full 吧, 其他的预设效果不是很好)\n",
    "# \n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# 使用 --optimizer_args 设置 weight_decay 和 betas, 更高的 weight_decay 可以降低拟合程度, 减少过拟合\n",
    "# 如果拟合程度不够高, 可以提高 --max_train_epochs 的值, 或者适当降低 weight_decay 的值, 可自行测试\n",
    "# 较小的训练集适合使用较小的值, 如 0.05, 较大的训练集适合用 0.1\n",
    "# 大概 34 Epoch 会有比较好的效果吧, 不过不好说, 看训练集\n",
    "# 自己测的时候大概在 26~40 Epoch 之间会出现好结果, 测试了很多炉基本都在这个区间里, 但也不排除意外情况 (训练参数这东西好麻烦啊, 苦い)\n",
    "# \n",
    "# 测试的时候发现 --debiased_estimation_loss 对于训练效果的有些改善\n",
    "# 这里有个对比: https://licyk.netlify.app/2025/02/10/debiased_estimation_loss_in_stable_diffusion_model_training\n",
    "# 启用后能提高拟合速度和颜色表现吧, 画风的学习能学得更好\n",
    "# 但, 肢体崩坏率可能会有点提高, 不过有另一套参数去优化了一下这个问题, 貌似会好一点\n",
    "# 可能画风会弱化, 所以不是很确定哪个比较好用, 只能自己试了\n",
    "# debiased estimation loss 有个相关的论文可以看看: https://arxiv.org/abs/2310.08442\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#         preset=\"full\" \\\n",
    "#     --optimizer_args \\\n",
    "#         weight_decay=0.05 \\\n",
    "#         betas=\"0.9,0.95\" \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --debiased_estimation_loss \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# (自己在用的)\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "# \n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 在 --network_args 设置了 preset, 可以调整训练网络的大小\n",
    "# 该值默认为 full, 如果使用 attn-mlp 可以得到更小的 LoRA, 但对于难学的概念使用 full 效果会更好 (最好还是 full 吧, 其他的预设效果不是很好)\n",
    "# \n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# 使用 --optimizer_args 设置 weight_decay 和 betas, 更高的 weight_decay 可以降低拟合程度, 减少过拟合\n",
    "# 如果拟合程度不够高, 可以提高 --max_train_epochs 的值, 或者适当降低 weight_decay 的值, 可自行测试\n",
    "# 较小的训练集适合使用较小的值, 如 0.05, 较大的训练集适合用 0.1\n",
    "# 大概 34 Epoch 会有比较好的效果吧, 不过不好说, 看训练集\n",
    "# 自己测的时候大概在 26~40 Epoch 之间会出现好结果, 测试了很多炉基本都在这个区间里, 但也不排除意外情况 (训练参数这东西好麻烦啊, 苦い)\n",
    "# \n",
    "# 测试的时候发现 --debiased_estimation_loss 对于训练效果的有些改善\n",
    "# 这里有个对比: https://licyk.netlify.app/2025/02/10/debiased_estimation_loss_in_stable_diffusion_model_training\n",
    "# 启用后能提高拟合速度和颜色表现吧, 画风的学习能学得更好\n",
    "# 但, 肢体崩坏率可能会有点提高, 不过有另一套参数去优化了一下这个问题, 貌似会好一点\n",
    "# 可能画风会弱化, 所以不是很确定哪个比较好用, 只能自己试了\n",
    "# debiased estimation loss 有个相关的论文可以看看: https://arxiv.org/abs/2310.08442\n",
    "# \n",
    "# 加上 v 预测参数进行训练, 提高模型对暗处和亮处的表现效果, 并且能让模型能够直出纯黑色背景, 画面也更干净\n",
    "# 相关的论文可以看看: https://arxiv.org/abs/2305.08891\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/noobaiXLNAIXL_vPred10Version.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#         preset=\"full\" \\\n",
    "#     --optimizer_args \\\n",
    "#         weight_decay=0.05 \\\n",
    "#         betas=\"0.9,0.95\" \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --debiased_estimation_loss \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --zero_terminal_snr \\\n",
    "#     --v_parameterization \\\n",
    "#     --scale_v_pred_loss_like_noise_pred \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "# \n",
    "# 在 --network_args 设置了 preset, 可以调整训练网络的大小\n",
    "# 该值默认为 full, 如果使用 attn-mlp 可以得到更小的 LoRA, 但对于难学的概念使用 full 效果会更好 (最好还是 full 吧, 其他的预设效果不是很好)\n",
    "# \n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# 使用 --optimizer_args 设置 weight_decay 和 betas, 更高的 weight_decay 可以降低拟合程度, 减少过拟合\n",
    "# 如果拟合程度不够高, 可以提高 --max_train_epochs 的值, 或者适当降低 weight_decay 的值, 可自行测试\n",
    "# 较小的训练集适合使用较小的值, 如 0.05, 较大的训练集适合用 0.1\n",
    "# 大概 34 Epoch 会有比较好的效果吧, 不过不好说, 看训练集\n",
    "# 自己测的时候大概在 26~40 Epoch 之间会出现好结果, 测试了很多炉基本都在这个区间里, 但也不排除意外情况 (训练参数这东西好麻烦啊, 苦い)\n",
    "# \n",
    "# 测试的时候发现 --debiased_estimation_loss 对于训练效果的有些改善\n",
    "# 这里有个对比: https://licyk.netlify.app/2025/02/10/debiased_estimation_loss_in_stable_diffusion_model_training\n",
    "# 启用后能提高拟合速度和颜色表现吧, 画风的学习能学得更好\n",
    "# 把学习率调度器 constant_with_warmup 换成了cosine, 稍微缓解了一下拟合速度过快导致肢体崩坏率增大的问题\n",
    "# 如果学的效果不够好, 拟合度不够高, 可以适当增加 --max_train_epochs 的值或者提高训练集的重复次数\n",
    "# debiased estimation loss 有个相关的论文可以看看: https://arxiv.org/abs/2310.08442\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#         preset=\"full\" \\\n",
    "#     --optimizer_args \\\n",
    "#         weight_decay=0.05 \\\n",
    "#         betas=\"0.9,0.95\" \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --debiased_estimation_loss \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 人物 LoRA, 使用多卡进行训练\n",
    "# 适合极少图或者单图训练集进行人物 LoRA 训练\n",
    "# 训练集使用打标器进行打标后, 要保留的人物的哪些特征, 就把对应的 Tag 删去, 触发词可加可不加\n",
    "# \n",
    "# 该参数使用 scale_weight_norms 降低过拟合程度, 进行训练时, 可在控制台输出看到 Average key norm 这个值\n",
    "# 通常测试 LoRA 时就测试 Average key norm 值在 0.5 ~ 0.9 之间的保存的 LoRA 模型\n",
    "# max_train_epochs 设置为 200, save_every_n_epochs 设置为 1 以为了更好的挑选最好的结果\n",
    "# \n",
    "# 可使用该方法训练一个人物 LoRA 模型用于生成人物的图片, 并将这些图片重新制作成训练集\n",
    "# 再使用不带 scale_weight_norms 的训练参数进行训练, 通过这种方式, 可以在图片极少的情况下得到比较好的 LoRA 模型\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=200 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --scale_weight_norms=1 \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用 rtx 4060 8g laptop 进行训练, 通过 fp8 降低显存占用\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# !python \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=3 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.0002 \\\n",
    "#     --unet_lr=0.0002 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"AdamW8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --fp8_base\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 参数加上了 noise_offset, 可以提高暗处和亮处的表现, 一般使用设置成 0.05 ~ 0.1\n",
    "# 但 noise_offset 可能会导致画面泛白, 光影效果变差\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --noise_offset=0.1 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 人物 LoRA, 使用多卡进行训练\n",
    "# 参数中使用了 --scale_weight_norms, 用于提高泛化性, 但可能会造成拟合度降低\n",
    "# 如果当训练人物 LoRA 的图片较多时, 可考虑删去该参数\n",
    "# 当训练人物 LoRA 的图片较少, 为了避免过拟合, 就可以考虑使用 --scale_weight_norms 降低过拟合概率\n",
    "#\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animagine-xl-3.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/robin\" \\\n",
    "#     --output_name=\"robin_1\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/robin_1\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=50 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --scale_weight_norms=1 \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 人物 LoRA, 使用多卡进行训练\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animagine-xl-3.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/murasame_(senren)_3\" \\\n",
    "#     --output_name=\"murasame_(senren)_10\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/murasame_(senren)_10\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=50 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00004 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --scale_weight_norms=1 \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用单卡进行训练 (Kaggle 的单 Tesla P100 性能不如双 Tesla T4, 建议使用双卡训练)\n",
    "# !python \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animagine-xl-3.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/rafa\" \\\n",
    "#     --output_name=\"rafa_1\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/rafa\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=4096 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=50 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00007 \\\n",
    "#     --unet_lr=0.00007 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 SD1.5 画风 LoRA, 使用双卡进行训练\n",
    "# 使用 NovelAI 1 模型进行训练\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animefull-final-pruned.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/vae-ft-mse-840000-ema-pruned.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/sunfish\" \\\n",
    "#     --output_name=\"nai1-sunfish_5\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/nai1-sunfish_5\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"768,768\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=1024 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=12 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00024 \\\n",
    "#     --unet_lr=0.00024 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 SD1.5 多画风(多概念) LoRA, 使用双卡进行训练\n",
    "# 使用 NovelAI 1 模型进行训练\n",
    "# \n",
    "# 在 SD1.5 中训练 Text Encoder 可以帮助模型更好的区分不同的画风(概念)\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animefull-final-pruned.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/vae-ft-mse-840000-ema-pruned.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/sunfish\" \\\n",
    "#     --output_name=\"nai1-sunfish_5\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/nai1-sunfish_5\" \\\n",
    "#     --wandb_run_name=\"Nachoneko\" \\\n",
    "#     --log_tracker_name=\"lora-Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"768,768\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=1024 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=12 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --learning_rate=0.00028 \\\n",
    "#     --unet_lr=0.00028 \\\n",
    "#     --text_encoder_lr=0.000015 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"{LOG_MODULE}\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --vae_batch_size=4 \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# 下面是 toml 格式的训练命令, 根据上面的训练命令做了格式转换\n",
    "# 只弄了自己常用的训练参数, 其他的参照下面的例子来改吧\n",
    "# \n",
    "# toml 转换格式如下 (在最前面已经写过一次了, 再写一遍方便对照):\n",
    "# (1)\n",
    "# toml 格式:\n",
    "# pretrained_model_name_or_path = \"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\"\n",
    "# 训练命令格式:\n",
    "# --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\"\n",
    "# \n",
    "# (2)\n",
    "# toml 格式:\n",
    "# unet_lr = 0.0001\n",
    "# 训练命令格式:\n",
    "# --unet_lr=0.0001\n",
    "# \n",
    "# (3)\n",
    "# toml 格式:\n",
    "# network_args = [\n",
    "#     \"conv_dim=100000\",\n",
    "#     \"conv_alpha=100000\",\n",
    "#     \"algo=lokr\",\n",
    "#     \"dropout=0\",\n",
    "#     \"factor=8\",\n",
    "#     \"train_norm=True\",\n",
    "#     \"preset=full\",\n",
    "# ]\n",
    "# 训练命令格式:\n",
    "# --network_args \\\n",
    "#     conv_dim=100000 \\\n",
    "#     conv_alpha=100000 \\\n",
    "#     algo=lokr \\\n",
    "#     dropout=0 \\\n",
    "#     factor=8 \\\n",
    "#     train_norm=True \\\n",
    "#     preset=full \\\n",
    "# \n",
    "# (4)\n",
    "# toml 格式:\n",
    "# enable_bucket = true\n",
    "# 训练命令格式:\n",
    "# --enable_bucket\n",
    "# \n",
    "# (5)\n",
    "# toml 格式:\n",
    "# lowram = false\n",
    "# 训练命令格式:\n",
    "# 无对应的训练命令, 也就是不需要填, 因为这个参数的值为 false, 也就是无对应的参数, 如果值为 true, 则对应训练命令中的 --lowram\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# (自己在用的, toml 格式的版本)\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "# \n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 在 --network_args 设置了 preset, 可以调整训练网络的大小\n",
    "# 该值默认为 full, 如果使用 attn-mlp 可以得到更小的 LoRA, 但对于难学的概念使用 full 效果会更好\n",
    "# \n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# 使用 --optimizer_args 设置 weight_decay 和 betas, 更高的 weight_decay 可以降低拟合程度, 减少过拟合\n",
    "# 如果拟合程度不够高, 可以提高 --max_train_epochs 的值, 或者适当降低 weight_decay 的值, 可自行测试\n",
    "# 较小的训练集适合使用较小的值, 如 0.05, 较大的训练集适合用 0.1\n",
    "# 大概 34 Epoch 会有比较好的效果吧, 不过不好说, 看训练集\n",
    "# 自己测的时候大概在 26~40 Epoch 之间会出现好结果, 测试了很多炉基本都在这个区间里, 但也不排除意外情况 (训练参数这东西好麻烦啊, 苦い)\n",
    "# \n",
    "# toml_file_path = os.path.join(WORKSPACE, \"train_config.toml\")\n",
    "# toml_content = f\"\"\"\n",
    "# pretrained_model_name_or_path = \"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\"\n",
    "# vae = \"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\"\n",
    "# train_data_dir = \"{INPUT_DATASET_PATH}/Nachoneko\"\n",
    "# output_name = \"Nachoneko_2\"\n",
    "# output_dir = \"{OUTPUT_PATH}/Nachoneko\"\n",
    "# wandb_run_name = \"Nachoneko\"\n",
    "# log_tracker_name = \"lora-Nachoneko\"\n",
    "# prior_loss_weight = 1\n",
    "# resolution = \"1024,1024\"\n",
    "# enable_bucket = true\n",
    "# min_bucket_reso = 256\n",
    "# max_bucket_reso = 4096\n",
    "# bucket_reso_steps = 64\n",
    "# save_model_as = \"safetensors\"\n",
    "# save_precision = \"fp16\"\n",
    "# save_every_n_epochs = 1\n",
    "# max_train_epochs = 40\n",
    "# train_batch_size = 6\n",
    "# gradient_checkpointing = true\n",
    "# network_train_unet_only = true\n",
    "# learning_rate = 0.0001\n",
    "# unet_lr = 0.0001\n",
    "# text_encoder_lr = 0.00001\n",
    "# lr_scheduler = \"constant_with_warmup\"\n",
    "# lr_warmup_steps = 100\n",
    "# optimizer_type = \"Lion8bit\"\n",
    "# network_module = \"lycoris.kohya\"\n",
    "# network_dim = 100000\n",
    "# network_alpha = 100000\n",
    "# network_args = [\n",
    "#     \"conv_dim=100000\",\n",
    "#     \"conv_alpha=100000\",\n",
    "#     \"algo=lokr\",\n",
    "#     \"dropout=0\",\n",
    "#     \"factor=8\",\n",
    "#     \"train_norm=True\",\n",
    "#     \"preset=full\",\n",
    "# ]\n",
    "# optimizer_args = [\n",
    "#     \"weight_decay=0.05\",\n",
    "#     \"betas=0.9,0.95\",\n",
    "# ]\n",
    "# log_with = \"{LOG_MODULE}\"\n",
    "# logging_dir = \"{OUTPUT_PATH}/logs\"\n",
    "# caption_extension = \".txt\"\n",
    "# shuffle_caption = true\n",
    "# keep_tokens = 0\n",
    "# max_token_length = 225\n",
    "# seed = 1337\n",
    "# mixed_precision = \"fp16\"\n",
    "# xformers = true\n",
    "# cache_latents = true\n",
    "# cache_latents_to_disk = true\n",
    "# persistent_data_loader_workers = true\n",
    "# vae_batch_size = 4\n",
    "# full_fp16 = true\n",
    "# \"\"\".strip()\n",
    "# if not os.path.exists(os.path.dirname(toml_file_path)):\n",
    "#     os.makedirs(toml_file_path, exist_ok=True)\n",
    "# with open(toml_file_path, \"w\", encoding=\"utf8\") as file:\n",
    "#     file.write(toml_content)\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --config_file=\"{toml_file_path}\"\n",
    "\n",
    "\n",
    "# (自己在用的, toml 格式的版本)\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "# \n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 在 --network_args 设置了 preset, 可以调整训练网络的大小\n",
    "# 该值默认为 full, 如果使用 attn-mlp 可以得到更小的 LoRA, 但对于难学的概念使用 full 效果会更好 (最好还是 full 吧, 其他的预设效果不是很好)\n",
    "# \n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# 使用 --optimizer_args 设置 weight_decay 和 betas, 更高的 weight_decay 可以降低拟合程度, 减少过拟合\n",
    "# 如果拟合程度不够高, 可以提高 --max_train_epochs 的值, 或者适当降低 weight_decay 的值, 可自行测试\n",
    "# 较小的训练集适合使用较小的值, 如 0.05, 较大的训练集适合用 0.1\n",
    "# 大概 34 Epoch 会有比较好的效果吧, 不过不好说, 看训练集\n",
    "# 自己测的时候大概在 26~40 Epoch 之间会出现好结果, 测试了很多炉基本都在这个区间里, 但也不排除意外情况 (训练参数这东西好麻烦啊, 苦い)\n",
    "# \n",
    "# 测试的时候发现 --debiased_estimation_loss 对于训练效果的有些改善\n",
    "# 这里有个对比: https://licyk.netlify.app/2025/02/10/debiased_estimation_loss_in_stable_diffusion_model_training\n",
    "# 启用后能提高拟合速度和颜色表现吧, 画风的学习能学得更好\n",
    "# 但, 肢体崩坏率可能会有点提高, 不过有另一套参数去优化了一下这个问题, 貌似会好一点\n",
    "# 可能画风会弱化, 所以不是很确定哪个比较好用, 只能自己试了\n",
    "# debiased estimation loss 有个相关的论文可以看看: https://arxiv.org/abs/2310.08442\n",
    "# \n",
    "# toml_file_path = os.path.join(WORKSPACE, \"train_config.toml\")\n",
    "# toml_content = f\"\"\"\n",
    "# pretrained_model_name_or_path = \"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\"\n",
    "# vae = \"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\"\n",
    "# train_data_dir = \"{INPUT_DATASET_PATH}/Nachoneko\"\n",
    "# output_name = \"Nachoneko_2\"\n",
    "# output_dir = \"{OUTPUT_PATH}/Nachoneko\"\n",
    "# wandb_run_name = \"Nachoneko\"\n",
    "# log_tracker_name = \"lora-Nachoneko\"\n",
    "# prior_loss_weight = 1\n",
    "# resolution = \"1024,1024\"\n",
    "# enable_bucket = true\n",
    "# min_bucket_reso = 256\n",
    "# max_bucket_reso = 4096\n",
    "# bucket_reso_steps = 64\n",
    "# save_model_as = \"safetensors\"\n",
    "# save_precision = \"fp16\"\n",
    "# save_every_n_epochs = 1\n",
    "# max_train_epochs = 40\n",
    "# train_batch_size = 6\n",
    "# gradient_checkpointing = true\n",
    "# network_train_unet_only = true\n",
    "# learning_rate = 0.0001\n",
    "# unet_lr = 0.0001\n",
    "# text_encoder_lr = 0.00001\n",
    "# lr_scheduler = \"constant_with_warmup\"\n",
    "# lr_warmup_steps = 100\n",
    "# optimizer_type = \"Lion8bit\"\n",
    "# network_module = \"lycoris.kohya\"\n",
    "# network_dim = 100000\n",
    "# network_alpha = 100000\n",
    "# network_args = [\n",
    "#     \"conv_dim=100000\",\n",
    "#     \"conv_alpha=100000\",\n",
    "#     \"algo=lokr\",\n",
    "#     \"dropout=0\",\n",
    "#     \"factor=8\",\n",
    "#     \"train_norm=True\",\n",
    "#     \"preset=full\",\n",
    "# ]\n",
    "# optimizer_args = [\n",
    "#     \"weight_decay=0.05\",\n",
    "#     \"betas=0.9,0.95\",\n",
    "# ]\n",
    "# log_with = \"{LOG_MODULE}\"\n",
    "# logging_dir = \"{OUTPUT_PATH}/logs\"\n",
    "# caption_extension = \".txt\"\n",
    "# shuffle_caption = true\n",
    "# keep_tokens = 0\n",
    "# max_token_length = 225\n",
    "# seed = 1337\n",
    "# mixed_precision = \"fp16\"\n",
    "# xformers = true\n",
    "# cache_latents = true\n",
    "# cache_latents_to_disk = true\n",
    "# persistent_data_loader_workers = true\n",
    "# debiased_estimation_loss = true\n",
    "# vae_batch_size = 4\n",
    "# full_fp16 = true\n",
    "# \"\"\".strip()\n",
    "# if not os.path.exists(os.path.dirname(toml_file_path)):\n",
    "#     os.makedirs(toml_file_path, exist_ok=True)\n",
    "# with open(toml_file_path, \"w\", encoding=\"utf8\") as file:\n",
    "#     file.write(toml_content)\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --config_file=\"{toml_file_path}\"\n",
    "\n",
    "\n",
    "# (自己在用的, toml 格式的版本)\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "# \n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 在 --network_args 设置了 preset, 可以调整训练网络的大小\n",
    "# 该值默认为 full, 如果使用 attn-mlp 可以得到更小的 LoRA, 但对于难学的概念使用 full 效果会更好 (最好还是 full 吧, 其他的预设效果不是很好)\n",
    "# \n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# 使用 --optimizer_args 设置 weight_decay 和 betas, 更高的 weight_decay 可以降低拟合程度, 减少过拟合\n",
    "# 如果拟合程度不够高, 可以提高 --max_train_epochs 的值, 或者适当降低 weight_decay 的值, 可自行测试\n",
    "# 较小的训练集适合使用较小的值, 如 0.05, 较大的训练集适合用 0.1\n",
    "# 大概 34 Epoch 会有比较好的效果吧, 不过不好说, 看训练集\n",
    "# 自己测的时候大概在 26~40 Epoch 之间会出现好结果, 测试了很多炉基本都在这个区间里, 但也不排除意外情况 (训练参数这东西好麻烦啊, 苦い)\n",
    "# \n",
    "# 测试的时候发现 --debiased_estimation_loss 对于训练效果的有些改善\n",
    "# 这里有个对比: https://licyk.netlify.app/2025/02/10/debiased_estimation_loss_in_stable_diffusion_model_training\n",
    "# 启用后能提高拟合速度和颜色表现吧, 画风的学习能学得更好\n",
    "# 但, 肢体崩坏率可能会有点提高, 不过有另一套参数去优化了一下这个问题, 貌似会好一点\n",
    "# 可能画风会弱化, 所以不是很确定哪个比较好用, 只能自己试了\n",
    "# debiased estimation loss 有个相关的论文可以看看: https://arxiv.org/abs/2310.08442\n",
    "# \n",
    "# 加上 v 预测参数进行训练, 提高模型对暗处和亮处的表现效果, 并且能让模型能够直出纯黑色背景, 画面也更干净\n",
    "# 相关的论文可以看看: https://arxiv.org/abs/2305.08891\n",
    "# \n",
    "# toml_file_path = os.path.join(WORKSPACE, \"train_config.toml\")\n",
    "# toml_content = f\"\"\"\n",
    "# pretrained_model_name_or_path = \"{SD_MODEL_PATH}/noobaiXLNAIXL_vPred10Version.safetensors\"\n",
    "# vae = \"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\"\n",
    "# train_data_dir = \"{INPUT_DATASET_PATH}/Nachoneko\"\n",
    "# output_name = \"Nachoneko_2\"\n",
    "# output_dir = \"{OUTPUT_PATH}/Nachoneko\"\n",
    "# wandb_run_name = \"Nachoneko\"\n",
    "# log_tracker_name = \"lora-Nachoneko\"\n",
    "# prior_loss_weight = 1\n",
    "# resolution = \"1024,1024\"\n",
    "# enable_bucket = true\n",
    "# min_bucket_reso = 256\n",
    "# max_bucket_reso = 4096\n",
    "# bucket_reso_steps = 64\n",
    "# save_model_as = \"safetensors\"\n",
    "# save_precision = \"fp16\"\n",
    "# save_every_n_epochs = 1\n",
    "# max_train_epochs = 40\n",
    "# train_batch_size = 6\n",
    "# gradient_checkpointing = true\n",
    "# network_train_unet_only = true\n",
    "# learning_rate = 0.0001\n",
    "# unet_lr = 0.0001\n",
    "# text_encoder_lr = 0.00001\n",
    "# lr_scheduler = \"constant_with_warmup\"\n",
    "# lr_warmup_steps = 100\n",
    "# optimizer_type = \"Lion8bit\"\n",
    "# network_module = \"lycoris.kohya\"\n",
    "# network_dim = 100000\n",
    "# network_alpha = 100000\n",
    "# network_args = [\n",
    "#     \"conv_dim=100000\",\n",
    "#     \"conv_alpha=100000\",\n",
    "#     \"algo=lokr\",\n",
    "#     \"dropout=0\",\n",
    "#     \"factor=8\",\n",
    "#     \"train_norm=True\",\n",
    "#     \"preset=full\",\n",
    "# ]\n",
    "# optimizer_args = [\n",
    "#     \"weight_decay=0.05\",\n",
    "#     \"betas=0.9,0.95\",\n",
    "# ]\n",
    "# log_with = \"{LOG_MODULE}\"\n",
    "# logging_dir = \"{OUTPUT_PATH}/logs\"\n",
    "# caption_extension = \".txt\"\n",
    "# shuffle_caption = true\n",
    "# keep_tokens = 0\n",
    "# max_token_length = 225\n",
    "# seed = 1337\n",
    "# mixed_precision = \"fp16\"\n",
    "# xformers = true\n",
    "# cache_latents = true\n",
    "# cache_latents_to_disk = true\n",
    "# persistent_data_loader_workers = true\n",
    "# debiased_estimation_loss = true\n",
    "# vae_batch_size = 4\n",
    "# zero_terminal_snr = true\n",
    "# v_parameterization = true\n",
    "# scale_v_pred_loss_like_noise_pred = true\n",
    "# full_fp16 = true\n",
    "# \"\"\".strip()\n",
    "# if not os.path.exists(os.path.dirname(toml_file_path)):\n",
    "#     os.makedirs(toml_file_path, exist_ok=True)\n",
    "# with open(toml_file_path, \"w\", encoding=\"utf8\") as file:\n",
    "#     file.write(toml_content)\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --config_file=\"{toml_file_path}\"\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "os.chdir(WORKSPACE)\n",
    "echo(\"离开 sd-scripts 目录\")\n",
    "echo(\"模型训练结束\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型上传\n",
    "通常不需要修改该单元内容  \n",
    "5. [← 上一个单元](#模型训练)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型上传到 HuggingFace / ModelScope, 通常不需要修改, 修改参数建议通过上方的参数配置单元进行修改\n",
    "\n",
    "# 使用 HuggingFace 上传模型\n",
    "if USE_HF_TO_SAVE_MODEL:\n",
    "    echo(\"使用 HuggingFace 保存模型\")\n",
    "    sd_scripts.repo_manager.push_file_to_huggingface(\n",
    "        hf_access_token=HF_TOKEN,           # HuggingFace Token\n",
    "        repo_id=HF_REPO_ID,                 # HuggingFace 仓库地址\n",
    "        repo_type=HF_REPO_TYPE,             # HuggingFace 仓库种类\n",
    "        visibility=HF_REPO_VISIBILITY,      # 当尝试创建仓库时设置仓库的可见性\n",
    "        upload_path=OUTPUT_PATH             # 要上传文件的目录\n",
    "    )\n",
    "\n",
    "# 使用 ModelScope 上传模型\n",
    "if USE_MS_TO_SAVE_MODEL:\n",
    "    echo(\"使用 ModelScope 保存模型\")\n",
    "    if USE_NEW_MS_UPLOADER:\n",
    "        echo(f\"使用 ModelScope API 模式\")\n",
    "        sd_scripts.repo_manager.push_file_to_modelscope(\n",
    "            ms_access_token=MS_TOKEN,       # Modelscope Token\n",
    "            repo_id=MS_REPO_ID,             # Modelscope 的仓库地址\n",
    "            repo_type=MS_REPO_TYPE,         # ModelScope 仓库的种类\n",
    "            visibility=MS_REPO_VISIBILITY,  # 当尝试创建仓库时设置仓库的可见性\n",
    "            upload_path=OUTPUT_PATH         # 要上传文件的目录\n",
    "        )\n",
    "    else:\n",
    "        echo(f\"使用 Git 模式\")\n",
    "        # 配置 Git\n",
    "        sd_scripts.repo_manager.set_git_config(\n",
    "            email=GIT_USER_EMAIL,\n",
    "            username=GIT_USER_NAME\n",
    "        )\n",
    "        # 上传模型\n",
    "        sd_scripts.repo_manager.push_file_to_modelscope_legacy(\n",
    "            ms_access_token=MS_TOKEN,       # Modelscope Token\n",
    "            repo_id=MS_REPO_ID,             # Modelscope 的仓库地址\n",
    "            repo_type=MS_REPO_TYPE,         # ModelScope 仓库的种类\n",
    "            visibility=MS_REPO_VISIBILITY,  # 当尝试创建仓库时设置仓库的可见性\n",
    "            work_path=WORKSPACE,            # 脚本工作目录, 仓库将克隆至该文件夹中\n",
    "            upload_path=OUTPUT_PATH         # 要上传文件的目录\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
