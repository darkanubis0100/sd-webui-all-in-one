{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD Scripts Kaggle\n",
    "Created by [licyk](https://github.com/licyk)\n",
    "\n",
    "Jupyter Notebook 仓库：[licyk/sd-webui-all-in-one](https://github.com/licyk/sd-webui-all-in-one)\n",
    "\n",
    "\n",
    "## 简介\n",
    "一个在 [Kaggle](https://www.kaggle.com) 部署 [sd-scripts](https://github.com/kohya-ss/sd-scripts) 的 Jupyter Notebook，可用于 Stable Diffusion 模型的训练。\n",
    "\n",
    "\n",
    "## 不同运行单元的功能\n",
    "该 Notebook 分为以下几个单元：\n",
    "\n",
    "- [功能初始化](#功能初始化)\n",
    "- [参数配置](#参数配置)\n",
    "- [安装](#安装)\n",
    "- [模型训练](#模型训练)\n",
    "- [模型上传](#模型上传)\n",
    "\n",
    "使用时请按顺序运行笔记单元。\n",
    "\n",
    "通常情况下[功能初始化](#功能初始化)和[模型上传](#模型上传)单元的内容无需修改，其他单元包含不同功能的注释，可阅读注释获得帮助。\n",
    "\n",
    "[参数配置](#参数配置)单元用于修改安装，训练，上传模型时的配置。\n",
    "\n",
    "[安装](#安装)单元执行安装训练环境的命令和下载模型 / 训练集的命令，可根据需求进行修改。\n",
    "\n",
    "[模型训练](#模型训练)执行训练模型的命令，需要根据自己的需求进行修改，该单元也提供一些训练参数的例子，可在例子的基础上进行修改。\n",
    "\n",
    "如果需要快速取消注释，可以选中代码，按下`Ctrl + /`取消注释。\n",
    "\n",
    "\n",
    "## 提示\n",
    "1. 不同单元中包含注释, 可阅读注释获得帮助。\n",
    "2. 训练代码的部分需要根据自己的需求进行更改。\n",
    "3. 推荐使用 Kaggle 的 `Save Version` 的功能运行笔记，可让 Kaggle 笔记在无人值守下保持运行，直至所有单元运行完成。\n",
    "4. 如果有 [HuggingFace](https://huggingface.co) 账号或者 [ModelScope](https://modelscope.cn) 账号，可通过填写 Token 和仓库名后实现自动上传训练好的模型，仓库需要手动创建。\n",
    "5. 进入 Kaggle 笔记后，在 Kaggle 的右侧栏可以调整 kaggle 笔记的设置，也可以上传训练集等。注意，在 Kaggle 笔记的`Session options`->`ACCELERATOR`中，需要选择`GPU T4 x 2`，才能使用 GPU 进行模型训练。\n",
    "6. 使用 Kaggle 进行模型训练时，训练集中最好没有 NSFW 内容，否则可能会导致 Kaggle 账号被封禁。\n",
    "7. 不同单元的标题下方包含快捷跳转链接，可使用跳转链接翻阅 Notebook。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 功能初始化\n",
    "1. [[下一个单元 →](#参数配置)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化功能, 不需要修改\n",
    "# 建议直接看下一个单元的内容\n",
    "# 如果想要了解该 Notebook 功能的具体代码实现可阅读该部分的代码\n",
    "\n",
    "\n",
    "def echo(*args):\n",
    "    \"\"\"格式化消息输出\"\"\"\n",
    "    for i in args:\n",
    "        print(f\":: {i}\")\n",
    "\n",
    "\n",
    "\n",
    "class ARIA2:\n",
    "    \"\"\"基于 Aria2 的文件下载工具\"\"\"\n",
    "    WORKSPACE = \"\"\n",
    "    WORKFOLDER = \"\"\n",
    "\n",
    "\n",
    "    def __init__(self, workspace, workfolder) -> None:\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    def aria2(self, url, path, filename):\n",
    "        \"\"\"调用 Aria2 下载文件\n",
    "\n",
    "        参数:\n",
    "            url:\n",
    "                文件的下载链接\n",
    "\n",
    "            path:\n",
    "                将文件下载到本地的路径\n",
    "\n",
    "            filename:\n",
    "                将要下载的文件重命名\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if not os.path.exists(os.path.join(path, filename)):\n",
    "            echo(f\"开始下载 {filename} ，路径: {path}/{filename}\")\n",
    "            !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{url}\" -d \"{path}\" -o \"{filename}\"\n",
    "            if os.path.exists(os.path.join(path, filename)) and not os.path.exists(os.path.join(path, filename) + \".aria2\"):\n",
    "                echo(f\"{filename} 下载完成\")\n",
    "            else:\n",
    "                echo(f\"{filename} 下载中断\")\n",
    "        else:\n",
    "            if os.path.exists(os.path.join(path, filename) + \".aria2\"):\n",
    "                echo(f\"开始下载 {filename} ，路径: {path}/{filename}\")\n",
    "                !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{url}\" -d \"{path}\" -o \"{filename}\"\n",
    "                if os.path.exists(os.path.join(path, filename)) and not os.path.exists(os.path.join(path, filename) + \".aria2\"):\n",
    "                    echo(f\"{filename} 下载完成\")\n",
    "                else:\n",
    "                    echo(f\"{filename} 下载中断\")\n",
    "            else:\n",
    "                echo(f\"{filename} 文件已存在，路径: {path}/{filename}\")\n",
    "\n",
    "\n",
    "\n",
    "class GIT:\n",
    "    \"\"\"基于 Git 命令的模块\"\"\"\n",
    "    WORKSPACE = \"\"\n",
    "    WORKFOLDER = \"\"\n",
    "\n",
    "\n",
    "    def __init__(self, workspace, workfolder) -> None:\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    def exists(self, addr=None, path=None, name=None):\n",
    "        \"\"\"检测要克隆的项目是否存在于指定路径\n",
    "\n",
    "        参数:\n",
    "            addr:\n",
    "                Git 仓库的地址\n",
    "\n",
    "            path:\n",
    "                将 Git 仓库下载到本地的路径\n",
    "\n",
    "            name:\n",
    "                将 Git 仓库进行重命名\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if addr is not None:\n",
    "            if path is None and name is None:\n",
    "                path = os.path.join(os.getcwd(), addr.split(\"/\").pop().split(\".git\", 1)[0])\n",
    "            elif path is None and name is not None:\n",
    "                path = os.path.join(os.getcwd(), name)\n",
    "            elif path is not None and name is None:\n",
    "                path = os.path.join(os.path.normpath(path), addr.split(\"/\").pop().split(\".git\", 1)[0])\n",
    "            elif path is not None and name is not None:\n",
    "                path = os.path.join(os.path.normpath(path), name)\n",
    "\n",
    "        if os.path.exists(path):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def clone(self, addr, path=None, name=None):\n",
    "        \"\"\"克隆 Git 仓库到本地\n",
    "\n",
    "        参数:\n",
    "            addr:\n",
    "                Git 仓库的地址\n",
    "\n",
    "            path:\n",
    "                将 Git 仓库下载到本地的路径\n",
    "\n",
    "            name:\n",
    "                将 Git 仓库进行重命名\n",
    "        \"\"\"\n",
    "        import os\n",
    "        repo = addr.split(\"/\").pop().split(\".git\", 1)[0]\n",
    "        if not self.exists(addr, path, name):\n",
    "            echo(f\"开始下载 {repo}\")\n",
    "            if path is None and name is None:\n",
    "                path = os.getcwd()\n",
    "                name = repo\n",
    "            elif path is not None and name is None:\n",
    "                name = repo\n",
    "            elif path is None and name is not None:\n",
    "                path = os.getcwd()\n",
    "            !git clone {addr} \"{path}/{name}\" --recurse-submodules\n",
    "        else:\n",
    "            echo(f\"{repo} 已存在\")\n",
    "\n",
    "\n",
    "    def checkout(self, path, branch):\n",
    "        \"\"\"切换 Git 仓库到指定分支\n",
    "        参数:\n",
    "            path:\n",
    "                Git 仓库的路径\n",
    "\n",
    "            branch:\n",
    "                指定要切换 Git 仓库分支\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if os.path.exists(os.path.join(path, \".git\")) and branch != \"\":\n",
    "            echo(f\"切换 {os.path.basename(path)} 的分支至 {branch}\")\n",
    "            !git -C \"{path}\" checkout \"{branch}\" --recurse-submodules\n",
    "\n",
    "\n",
    "    def reset(self, path, commit):\n",
    "        \"\"\"切换到执行提交记录上\n",
    "        参数:\n",
    "            path:\n",
    "                Git 仓库的路径\n",
    "\n",
    "            commmit:\n",
    "                指定要切换 Git 仓库的提交哈希值\n",
    "        \"\"\"\n",
    "        import os\n",
    "        if os.path.exists(os.path.join(path, \".git\")) and commit != \"\":\n",
    "            echo(f\"切换 {os.path.basename(path)} 的分支至 {commit}\")\n",
    "            !git -C \"{path}\" reset \"{commit}\" --hard --recurse-submodules\n",
    "\n",
    "\n",
    "\n",
    "class ENV:\n",
    "    \"\"\"提供初始化环境的功能\"\"\"\n",
    "    WORKSPACE = \"\"\n",
    "    WORKFOLDER = \"\"\n",
    "\n",
    "\n",
    "    def __init__(self, workspace, workfolder) -> None:\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    def prepare_env_depend(self, use_uv=False):\n",
    "        \"\"\"为 Notebook 的功能准备必须的环境依赖\n",
    "        参数:\n",
    "            use_uv (bool):\n",
    "                是否使用 uv 代替 Pip 安装 Python 软件包\n",
    "        \"\"\"\n",
    "        pip_mirror = \"--index-url https://pypi.python.org/simple --extra-index-url https://download.pytorch.org/whl/cu121\"\n",
    "\n",
    "        echo(\"安装自身组件依赖\")\n",
    "        !pip install uv {pip_mirror}\n",
    "        pkg = \"huggingface_hub modelscope\"\n",
    "        if use_uv:\n",
    "            !uv pip install {pkg} {pip_mirror} --system --quiet -U || pip install {pkg} {pip_mirror} -U\n",
    "        else:\n",
    "            !pip install {pkg} {pip_mirror} -U\n",
    "        !apt update\n",
    "        !apt install aria2 google-perftools p7zip-full unzip tree -y\n",
    "\n",
    "\n",
    "    def prepare_torch(self, torch_ver, xformers_ver, use_uv=False):\n",
    "        \"\"\"安装 PyTorch 和 xFormers\n",
    "        参数:\n",
    "            torch_ver:\n",
    "                PyTorch 软件包名称和版本信息, 如`torch==2.0.0 torchvision==0.15.1`\n",
    "\n",
    "            xformers_ver:\n",
    "                xFormers 软件包名称和版本信息, 如`xformers==0.0.18`\n",
    "\n",
    "            use_uv (bool):\n",
    "                使用 uv 代替 Pip 进行 Python 软件包安装\n",
    "        \"\"\"\n",
    "        pip_mirror = \"--index-url https://download.pytorch.org/whl/cu121\"\n",
    "        if use_uv:\n",
    "            if torch_ver != \"\":\n",
    "                echo(\"安装 PyTorch\")\n",
    "                !uv pip install {torch_ver} {pip_mirror} --system --quiet || pip install {torch_ver} {pip_mirror}\n",
    "            if xformers_ver != \"\":\n",
    "                echo(\"安装 xFormers\")\n",
    "                !uv pip install {xformers_ver} {pip_mirror} --no-deps --system --quiet || pip install {xformers_ver} {pip_mirror} --no-deps\n",
    "        else:\n",
    "            if torch_ver != \"\":\n",
    "                echo(\"安装 PyTorch\")\n",
    "                !pip install {torch_ver} {pip_mirror}\n",
    "            if xformers_ver != \"\":\n",
    "                echo(\"安装 xFormers\")\n",
    "                !pip install {xformers_ver} {pip_mirror} --no-deps\n",
    "\n",
    "\n",
    "    def install_requirements(self, path, use_uv=False):\n",
    "        \"\"\"从文件 (requirements.txt) 中安装 Python 软件包\n",
    "        参数:\n",
    "            path:\n",
    "                依赖记录文件的路径\n",
    "\n",
    "            use_uv (bool):\n",
    "                使用 uv 代替 Pip 进行 Python 软件包安装\n",
    "        \"\"\"\n",
    "        import os\n",
    "        pip_mirror = \"--index-url https://pypi.python.org/simple --extra-index-url https://download.pytorch.org/whl/cu121\"\n",
    "        if os.path.exists(path):\n",
    "            echo(\"安装依赖\")\n",
    "            if use_uv:\n",
    "                !uv pip install -r \"{path}\" {pip_mirror} --system --quiet || pip install -r \"{path}\" {pip_mirror}\n",
    "            else:\n",
    "                !pip install -r \"{path}\" {pip_mirror}\n",
    "        else:\n",
    "            echo(\"依赖文件路径为空\")\n",
    "\n",
    "\n",
    "    def py_pkg_manager(self, pkg, type=None, use_uv=False):\n",
    "        \"\"\"使用 Pip / uv 执行对 Python 软件包的操作\n",
    "        参数:\n",
    "            pkg:\n",
    "                指定 Python 软件包名\n",
    "\n",
    "            type:\n",
    "                指定对 Python 软件包的操作\n",
    "\n",
    "                可选的操作: (install / install_single / force_install / force_install_single / update / uninstall)\n",
    "\n",
    "            use_uv (bool):\n",
    "                使用 uv 代替 Pip 进行 Python 软件包安装\n",
    "\n",
    "        type 支持的操作和对应的命令行参数如下:\n",
    "            安装: install -> install\n",
    "\n",
    "            仅安装: install_single -> install --no-deps\n",
    "\n",
    "            强制重装: force_install -> install --force-reinstall\n",
    "\n",
    "            仅强制重装: force_install_single -> install --force-reinstall --no-deps\n",
    "\n",
    "            更新: update -> install --upgrade\n",
    "\n",
    "            卸载: uninstall -> uninstall -y\n",
    "        \"\"\"\n",
    "\n",
    "        pip_mirror = \"--index-url https://pypi.python.org/simple --extra-index-url https://download.pytorch.org/whl/cu121\"\n",
    "\n",
    "        if type == \"install\":\n",
    "            func = \"install\"\n",
    "            args = \"\"\n",
    "        elif type == \"install_single\":\n",
    "            func = \"install\"\n",
    "            args = \"--no-deps\"\n",
    "        elif type == \"force_install\":\n",
    "            func = \"install\"\n",
    "            args = \"--force-reinstall\"\n",
    "        elif type == \"force_install_single\":\n",
    "            func = \"install\"\n",
    "            args = \"install --force-reinstall --no-deps\"\n",
    "        elif type == \"update\":\n",
    "            func = \"install\"\n",
    "            args = \"--upgrade\"\n",
    "        elif type == \"uninstall\":\n",
    "            func = \"uninstall\"\n",
    "            args = \"-y\"\n",
    "            pip_mirror = \"\"\n",
    "        else:\n",
    "            echo(f\"未知操作: {type}\")\n",
    "            return\n",
    "\n",
    "        if use_uv:\n",
    "            echo(f\"执行操作: uv pip {func} {pkg} {args} {pip_mirror} --system --quiet\")\n",
    "            !uv pip {func} {pkg} {args} {pip_mirror} --system --quiet\n",
    "        else:\n",
    "            echo(f\"执行操作: pip {func} {pkg} {args} {pip_mirror}\")\n",
    "            !pip {func} {pkg} {args} {pip_mirror}\n",
    "\n",
    "\n",
    "    def tcmalloc(self):\n",
    "        \"\"\"使用 TCMalloc 优化内存的占用, 通过 LD_PRELOAD 环境变量指定 TCMalloc\"\"\"\n",
    "        echo(\"配置内存优化\")\n",
    "        import os\n",
    "        os.environ[\"LD_PRELOAD\"] = \"/usr/lib/x86_64-linux-gnu/libtcmalloc_minimal.so.4\"\n",
    "\n",
    "\n",
    "\n",
    "class MANAGER:\n",
    "    \"\"\"环境管理\"\"\"\n",
    "    WORKSPACE = \"\"\n",
    "    WORKFOLDER = \"\"\n",
    "\n",
    "\n",
    "    def __init__(self, workspace, workfolder) -> None:\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    def clear_up(self):\n",
    "        \"\"\"清理 Notebook 的内容输出\"\"\"\n",
    "        from IPython.display import clear_output\n",
    "        clear_output(wait=False)\n",
    "\n",
    "\n",
    "    def check_gpu(self):\n",
    "        \"\"\"检查环境中是否有可用的 GPU\"\"\"\n",
    "        echo(\"检测 GPU 是否可用\")\n",
    "        import tensorflow as tf\n",
    "        echo(f\"TensorFlow 版本: {tf.__version__}\")\n",
    "        if tf.test.gpu_device_name():\n",
    "            echo(\"GPU 可用\")\n",
    "        else:\n",
    "            echo(\"GPU 不可用\")\n",
    "            raise Exception(\"\\n没有使用GPU，请在代码执行程序-更改运行时类型-设置为GPU！\\n如果不能使用GPU，建议更换账号！\")\n",
    "\n",
    "\n",
    "\n",
    "class REPO_MANAGER:\n",
    "    \"\"\"基于 HuggingFace / ModelScope 的仓库管理工具\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "    def get_all_file(self, directory):\n",
    "        \"\"\"获取文件夹中所有文件的绝对路径\n",
    "        参数:\n",
    "            directory:\n",
    "                文件夹的路径\n",
    "\n",
    "        返回值:\n",
    "            `list`: 所有文件的绝对路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        file_list = []\n",
    "        for dirname, _, filenames in os.walk(directory):\n",
    "            for filename in filenames:\n",
    "                file_list.append(os.path.join(dirname, filename))\n",
    "        return file_list\n",
    "\n",
    "\n",
    "    # ModelScope\n",
    "\n",
    "    def is_file_exists_in_ms_repo(self, upload_file, work_path, repo_id):\n",
    "        \"\"\"检测指定文件是否存在于 ModelScope 仓库中\n",
    "        参数:\n",
    "            upload_file:\n",
    "                文件在仓库中对应的路径\n",
    "\n",
    "            work_path:\n",
    "                仓库在本地的父路径\n",
    "\n",
    "            repo_id:\n",
    "                ModelScope 仓库的 ID\n",
    "\n",
    "        返回值:\n",
    "            `bool`: 当文件存在时返回`True`, 否则为`False`\n",
    "        \"\"\"\n",
    "        import os\n",
    "\n",
    "        repo_file = os.path.join(work_path, repo_id.split(\"/\").pop(), upload_file)\n",
    "        if os.path.exists(repo_file):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "\n",
    "    def clone_modelscope_without_lfs(self, ms_access_token, repo_id, repo_type, work_path):\n",
    "        \"\"\"将 ModelScope 仓库下载到本地中, 并且不包含 Git LFS 文件\n",
    "        参数:\n",
    "            ms_access_token:\n",
    "                ModelScope 账号的 Git Token\n",
    "\n",
    "            repo_id:\n",
    "                ModelScope 仓库 ID\n",
    "\n",
    "            repo_type:\n",
    "                ModelScope 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 创空间仓库\n",
    "\n",
    "            work_path:\n",
    "                将仓库下载到本地的路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "\n",
    "        # 禁用 Git LFS\n",
    "        os.environ[\"GIT_LFS_SKIP_SMUDGE\"] = \"1\"\n",
    "        !git lfs uninstall\n",
    "\n",
    "        # 本地存在仓库时进行删除\n",
    "        repo_name = repo_id.split(\"/\").pop()\n",
    "        path = os.path.join(work_path, repo_name)\n",
    "        if os.path.exists(path):\n",
    "            !rm -rf \"{path}\"\n",
    "\n",
    "        # 下载仓库并启用 Git LFS\n",
    "        if repo_type == \"model\":\n",
    "            repo_url = f\"https://oauth2:{ms_access_token}@www.modelscope.cn/{repo_id}.git\"\n",
    "        elif repo_type == \"dataset\":\n",
    "            repo_url = f\"https://oauth2:{ms_access_token}@www.modelscope.cn/datasets/{repo_id}.git\"\n",
    "        elif repo_type == \"space\":\n",
    "            repo_url = f\"https://oauth2:{ms_access_token}@www.modelscope.cn/studios/{repo_id}.git\"\n",
    "\n",
    "        !git clone \"{repo_url}\" \"{path}\"\n",
    "\n",
    "        # 启用 Git LFS\n",
    "        os.environ[\"GIT_LFS_SKIP_SMUDGE\"] = \"0\"\n",
    "        !git -C \"{path}\" lfs install\n",
    "\n",
    "\n",
    "    def push_file_to_modelscope(self, ms_access_token, repo_id, repo_type, work_path, upload_path):\n",
    "        \"\"\"将指定路径中的文件上传到 ModelScope 中\n",
    "        参数:\n",
    "            ms_access_token:\n",
    "                ModelScope 账号的 Token\n",
    "\n",
    "            repo_id:\n",
    "                ModelScope 仓库的 ID\n",
    "\n",
    "            repo_type:\n",
    "                ModelScope 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 创空间仓库\n",
    "\n",
    "            work_path:\n",
    "                将仓库下载到本地的路径\n",
    "\n",
    "            upload_path:\n",
    "                要上传文件到 ModelScope 仓库的路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        from modelscope.hub.api import HubApi\n",
    "        api = HubApi()\n",
    "\n",
    "        echo(\"验证 ModelScope Token 中\")\n",
    "        try:\n",
    "            ms_access_token = api.login(ms_access_token)[0] # 将 ModelScope Token 转为 ModelScope Git Token\n",
    "            echo(\"ModelScope Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"ModelScope Token 验证失败: \", e)\n",
    "            return\n",
    "\n",
    "        repo_name = repo_id.split(\"/\").pop() # 仓库名称\n",
    "        tmp_work_path = os.path.join(work_path, f\"__ms_repo_{repo_name}__\") # 临时的工作路径\n",
    "        repo_local_path = os.path.join(tmp_work_path, repo_name) # 仓库对应的本地绝对路径\n",
    "        upload_file_lists = self.get_all_file(upload_path) # 原文件的绝对路径列表\n",
    "        # 统计信息\n",
    "        count = 0\n",
    "        sum = len(upload_file_lists)\n",
    "\n",
    "        echo(f\"将文件上传至 ModelScope:: {upload_path} -> {repo_local_path}\")\n",
    "        echo(f\"使用的 ModelScope 仓库: {repo_id}, 类型: {repo_type}\")\n",
    "\n",
    "        for upload_file in upload_file_lists:\n",
    "            count += 1\n",
    "            rel_upload_file = os.path.relpath(upload_file, upload_path) # 原文件相对路径\n",
    "            upload_file_name = os.path.basename(upload_file)\n",
    "            # Git 仓库的配置信息\n",
    "            if repo_type == \"model\":\n",
    "                git_repo_config = f\"lfs.https://oauth2:{ms_access_token}@www.modelscope.cn/{repo_id}.git/info/lfs.locksverify\"\n",
    "            elif repo_type == \"dataset\":\n",
    "                git_repo_config = f\"lfs.https://oauth2:{ms_access_token}@www.modelscope.cn/datasets/{repo_id}.git/info/lfs.locksverify\"\n",
    "            elif repo_type == \"space\":\n",
    "                git_repo_config = f\"lfs.https://oauth2:{ms_access_token}@www.modelscope.cn/studios/{repo_id}.git/info/lfs.locksverify\"\n",
    "\n",
    "            # 下载仓库到本地\n",
    "            echo(f\"[{count}/{sum}]:: 克隆仓库到 {tmp_work_path}\")\n",
    "            self.clone_modelscope_without_lfs(\n",
    "                ms_access_token=ms_access_token,\n",
    "                repo_id=repo_id,\n",
    "                repo_type=repo_type,\n",
    "                work_path=tmp_work_path\n",
    "            )\n",
    "\n",
    "            echo(f\"[{count}/{sum}]:: 要上传的文件的相对路径: {rel_upload_file}\")\n",
    "            echo(f\"[{count}/{sum}]:: 要上传的文件的绝对路径: {upload_file}\")\n",
    "            echo(f\"[{count}/{sum}]:: 仓库本地绝对路径: {repo_local_path}\")\n",
    "\n",
    "            # 检测文件是否存在于仓库中\n",
    "            if self.is_file_exists_in_ms_repo(\n",
    "                upload_file=rel_upload_file,\n",
    "                work_path=tmp_work_path,\n",
    "                repo_id=repo_id\n",
    "            ):\n",
    "                !rm -rf \"{repo_local_path}\"\n",
    "                echo(f\"[{count}/{sum}]:: {upload_file_name} 已存在于仓库中\")\n",
    "                continue\n",
    "\n",
    "            # 为仓库创建文件对应的父文件夹\n",
    "            p_path = os.path.dirname(os.path.join(tmp_work_path, repo_name, rel_upload_file)) # 原文件到仓库中后对应的父文件夹\n",
    "            if not os.path.exists(p_path):\n",
    "                echo(f\"[{count}/{sum}]:: 为 {upload_file_name} 创建对应的父文件夹: {p_path}\")\n",
    "                os.makedirs(p_path, exist_ok=True)\n",
    "\n",
    "            # 复制文件到仓库中\n",
    "            echo(f\"[{count}/{sum}]:: {upload_file} -> {repo_local_path}\")\n",
    "            !cp -f \"{upload_file}\" \"{p_path}\"\n",
    "\n",
    "            # 对文件进行追踪\n",
    "            file_name = os.path.basename(rel_upload_file) # 文件名\n",
    "            echo(f\"[{count}/{sum}]:: 添加文件： {rel_upload_file}\")\n",
    "            !git -C \"{repo_local_path}\" add \"{rel_upload_file}\"\n",
    "\n",
    "            # 创建提交信息\n",
    "            echo(f\"[{count}/{sum}]:: 提交信息: \\\"Upload {file_name}\\\"\")\n",
    "            !git -C \"{repo_local_path}\" commit -m \"upload {file_name}\"\n",
    "            !git -C \"{repo_local_path}\" config \"{git_repo_config}\" true\n",
    "\n",
    "            # 推送文件到 ModelScope\n",
    "            echo(f\"[{count}/{sum}]:: 上传 {file_name} 到 {repo_id} 中\")\n",
    "            !git -C \"{repo_local_path}\" push\n",
    "\n",
    "            # 清理仓库文件\n",
    "            !rm -rf \"{repo_local_path}\"\n",
    "            echo(f\"[{count}/{sum}]:: 上传 {file_name} 完成\")\n",
    "\n",
    "        # 清理临时工作路径\n",
    "        !rm -rf \"{tmp_work_path}\"\n",
    "        echo(f\"[{count}/{sum}]:: {repo_id} 仓库上传完成\")\n",
    "\n",
    "\n",
    "    # HuggingFace\n",
    "\n",
    "    def get_hf_repo_file_list(self, hf_access_token, repo_id, repo_type):\n",
    "        \"\"\"从 HuggingFace 获取仓库中所有文件路径\n",
    "        参数:\n",
    "            hf_access_token:\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "            repo_id:\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type:\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "        返回值:\n",
    "            `list`: 所有文件在 HuggingFace 仓库中的路径\n",
    "        \"\"\"\n",
    "        from huggingface_hub import HfApi\n",
    "        api = HfApi()\n",
    "        model_list = api.list_repo_files(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type,\n",
    "            token=hf_access_token\n",
    "        )\n",
    "        return model_list\n",
    "\n",
    "\n",
    "    def push_file_to_huggingface(self, hf_access_token, repo_id, repo_type, upload_path):\n",
    "        \"\"\"上传文件到 HuggingFace 中\n",
    "        参数:\n",
    "            hf_access_token:\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "            repo_id:\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type:\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            upload_path:\n",
    "                要上传到 HuggingFace 仓库的文件本地路径\n",
    "        \"\"\"\n",
    "        import os\n",
    "        from pathlib import Path\n",
    "        from huggingface_hub import HfApi, CommitOperationAdd\n",
    "        api = HfApi()\n",
    "\n",
    "        try:\n",
    "            api.whoami(token=hf_access_token)\n",
    "            echo(\"HuggingFace Token 验证成功\")\n",
    "        except Exception as e:\n",
    "            echo(\"HuggingFace Token 验证失败: \", e)\n",
    "\n",
    "        upload_file_lists = self.get_all_file(upload_path) # 原文件的路径列表\n",
    "        hf_repo_flie_list = self.get_hf_repo_file_list(hf_access_token, repo_id, repo_type) # 获取仓库中的文件列表\n",
    "        # 统计信息\n",
    "        count = 0\n",
    "        sum = len(upload_file_lists)\n",
    "\n",
    "        echo(f\"将文件上传至 HuggingFace:: {upload_path} -> {repo_id}\")\n",
    "        echo(f\"使用的 HuggingFace 仓库: {repo_id}, 种类: {repo_type}\")\n",
    "\n",
    "        for upload_file in upload_file_lists:\n",
    "            count += 1\n",
    "            rel_upload_file = os.path.relpath(upload_file, upload_path) # 原文件相对路径\n",
    "            file_name = os.path.basename(upload_file) # 文件名\n",
    "            hf_path_in_repo = Path(rel_upload_file).as_posix() # 文件在仓库中的路径\n",
    "            local_file_obj = Path(upload_file).as_posix() # 文件在本地的绝对路径\n",
    "\n",
    "            echo(f\"[{count}/{sum}]:: 要上传的文件的相对路径: {rel_upload_file}\")\n",
    "            echo(f\"[{count}/{sum}]:: 绝对路径: {upload_file}\")\n",
    "\n",
    "            # 检测文件是否存在于仓库中\n",
    "            if rel_upload_file in hf_repo_flie_list:\n",
    "                echo(f\"[{count}/{sum}]:: {file_name} 已存在于仓库中\")\n",
    "                continue\n",
    "\n",
    "            # 对文件进行追踪\n",
    "            echo(f\"[{count}/{sum}]:: {local_file_obj} -> {repo_id}/{hf_path_in_repo}\")\n",
    "            operations = [\n",
    "                CommitOperationAdd(\n",
    "                    path_in_repo=hf_path_in_repo,\n",
    "                    path_or_fileobj=local_file_obj\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            # 上传文件到 HuggingFace\n",
    "            echo(f\"[{count}/{sum}]:: 上传 {file_name} 到 {repo_id} 中\")\n",
    "            try:\n",
    "                api.create_commit(\n",
    "                    repo_id=repo_id,\n",
    "                    operations=operations,\n",
    "                    commit_message=f\"Upload {file_name}\",\n",
    "                    repo_type=repo_type,\n",
    "                    token=hf_access_token\n",
    "                )\n",
    "                echo(f\"[{count}/{sum}]:: 上传 {file_name} 完成\")\n",
    "            except Exception as e:\n",
    "                echo(f\"[{count}/{sum}]:: 上传 {file_name} 失败\", e)\n",
    "\n",
    "        echo(f\"[{count}/{sum}]:: {repo_id} 仓库上传完成\")\n",
    "\n",
    "\n",
    "    def set_git_config(self, email, username):\n",
    "        \"\"\"配置 Git 信息\n",
    "        参数:\n",
    "            email:\n",
    "                邮箱地址\n",
    "\n",
    "            username:\n",
    "                用户名\n",
    "        \"\"\"\n",
    "        echo(\"配置 Git 信息中\")\n",
    "        !git config --global user.email \"{email}\"\n",
    "        !git config --global user.name \"{username}\"\n",
    "\n",
    "\n",
    "\n",
    "class HF_DATASET():\n",
    "    \"HuggingFace 数据集处理\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def get_hf_file_list(self, repo_id, repo_type, hf_token) -> list:\n",
    "        \"\"\"从 HuggingFace 仓库中获取所有文件的路径\n",
    "        参数:\n",
    "            repo_id:\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type:\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            hf_token:\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "        返回值:\n",
    "            `list`: 所有文件在 HuggingFace 仓库中的路径\n",
    "        \"\"\"\n",
    "        from huggingface_hub import HfApi\n",
    "        echo(f\"获取 {repo_id} (类型: {repo_type}) 中所有的文件列表中\")\n",
    "        api = HfApi()\n",
    "        model_list = api.list_repo_files(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type,\n",
    "            token=hf_token\n",
    "        )\n",
    "        echo(f\"{repo_id} 中所有文件的数量: {len(model_list)}\")\n",
    "        return model_list\n",
    "\n",
    "\n",
    "    def download_hf_file(self, repo_id, repo_type, filename, local_dir, hf_token):\n",
    "        \"\"\"从 HuggingFace 仓库下载文件到本地路径\n",
    "        参数:\n",
    "            repo_id:\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type:\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            filename:\n",
    "                文件在 HuggingFace 仓库中的路径\n",
    "\n",
    "            local_dir:\n",
    "                将文件下载到的本地路径\n",
    "\n",
    "            hf_token:\n",
    "                HuggingFace 账号 Token\n",
    "        \"\"\"\n",
    "        from huggingface_hub import hf_hub_download\n",
    "        try:\n",
    "            hf_hub_download(\n",
    "                repo_id=repo_id,\n",
    "                repo_type=repo_type,\n",
    "                filename=filename,\n",
    "                local_dir=local_dir,\n",
    "                token=hf_token\n",
    "            )\n",
    "        except Exception as e:\n",
    "            echo(f\"{filename} 下载失败, {e}\")\n",
    "\n",
    "\n",
    "    def filter_file(self, file_list, start_dir):\n",
    "        \"\"\"从文件列表中过滤出指定的文件列表\n",
    "        参数:\n",
    "            file_list (list):\n",
    "                所有文件列表\n",
    "\n",
    "            start_dir:\n",
    "                指定文件所在的路径, 并过滤出新的文件列表\n",
    "\n",
    "        返回值:\n",
    "            `list`: 过滤后的文件列表\n",
    "        \"\"\"\n",
    "        filter_file_list = []\n",
    "        for f in file_list:\n",
    "            if f.startswith(start_dir):\n",
    "                filter_file_list.append(f)\n",
    "\n",
    "        echo(f\"{start_dir} 中的文件数量: {len(filter_file_list)}\")\n",
    "        return filter_file_list\n",
    "\n",
    "\n",
    "\n",
    "class HFDatasetDownloader:\n",
    "    \"\"\"HuggingFace 数据集下载器\"\"\"\n",
    "    def __init__(self, urls) -> None:\n",
    "        import threading\n",
    "        from queue import Queue\n",
    "        self.hf_dataset = HF_DATASET()\n",
    "        self.urls = urls\n",
    "        self.queue = Queue()\n",
    "        self.total_urls = len(urls)  # 记录总的URL数\n",
    "        self.downloaded_count = 0  # 记录已下载的数量\n",
    "        self.lock = threading.Lock()  # 创建锁以保护对下载计数器的访问\n",
    "\n",
    "\n",
    "    def worker(self):\n",
    "        \"\"\"调用文件下载工具\"\"\"\n",
    "        while True:\n",
    "            url = self.queue.get()\n",
    "            if url is None:\n",
    "                break\n",
    "            self.hf_dataset.download_hf_file(\n",
    "                repo_id=url[0],\n",
    "                repo_type=url[1],\n",
    "                filename=url[2],\n",
    "                local_dir=url[3],\n",
    "                hf_token=url[4]\n",
    "            )\n",
    "            self.queue.task_done()\n",
    "            with self.lock:  # 访问共享资源时加锁\n",
    "                self.downloaded_count += 1\n",
    "                self.print_progress()  # 打印进度\n",
    "\n",
    "\n",
    "    def print_progress(self):\n",
    "        \"\"\"显示下载进度条\"\"\"\n",
    "        progress = (self.downloaded_count / self.total_urls) * 100\n",
    "        echo(f\"下载进度: {self.downloaded_count}/{self.total_urls} ({progress:.2f}%)\")\n",
    "\n",
    "\n",
    "    def start_threads(self, num_threads=16):\n",
    "        \"\"\"启动多线程下载器\n",
    "\n",
    "        参数:\n",
    "            num_threads:\n",
    "                下载线程\n",
    "        \"\"\"\n",
    "        import threading\n",
    "        threads = []\n",
    "        for _ in range(num_threads):\n",
    "            thread = threading.Thread(target=self.worker)\n",
    "            thread.start()\n",
    "            threads.append(thread)\n",
    "\n",
    "        for url in self.urls:\n",
    "            self.queue.put(url)\n",
    "\n",
    "        self.queue.join()\n",
    "\n",
    "        for _ in range(num_threads):\n",
    "            self.queue.put(None)\n",
    "\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "\n",
    "\n",
    "\n",
    "class DATASET(ARIA2):\n",
    "    \"\"\"数据集下载工具\"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self.hf_dataset = HF_DATASET()\n",
    "\n",
    "\n",
    "    def get_dataset(self, dataset_path, url, name = None):\n",
    "        \"\"\"从下载链接获取数据集\n",
    "\n",
    "        参数:\n",
    "            dataset_path:\n",
    "                数据集的存放路径\n",
    "\n",
    "            url:\n",
    "                数据集的下载链接\n",
    "\n",
    "            name:\n",
    "                将下载的文件进行重命名\n",
    "        \"\"\"\n",
    "        import os\n",
    "        path = \"/tmp\"\n",
    "        if name is None:\n",
    "            name = url.split(\"/\").pop()\n",
    "\n",
    "        super().aria2(url, path, name) # 下载文件\n",
    "\n",
    "        archive_format = name.split(\".\").pop() # 压缩包格式\n",
    "        origin_file_path = os.path.join(path, name) # 将文件下载到的本地路径\n",
    "\n",
    "        # 解压文件\n",
    "        echo(f\"尝试解压 {name}\")\n",
    "        if archive_format == \"7z\":\n",
    "            !7z x \"{origin_file_path}\" -o\"{dataset_path}\"\n",
    "        elif archive_format == \"zip\":\n",
    "            !unzip \"{origin_file_path}\" -d \"{dataset_path}\"\n",
    "        elif archive_format == \"tar\":\n",
    "            !tar -xvf \"{origin_file_path}\" -C \"{dataset_path}\"\n",
    "        else:\n",
    "            echo(f\"{name} 的格式不支持解压\")\n",
    "\n",
    "\n",
    "    def get_dataset_from_hf(self, local_path, repo_id, repo_type, folder = None, hf_token = None):\n",
    "        \"\"\"从 HuggingFace 下载训练集\n",
    "\n",
    "        参数:\n",
    "            local_path:\n",
    "                将数据集下载到本地的路径\n",
    "\n",
    "            repo_id:\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type:\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            folder:\n",
    "                指定要下载 HuggingFace 中指定的文件夹, 例如:\n",
    "\n",
    "            hf_token:\n",
    "                HuggingFace 账号 Token\n",
    "\n",
    "\n",
    "        说明:\n",
    "            folder 未指定时, 则下载 HuggingFace 仓库中的所有文件, 如果 folder 指定了, 例如指定的是`aaaki`\n",
    "            \n",
    "            而仓库的文件结构如下:\n",
    "\n",
    "            ```\n",
    "            HuggingFace Repo\n",
    "            ├── Nachoneko\n",
    "            │   ├── 1_nachoneko\n",
    "            │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "            │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "            │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "            │   │       └── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "            │   ├── 2_nachoneko\n",
    "            │   │       ├── 0(8).txt\n",
    "            │   │       ├── 0(8).webp\n",
    "            │   │       ├── 001_2.png\n",
    "            │   │       └── 001_2.txt\n",
    "            │   └── 4_nachoneko\n",
    "            │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "            │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "            │           ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "            │           └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "            └ aaaki\n",
    "                ├── 1_aaaki\n",
    "                │   ├── 1.png\n",
    "                │   ├── 1.txt\n",
    "                │   ├── 11.png\n",
    "                │   ├── 11.txt\n",
    "                │   ├── 12.png\n",
    "                │   └── 12.txt\n",
    "                └── 3_aaaki\n",
    "                    ├── 14.png\n",
    "                    ├── 14.txt\n",
    "                    ├── 16.png\n",
    "                    └── 16.txt\n",
    "            ```\n",
    "\n",
    "            则使用该函数下载 HuggingFace 仓库的文件时将下载`aaaki`文件夹中的所有文件, 而`Nachoneko`文件夹中的文件不会被下载\n",
    "        \"\"\"\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        echo(f\"从 {repo_id} (类型: {repo_type}) 下载数据集\")\n",
    "        # 从 HuggingFace 仓库中获取所有文件列表\n",
    "        hf_file_list = self.hf_dataset.get_hf_file_list(\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type,\n",
    "            hf_token=hf_token\n",
    "        )\n",
    "\n",
    "        # 指定 folder 时过滤出新的文件列表\n",
    "        if folder is None:\n",
    "            filter_file_list = hf_file_list\n",
    "        else:\n",
    "            echo(f\"指定下载 {folder} 中的文件\")\n",
    "            filter_file_list = self.hf_dataset.filter_file(hf_file_list, folder)\n",
    "\n",
    "        # 创建下载任务\n",
    "        task = []\n",
    "        for file in tqdm(filter_file_list, desc=\"创建下载任务\"):\n",
    "            task.append([repo_id, repo_type, file, local_path, hf_token])\n",
    "\n",
    "        # 从 HuggingFace 仓库下载文件\n",
    "        echo(f\"下载 {repo_id} 中的文件中\")\n",
    "        dataset_downloader = HFDatasetDownloader(task)\n",
    "        dataset_downloader.start_threads(num_threads=32)\n",
    "        echo(f\"从 {repo_id} 下载数据集文件完成\")\n",
    "\n",
    "\n",
    "    def get_single_file_from_hf(repo_id: str, repo_type: str, filename: str, local_dir: str, token: str = None):\n",
    "        \"\"\"从 HuggingFace 仓库下载单个文件\n",
    "\n",
    "        参数:\n",
    "            repo_id (str):\n",
    "                HuggingFace 仓库的 ID\n",
    "\n",
    "            repo_type (str):\n",
    "                HuggingFace 仓库种类 (model / dataset / space), 仓库有以下类型:\n",
    "\n",
    "                    - model: 模型仓库\n",
    "                    - dataset: 数据集仓库\n",
    "                    - space: 在线运行空间仓库\n",
    "\n",
    "            filename (str):\n",
    "                文件在 HuggingFace 仓库中的路径\n",
    "\n",
    "            local_dir (str):\n",
    "                将文件下载到本地的路径\n",
    "\n",
    "            token (str):\n",
    "                HuggingFace 账号 Token\n",
    "        \"\"\"\n",
    "        import os\n",
    "        from huggingface_hub import hf_hub_download\n",
    "\n",
    "        repo_name = repo_id.split(\"/\").pop()\n",
    "        tmp = \"/tmp\"\n",
    "        tmp_path = os.path.join(tmp, f\"__hf_file_downloader_{repo_name}_tmp__\") # 临时文件路径\n",
    "        file_path = os.path.join(local_dir, filename.split(\"/\").pop()) # 下载文件到本地的路径\n",
    "\n",
    "        # 从 HuggingFace 下载文件\n",
    "        echo(f\"从 {repo_id} (类型: {repo_type}) 下载 {filename} 中, 路径: {file_path}\")\n",
    "        try:\n",
    "            hf_file_path = hf_hub_download(\n",
    "                repo_id=repo_id,\n",
    "                repo_type=repo_type,\n",
    "                filename=filename,\n",
    "                local_dir=tmp_path,\n",
    "                token=token\n",
    "            )\n",
    "\n",
    "            !mv -f \"{hf_file_path}\" \"{local_dir}\"\n",
    "            echo(f\"{filename} 下载完成\")\n",
    "        except Exception as e:\n",
    "            echo(f\"从 {repo_id} 下载 {filename} 失败\", e)\n",
    "\n",
    "\n",
    "\n",
    "class SD_SCRIPTS(ARIA2, GIT, MANAGER, ENV):\n",
    "    \"\"\"sd-scripts 管理工具\"\"\"\n",
    "    WORKSPACE = \"\"\n",
    "    WORKFOLDER = \"\"\n",
    "\n",
    "    repo_manager = REPO_MANAGER()\n",
    "    dataset = DATASET()\n",
    "\n",
    "    def __init__(self, workspace, workfolder) -> None:\n",
    "        self.WORKSPACE = workspace\n",
    "        self.WORKFOLDER = workfolder\n",
    "\n",
    "\n",
    "    def get_model(self, url, path, filename = None):\n",
    "        \"\"\"下载模型文件到本地中\n",
    "        \n",
    "        参数:\n",
    "            url:\n",
    "                模型文件的下载链接\n",
    "\n",
    "            path:\n",
    "                模型文件下载到本地的路径\n",
    "\n",
    "            filename:\n",
    "                指定下载的模型文件名称\n",
    "        \"\"\"\n",
    "        import os\n",
    "        filename = url.split(\"/\").pop() if filename is None else filename\n",
    "        super().aria2(url, path, filename)\n",
    "\n",
    "\n",
    "    def get_model_from_list(self, path, model_list: list):\n",
    "        \"\"\"从模型列表下载模型\n",
    "        参数:\n",
    "            path:\n",
    "                将模型下载到的本地路径\n",
    "\n",
    "            model_list (list):\n",
    "                模型列表\n",
    "\n",
    "        使用:\n",
    "            model_list (list) 需要指定模型下载的链接和下载状态, 例如\n",
    "\n",
    "            ```python\n",
    "            model_list = [\n",
    "                [\"url1\", 0],\n",
    "                [\"url2\", 1],\n",
    "                [\"url3\", 0],\n",
    "                [\"url4\", 1, \"file.safetensors\"]\n",
    "            ]\n",
    "            ```\n",
    "\n",
    "            在这个例子中, 第一个参数指定了模型的下载链接, 第二个参数设置了是否要下载这个模型, 当这个值为 1 时则下载该模型\n",
    "\n",
    "            第三个参数是可选参数, 用于指定下载到本地后的文件名称\n",
    "\n",
    "            则上面的例子中`url2`和`url4`下载链接所指的文件将被下载, 并且`url4`所指的文件将被重命名为`file.safetensors`\n",
    "        \"\"\"\n",
    "        for model in model_list:\n",
    "            url = model[0]\n",
    "            status = model[1]\n",
    "            filename = model[2] if len(model) > 2 else None\n",
    "            if status == 1:\n",
    "                if filename is None:\n",
    "                    self.get_model(\n",
    "                        url=url,\n",
    "                        path=path\n",
    "                    )\n",
    "                else:\n",
    "                    self.get_model(\n",
    "                        url=url,\n",
    "                        path=path,\n",
    "                        filename=filename\n",
    "                    )\n",
    "\n",
    "\n",
    "    def install(self, torch_ver, xformers_ver, git_branch, git_commit, model_path, model_list, use_uv):\n",
    "        \"\"\"安装 sd-scripts 和其余环境\n",
    "\n",
    "        参数:\n",
    "            torch_ver:\n",
    "                指定的 PyTorch 软件包包名, 并包括版本号\n",
    "\n",
    "            xformers_ver:\n",
    "                指定的 xFormers 软件包包名, 并包括版本号\n",
    "\n",
    "            git_branch:\n",
    "                指定要切换 sd-scripts 的分支\n",
    "\n",
    "            git_commit:\n",
    "                指定要切换到 sd-scripts 的提交记录\n",
    "\n",
    "            model_path:\n",
    "                指定模型下载的路径\n",
    "\n",
    "            model_list:\n",
    "                模型下载列表\n",
    "\n",
    "            use_uv:\n",
    "                使用 uv 替代 Pip 进行 Python 软件包的安装\n",
    "        \"\"\"\n",
    "        import os\n",
    "        sd_scripts_path = os.path.join(self.WORKSPACE, self.WORKFOLDER)\n",
    "        req_file = os.path.join(sd_scripts_path, \"requirements.txt\")\n",
    "        sd_scripts_repo = \"https://github.com/kohya-ss/sd-scripts\"\n",
    "\n",
    "        self.check_gpu() # 检查是否有可用的 GPU\n",
    "        self.prepare_env_depend(use_uv=use_uv) # 准备 Notebook 的运行依赖\n",
    "        # 下载 sd-scripts\n",
    "        self.clone(\n",
    "            addr=sd_scripts_repo,\n",
    "            path=self.WORKSPACE,\n",
    "            name=self.WORKFOLDER\n",
    "        )\n",
    "        # 切换指定的 sd-scripts 分支\n",
    "        self.checkout(\n",
    "            path=sd_scripts_path,\n",
    "            branch=git_branch\n",
    "        )\n",
    "        # 切换到指定的 sd-scripts 提交记录\n",
    "        self.reset(\n",
    "            path=sd_scripts_path,\n",
    "            commit=git_commit\n",
    "        )\n",
    "        # 安装 PyTorch 和 xFormers\n",
    "        self.prepare_torch(\n",
    "            torch_ver=torch_ver,\n",
    "            xformers_ver=xformers_ver,\n",
    "            use_uv=use_uv\n",
    "        )\n",
    "        # 安装 sd-scripts 的依赖\n",
    "        self.install_requirements(\n",
    "            path=req_file,\n",
    "            use_uv=use_uv\n",
    "        )\n",
    "        # 安装使用 sd-scripts 进行训练所需的其他软件包\n",
    "        self.py_pkg_manager(\n",
    "            pkg=\"lycoris-lora dadaptation open-clip-torch wandb\",\n",
    "            type=\"install\",\n",
    "            use_uv=use_uv\n",
    "        )\n",
    "        # 确保 PyTorch 和 xFormers 版本的正确\n",
    "        self.prepare_torch(\n",
    "            torch_ver=torch_ver,\n",
    "            xformers_ver=xformers_ver,\n",
    "            use_uv=use_uv\n",
    "        )\n",
    "        # 更新 urllib3\n",
    "        self.py_pkg_manager(\n",
    "            pkg=\"urllib3\",\n",
    "            type=\"update\",\n",
    "            use_uv=False\n",
    "        )\n",
    "        self.tcmalloc() # 设置 TCMalloc 内存优化\n",
    "        self.get_model_from_list(\n",
    "            path=model_path,\n",
    "            model_list=model_list\n",
    "        )\n",
    "\n",
    "\n",
    "###################################\n",
    "echo(\"初始化功能完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数配置\n",
    "2. [[← 上一个单元](#功能初始化)|[下一个单元 →](#安装)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境设置\n",
    "WORKSPACE = \"/kaggle\" # 工作路径, 通常不需要修改\n",
    "WORKFOLDER = \"sd-scripts\" # 工作路径中文件夹名称, 通常不需要修改\n",
    "SD_SCRIPTS_PATH = \"/kaggle/sd-scripts\" # sd-scripts 的路径\n",
    "TORCH_VER = \"torch==2.5.0+cu121 torchvision==0.20.0+cu121 torchaudio==2.5.0+cu121\" # PyTorch 版本\n",
    "XFORMERS_VER = \"xformers==0.0.28.post2\" # xFormers 版本\n",
    "USE_UV = True # 使用 uv 加速 Python 软件包安装, 修改为 True 为启用, False 为禁用\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# sd-scripts 版本设置\n",
    "SD_SCRIPTS_BRANCH = \"dev\" # sd-scripts 分支, 可切换成 main / dev 或者其它分支, 留空则不进行切换\n",
    "SD_SCRIPTS_COMMIT = \"\" # 切换 sd-scripts 的版本到某个 Git 提交记录上, 留空则不进行切换\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# 模型上传设置, 使用 HuggingFace / ModelScope 上传训练好的模型\n",
    "# HuggingFace: https://huggingface.co\n",
    "# ModelScope: https://modelscope.cn\n",
    "USE_HF_TO_SAVE_MODEL = False # 使用 HuggingFace 保存训练好的模型, 修改为 True 为启用, False 为禁用\n",
    "USE_MS_TO_SAVE_MODEL = False # 使用 ModelScope 保存训练好的模型, 修改为 True 为启用, False 为禁用\n",
    "\n",
    "# HuggingFace Token 在 Account -> Settings -> Access Tokens 中获取\n",
    "HF_TOKEN = \"\" # HuggingFace Token\n",
    "# ModelScope Token 在 首页 -> 访问令牌 -> SDK 令牌 中获取\n",
    "MS_TOKEN = \"\" # ModelScope Token\n",
    "\n",
    "# HuggingFace 模型仓库的 ID, 需要在 HuggingFace 上提前新建一个模型仓库\n",
    "HF_REPO_ID = \"username/reponame\" # HuggingFace 仓库的 ID\n",
    "HF_REPO_TYPE = \"model\" # HuggingFace 仓库的种类 (可选的类型为: model / dataset / space), 如果在 HuggingFace 新建的仓库为模型仓库则不需要修改\n",
    "# HuggingFace 仓库类型和对应名称:\n",
    "# model: 模型仓库\n",
    "# dataset: 数据集仓库\n",
    "# space: 在线运行空间仓库\n",
    "\n",
    "# ModelScope 模型仓库的 ID, 需要在 ModelScope 上提前新建一个模型仓库\n",
    "MS_REPO_ID = \"username/reponame\" # ModelScope 仓库的 ID\n",
    "MS_REPO_TYPE = \"model\" # ModelScope 仓库的种类 (model / dataset / space), 如果在 ModelScope 新建的仓库为模型仓库则不需要修改\n",
    "# ModelScope 仓库类型和对应名称:\n",
    "# model: 模型仓库\n",
    "# dataset: 数据集仓库\n",
    "# space: 创空间仓库\n",
    "\n",
    "# Git 信息设置, 用于上传模型至 ModelScope 时使用, 可以使用默认值\n",
    "GIT_USER_EMAIL = \"username@xxx.com\" # Git 的邮箱\n",
    "GIT_USER_NAME = \"username\" # Git 的用户名\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# 路径设置, 通常保持默认即可\n",
    "INPUT_DATASET_PATH = \"/kaggle/dataset\" # 训练集保存的路径\n",
    "OUTPUT_PATH = \"/kaggle/working/model\" # 训练时模型保存的路径\n",
    "SD_MODEL_PATH = \"/kaggle/sd-scripts/sd-models\" # 模型下载到的路径\n",
    "KAGGLE_INPUT_PATH = \"/kaggle/input\" # Kaggle Input 的路径\n",
    "\n",
    "##############################################################################\n",
    "\n",
    "# 训练模型设置, 在安装时将会下载选择的模型\n",
    "# 下面举个例子:\n",
    "# SD_MODEL = [\n",
    "#     [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/v1-5-pruned-emaonly.safetensors\", 0],\n",
    "#     [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/animefull-final-pruned.safetensors\", 1],\n",
    "#     [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/Counterfeit-V3.0_fp16.safetensors\", 0],\n",
    "#     [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v0.1.safetensors\", 1, \"Illustrious.safetensors\"]\n",
    "# ]\n",
    "# \n",
    "# 在这个例子中, 第一个参数指定了模型的下载链接, 第二个参数设置了是否要下载这个模型, 当这个值为 1 时则下载该模型\n",
    "# 第三个参数是可选参数, 用于指定下载到本地后的文件名称\n",
    "# \n",
    "# 则上面的例子中\n",
    "# https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/animefull-final-pruned.safetensors 和 \n",
    "# https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v0.1.safetensors 下载链接所指的文件将被下载\n",
    "# https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/animefull-final-pruned.safetensors 的文件下载到本地后名称为 animefull-final-pruned.safetensors\n",
    "# 并且 https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v0.1.safetensors 所指的文件将被重命名为 Illustrious.safetensors\n",
    "\n",
    "SD_MODEL = [\n",
    "    # Stable Diffusion 模型\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/v1-5-pruned-emaonly.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/animefull-final-pruned.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/Counterfeit-V3.0_fp16.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/cetusMix_Whalefall2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/cuteyukimixAdorable_neochapter3.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/ekmix-pastel-fp16-no-ema.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/ex2K_sse2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/kohakuV5_rev2.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/meinamix_meinaV11.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/oukaStar_10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/pastelMixStylizedAnime_pastelMixPrunedFP16.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/rabbit_v6.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/sweetSugarSyndrome_rev15.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/AnythingV5Ink_ink.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/bartstyledbBlueArchiveArtStyleFineTunedModel_v10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/meinapastel_v6Pastel.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/qteamixQ_omegaFp16.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sd_1.5/tmndMix_tmndMixSPRAINBOW.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/sd_xl_base_1.0_0.9vae.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animagine-xl-3.0.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/AnythingXL_xl.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/abyssorangeXLElse_v10.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animaPencilXL_v200.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/animagine-xl-3.1.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/heartOfAppleXL_v20.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/baxlBartstylexlBlueArchiveFlatCelluloid_xlv1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohaku-xl-delta-rev1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohakuXLEpsilon_rev1.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohaku-xl-epsilon-rev3.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/kohaku-xl-zeta.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/nekorayxl_v06W3.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/CounterfeitXL-V1.0.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/ponyDiffusionV6XL_v6StartWithThisOne.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/Illustrious-XL-v0.1.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_earlyAccessVersion.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_epsilonPred05Version.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_epsilonPred075.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_epsilonPred077.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_epsilonPred10Version.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_epsilonPred11Version.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPredTestVersion.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred05Version.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred06Version.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred065SVersion.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred075SVersion.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred09RVersion.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-model/resolve/main/sdxl_1.0/noobaiXLNAIXL_vPred10Version.safetensors\", 0],\n",
    "\n",
    "    # VAE 模型\n",
    "    [\"https://huggingface.co/licyk/sd-vae/resolve/main/sd_1.5/vae-ft-ema-560000-ema-pruned.safetensors\", 0],\n",
    "    [\"https://huggingface.co/licyk/sd-vae/resolve/main/sd_1.5/vae-ft-mse-840000-ema-pruned.safetensors\", 1],\n",
    "    [\"https://huggingface.co/licyk/sd-vae/resolve/main/sdxl_1.0/sdxl_fp16_fix_vae.safetensors\", 1],\n",
    "]\n",
    "\n",
    "##############################################################################\n",
    "echo(\"参数设置完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装\n",
    "3. [[← 上一个单元](#参数配置)|[下一个单元 →](#模型训练)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化部分参数并执行安装命令\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "echo(\"初始化 sd-scripts 安装参数\")\n",
    "os.makedirs(WORKSPACE, exist_ok = True)\n",
    "os.chdir(WORKSPACE)\n",
    "sd_scripts = SD_SCRIPTS(WORKSPACE, WORKFOLDER)\n",
    "echo(f\"开始安装 sd-scripts\")\n",
    "\n",
    "\n",
    "# 安装 sd-scripts\n",
    "sd_scripts.install(\n",
    "    torch_ver=TORCH_VER,\n",
    "    xformers_ver=XFORMERS_VER,\n",
    "    git_branch=SD_SCRIPTS_BRANCH,\n",
    "    git_commit=SD_SCRIPTS_COMMIT,\n",
    "    model_path=SD_MODEL_PATH,\n",
    "    model_list=SD_MODEL,\n",
    "    use_uv=USE_UV\n",
    ")\n",
    "# sd_scripts.install() 将会以下几件事\n",
    "# 1. 安装 PyTorch / xFormers\n",
    "# 2. 安装 sd-scripts\n",
    "# 3. 安装 sd-scripts 的依赖\n",
    "# 4. 下载模型\n",
    "# 模型将会下载到 SD_MODEL_PATH 中, 即 /kaggle/sd-scripts/sd-models\n",
    "\n",
    "\n",
    "# 根据预设参数创建其他目录\n",
    "echo(\"创建其他目录\")\n",
    "os.makedirs(os.path.join(WORKSPACE, \"working\", \"MS_REPO\"), exist_ok = True) # 为 ModelScope 仓库创建临时文件夹\n",
    "os.makedirs(OUTPUT_PATH, exist_ok = True) # 创建训练时保存模型的路径(由 OUTPUT_PATH 变量设定)\n",
    "os.makedirs(INPUT_DATASET_PATH, exist_ok = True) # 创建存放训练集的路径(由 INPUT_DATASET_PATH 变量设定)\n",
    "\n",
    "\n",
    "# 将 KAGGLE_INPUT_PATH 内的文件移动到 INPUT_DATASET_PATH 指定的路径\n",
    "if os.path.exists(KAGGLE_INPUT_PATH):\n",
    "    echo(\"从 Kaggle Input 导入文件中\")\n",
    "    for i in tqdm(os.listdir(KAGGLE_INPUT_PATH), desc=\"文件导入\"):\n",
    "        f = os.path.join(KAGGLE_INPUT_PATH, i)\n",
    "        !cp -rf \"{f}\" \"{INPUT_DATASET_PATH}\"\n",
    "# 在 Kaggle 界面右侧中有 Kaggle Input 的功能, 可用于导入训练集 / 模型\n",
    "# 如果使用了 Kaggle Input 导入了训练集 / 模型, 则 KAGGLE_INPUT_PATH 中的所有文件将被复制到 INPUT_DATASET_PATH 中\n",
    "# 即将 /kaggle/input 中的所有文件复制到 /kaggle/dataset 中\n",
    "##########################################################################################\n",
    "# 下方的命令可以根据自己的需求进行修改\n",
    "\n",
    "\n",
    "##### 关于运行环境 #####\n",
    "\n",
    "# 如果需要安装某个软件包, 可以使用 sd_scripts.py_pkg_manager() 函数\n",
    "# 使用参数:\n",
    "# sd_scripts.py_pkg_manager(\n",
    "#     pkg=\"python packages name\", # Python 软件包名称, 可写多个\n",
    "#     type=\"pip operate type\"     # 对 Python 软件包的操作(install / install_single / force_install / force_install_single / update / uninstall)\n",
    "# )\n",
    "# \n",
    "# 以下是 type 可以指定的操作和对应的命令行参数\n",
    "# 安装: install -> install\n",
    "# 仅安装: install_single -> install --no-deps\n",
    "# 强制重装: force_install -> install --force-reinstall\n",
    "# 仅强制重装: force_install_single -> install --force-reinstall --no-deps\n",
    "# 更新: update -> install --upgrade\n",
    "# 卸载: uninstall -> uninstall -y\n",
    "# \n",
    "# 下面是几个使用例子:\n",
    "# 1.\n",
    "# sd_scripts.py_pkg_manager(\n",
    "#     pkg=\"lycoris-lora==2.1.0.post3 dadaptation==3.1\",\n",
    "#     type=\"install\"\n",
    "# )\n",
    "# 这将安装 lycoris-lora==2.1.0.post3 和 dadaptation==3.1\n",
    "# \n",
    "# 2.\n",
    "# sd_scripts.py_pkg_manager(\n",
    "#     pkg=\"tensorboard\",\n",
    "#     type=\"uninstall\"\n",
    "# )\n",
    "# 这将卸载 tensorboard\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "##### 关于模型下载 #####\n",
    "\n",
    "# 如果需要通过链接下载额外的模型, 可以使用 sd_scripts.get_model()\n",
    "# 使用参数:\n",
    "# sd_scripts.get_model(\n",
    "#     url=\"model_url\",                # 模型下载链接\n",
    "#     path=SD_MODEL_PATH,             # 模型下载到本地的路径\n",
    "#     filename=\"filename.safetensors\" # 模型的名称\n",
    "# )\n",
    "# 下面是几个使用例子:\n",
    "# 1.\n",
    "# sd_scripts.get_model(\n",
    "#     url=\"https://modelscope.cn/models/user/repo/resolve/master/your_model.safetensors\",\n",
    "#     path=SD_MODEL_PATH,\n",
    "# )\n",
    "# 这将从 https://modelscope.cn/models/user/repo/resolve/master/your_model.safetensors 下载模型并保存到 SD_MODEL_PATH 中\n",
    "# \n",
    "# sd_scripts.get_model(\n",
    "#     url=\"https://modelscope.cn/models/user/repo/resolve/master/your_model.safetensors\",\n",
    "#     path=SD_MODEL_PATH,\n",
    "#     filename=\"rename_model.safetensors\"\n",
    "# )\n",
    "# 这将从 https://modelscope.cn/models/user/repo/resolve/master/your_model.safetensors 下载模型并保存到 SD_MODEL_PATH 中, 并且重命名为 rename_model.safetensors\n",
    "\n",
    "\n",
    "# 如果需要从 HuggingFace 仓库下载模型, 可以使用 sd_scripts.dataset.get_single_file_from_hf()\n",
    "# 使用参数:\n",
    "# sd_scripts.dataset.get_single_file_from_hf(\n",
    "#     repo_id=\"usename/repo_id\",          # HuggingFace 仓库 ID\n",
    "#     repo_type=\"model\",                  # HuggingFace 仓库种类 (model / dataset / space)\n",
    "#     filename=\"abc/file.safetensors\",    # 文件在 HuggingFace 仓库中的路径\n",
    "#     local_dir=SD_MODEL_PATH,            # 模型下载到本地的路径\n",
    "#     token=\"your_huggingface_token\"      # HuggingFace Token\n",
    "# )\n",
    "# \n",
    "# 例如要从 stabilityai/stable-diffusion-xl-base-1.0 (类型为 model) 下载 sd_xl_base_1.0_0.9vae.safetensors\n",
    "# sd_scripts.dataset.get_single_file_from_hf(\n",
    "#     repo_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "#     repo_type=\"model\",\n",
    "#     filename=\"sd_xl_base_1.0_0.9vae.safetensors\",\n",
    "#     local_dir=SD_MODEL_PATH,\n",
    "# )\n",
    "# 则上述的命令将会从 stabilityai/stable-diffusion-xl-base-1.0 下载 sd_xl_base_1.0_0.9vae.safetensors 模型\n",
    "# 并将模型保存到 SD_MODEL_PATH 中\n",
    "# 如果仓库的为私有仓库, 需要 HuggingFace Token 才能访问, 则加上 token 参数, 填上自己的 Token (比如是 abcde)\n",
    "# sd_scripts.dataset.get_single_file_from_hf(\n",
    "#     repo_id=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "#     repo_type=\"model\",\n",
    "#     filename=\"sd_xl_base_1.0_0.9vae.safetensors\",\n",
    "#     local_dir=SD_MODEL_PATH,\n",
    "#     token=\"abcde\",\n",
    "# )\n",
    "# 这样就可以正常从仓库中下载文件\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "##### 关于训练集导入 #####\n",
    "\n",
    "# 在 Kaggle 界面的右侧包含 Kaggle Input 的功能, 可用于导入数据集\n",
    "# 除了使用 Kaggle Input 导入数据集, 还可以使用下面的方式导入数据集\n",
    "\n",
    "\n",
    "# 如果将训练集压缩后保存在某个平台, 如 HuggingFace, ModelScope, 并且有下载链接, 可以使用 sd_scripts.dataset.get_dataset() 函数下载训练集\n",
    "# 使用参数:\n",
    "# sd_scripts.dataset.get_dataset(\n",
    "#     dataset_path=\"path_to_local\",   # 下载数据集到本地的路径\n",
    "#     url=\"download_url\",             # 训练集压缩包的下载链接\n",
    "#     name=\"filename.zip\"             # 将数据集压缩包进行重命名\n",
    "# )\n",
    "# \n",
    "# 该函数在下载训练集压缩包完成后将解压到指定的本地路径\n",
    "# 压缩包格式仅支持 7z, zip, tar\n",
    "# \n",
    "# 下面是几个使用的例子:\n",
    "# 1.\n",
    "# sd_scripts.dataset.get_dataset(\n",
    "#     dataset_path=INPUT_DATASET_PATH,\n",
    "#     url=\"https://modelscope.cn/models/user/repo/resolve/master/data_1.7z\",\n",
    "# )\n",
    "# 这将从 https://modelscope.cn/models/user/repo/resolve/master/data_1.7z 下载训练集压缩包并解压到 INPUT_DATASET_PATH 中\n",
    "# \n",
    "# 2.\n",
    "# sd_scripts.dataset.get_dataset(\n",
    "#     dataset_path=INPUT_DATASET_PATH,\n",
    "#     url=\"https://modelscope.cn/models/user/repo/resolve/master/data_1.7z\",\n",
    "#     name=\"training_dataset.7z\"\n",
    "# )\n",
    "# 这将从 https://modelscope.cn/models/user/repo/resolve/master/data_1.7z 下载训练集压缩包并重命名成 training_dataset.7z\n",
    "# 再将 training_dataset.7z 中的文件解压到 INPUT_DATASET_PATH 中\n",
    "# \n",
    "# \n",
    "# 训练集的要求:\n",
    "# 需要将图片进行打标, 并调整训练集为指定的目结构, 例如:\n",
    "# Nachoneko\n",
    "#     └── 1_nachoneko\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "#             ├── 0(8).txt\n",
    "#             ├── 0(8).webp\n",
    "#             ├── 001_2.png\n",
    "#             ├── 001_2.txt\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "#             ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "#             └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "# \n",
    "# 在 Nachoneko 文件夹新建一个文件夹, 格式为 <数字>_<名称>, 如 1_nachoneko, 前面的数字代表这部分的训练集的重复次数, 1_nachoneko 文件夹内则放图片和打标文件\n",
    "# \n",
    "# 训练集也可以分成多个部分组成, 例如:\n",
    "# Nachoneko\n",
    "#     ├── 1_nachoneko\n",
    "#     │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "#     │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "#     │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "#     │       └── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "#     ├── 2_nachoneko\n",
    "#     │       ├── 0(8).txt\n",
    "#     │       ├── 0(8).webp\n",
    "#     │       ├── 001_2.png\n",
    "#     │       └── 001_2.txt\n",
    "#     └── 4_nachoneko\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "#             ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "#             └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "# \n",
    "# 处理好训练集并调整好目录结构后可以将 Nachoneko 文件夹进行压缩了, 使用 zip / 7z / tar 格式进行压缩\n",
    "# 例如将上述的训练集压缩成 Nachoneko.7z, 此时需要检查一下压缩后在压缩包的目录结果是否和原来的一致(有些压缩软件在部分情况下会破坏原来的目录结构)\n",
    "# 确认没有问题后将该训练集上传到网盘, 推荐使用 HuggingFace / ModelScope\n",
    "\n",
    "\n",
    "# 如果训练集保存在 HuggingFace, 可以使用 sd_scripts.dataset.get_dataset_from_hf() 函数从 HuggingFace 下载数据集\n",
    "# 使用格式:\n",
    "# sd_scripts.dataset.get_dataset_from_hf(\n",
    "#     local_path=INPUT_DATASET_PATH,    # 下载数据集到哪个路径\n",
    "#     repo_id=\"username/train_data\",    # HuggingFace 仓库 ID\n",
    "#     repo_type=\"dataset\",              # HuggingFace 仓库的类型 (model / dataset / space)\n",
    "#     folder=\"folder_in_repo\",          # 指定要从 HuggingFace 仓库里下载哪个文件夹的内容\n",
    "#     hf_token=\"hf_token\"               # HuggingFace Token, 用于访问私有仓库\n",
    "# )\n",
    "# \n",
    "# 比如在 HuggingFace 的仓库为 username/train_data, 仓库类型为 dataset\n",
    "# 仓库的文件结构如下:\n",
    "# ├── Nachoneko\n",
    "# │   ├── 1_nachoneko\n",
    "# │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "# │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "# │   │       ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "# │   │       └── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "# │   ├── 2_nachoneko\n",
    "# │   │       ├── 0(8).txt\n",
    "# │   │       ├── 0(8).webp\n",
    "# │   │       ├── 001_2.png\n",
    "# │   │       └── 001_2.txt\n",
    "# │   └── 4_nachoneko\n",
    "# │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "# │           ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "# │           ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "# │           └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "# └ aaaki\n",
    "#   ├── 1_aaaki\n",
    "#   │   ├── 1.png\n",
    "#   │   ├── 1.txt\n",
    "#   │   ├── 11.png\n",
    "#   │   ├── 11.txt\n",
    "#   │   ├── 12.png\n",
    "#   │   └── 12.txt\n",
    "#   └── 3_aaaki\n",
    "#       ├── 14.png\n",
    "#       ├── 14.txt\n",
    "#       ├── 16.png\n",
    "#       └── 16.txt\n",
    "#\n",
    "# 此时想要下载这个仓库中的 Nachoneko 文件夹的内容, 则下载命令为\n",
    "# sd_scripts.dataset.get_dataset_from_hf(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     folder=\"Nachoneko\",\n",
    "# )\n",
    "# \n",
    "# 如果想下载整个仓库, 则命令修改为\n",
    "# sd_scripts.dataset.get_dataset_from_hf(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\"\n",
    "# )\n",
    "# \n",
    "# 如果仓库为私有仓库, 需要使用 HuggingFace Token 进行访问 \n",
    "# sd_scripts.dataset.get_dataset_from_hf(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     hf_token=\"xxxxxxx\"\n",
    "# )\n",
    "# \n",
    "# 既是私有仓库, 又需要下载里面的某个文件夹中的内容, 则命令修改为\n",
    "# sd_scripts.dataset.get_dataset_from_hf(\n",
    "#     local_path=INPUT_DATASET_PATH,\n",
    "#     repo_id=\"username/train_data\",\n",
    "#     repo_type=\"dataset\",\n",
    "#     folder=\"Nachoneko\",\n",
    "#     hf_token=\"xxxxxxx\"\n",
    "# )\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# sd_scripts.clear_up() # 清理输出\n",
    "echo(\"sd-scripts 安装完成\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "需自行编写命令，下方有可参考的例子  \n",
    "4. [[← 上一个单元](#安装)|[下一个单元 →](#模型上传)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "echo(\"进入 sd-scripts 目录\")\n",
    "os.chdir(SD_SCRIPTS_PATH)\n",
    "echo(\"训练集目录中的文件列表\")\n",
    "!tree -L 1 \"{INPUT_DATASET_PATH}\"\n",
    "echo(\"使用 sd-scripts 进行模型训练\")\n",
    "##########################################################################################\n",
    "# 1.\n",
    "# 运行前需要根据自己的需求更改参数\n",
    "# \n",
    "# 训练参数的设置可参考：\n",
    "# https://rentry.org/59xed3\n",
    "# https://github.com/kohya-ss/sd-scripts?tab=readme-ov-file#links-to-usage-documentation\n",
    "# https://github.com/bmaltais/kohya_ss/wiki/LoRA-training-parameters\n",
    "# \n",
    "# \n",
    "# 2.\n",
    "# 下方被注释的代码选择后使用 Ctrl + / 取消注释\n",
    "# \n",
    "# \n",
    "# 3.\n",
    "# 训练使用的底模会被下载到 SD_MODEL_PATH, 即 /kaggle/sd-scripts/sd-models\n",
    "# 填写底模路径时一般可以通过 --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/base_model.safetensors\" 指定\n",
    "# \n",
    "# 通过 Kaggle Inout 导入的训练集保存在 KAGGLE_INPUT_PATH, 即 /kaggle/input, 运行该笔记时将会把训练集复制进 INPUT_DATASET_PATH, 即 /kaggle/dataset\n",
    "# 该路径可通过 INPUT_DATASET_PATH 调整\n",
    "# 如果使用 sd_scripts.dataset.get_dataset() 函数下载训练集, 数据集一般会解压到 INPUT_DATASET_PATH, 这取决于函数第一个参数传入的路径\n",
    "# 训练集的路径通常要这种结构\n",
    "# $ tree /kaggle\n",
    "# kaggle\n",
    "# └── dataset\n",
    "#     └── Nachoneko\n",
    "#         └── 1_gan_cheng\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.png\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2019 winter 麗.txt\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).png\n",
    "#             ├── [メロンブックス (よろず)]Melonbooks Girls Collection 2020 spring 彩 (オリジナル).txt\n",
    "#             ├── 0(8).txt\n",
    "#             ├── 0(8).webp\n",
    "#             ├── 001_2.png\n",
    "#             ├── 001_2.txt\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.png\n",
    "#             ├── 0b1c8893-c9aa-49e5-8769-f90c4b6866f5.txt\n",
    "#             ├── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.png\n",
    "#             └── 0d5149dd-3bc1-484f-8c1e-a1b94bab3be5.txt\n",
    "# 4 directories, 12 files\n",
    "# 在填写训练集路径时, 应使用 --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\"\n",
    "# \n",
    "# 模型保存的路径通常用 --output_dir=\"{OUTPUT_PATH}\" 指定, 如 --output_dir=\"{OUTPUT_PATH}/Nachoneko\", OUTPUT_PATH 默认设置为 /kaggle/working/model\n",
    "# 在 Kaggle 的 Output 中可以看到保存的模型, 前提是使用 Kaggle 的 Save Version 运行 Kaggle\n",
    "# OUTPUT_PATH 也指定了保存模型到 HuggingFace / ModelScope 的功能的上传路径\n",
    "# \n",
    "# --output_name 用于指定保存的模型名字, 如 --output_name=\"Nachoneko\"\n",
    "# \n",
    "# \n",
    "# 5.\n",
    "# Kaggle 的实例最长可运行 12 h, 要注意训练时长不要超过 12 h, 否则将导致训练被意外中断, 并且最后的模型保存功能将不会得到运行\n",
    "# 如果需要在模型被保存后立即上传到 HuggingFace 进行保存, 可使用启动参数为 sd-scripts 设置自动保存, 具体可阅读 sd-scripts 的帮助信息\n",
    "# 使用 python train_network.py -h 命令可查询可使用的启动参数, 命令中的 train_network.py 可替换成 sdxl_train_network.py 等\n",
    "# \n",
    "# \n",
    "# 6.\n",
    "# 下方提供了一些训练参数, 可以直接使用, 使用时取消注释后根据需求修改部分参数即可\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数在 animagine-xl-3.1.safetensors 测试, 大概在 30 ~ 40 Epoch 有比较好的效果 (在 36 Epoch 出好效果的概率比较高)\n",
    "#\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animagine-xl-3.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=50 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "#\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 在 --network_args 设置了 preset，可以调整训练网络的大小\n",
    "# 该值默认为 full，而使用 attn-mlp 可以得到更小的 LoRA 但几乎不影响 LoRA 效果\n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#         preset=\"attn-mlp\" \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 在 --network_args 设置了 preset，可以调整训练网络的大小\n",
    "# 该值默认为 full，而使用 attn-mlp 可以得到更小的 LoRA 但几乎不影响 LoRA 效果\n",
    "# 可用的预设可阅读文档: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/docs/Preset.md\n",
    "# 该预设也可以自行编写并指定, 编写例子可查看: https://github.com/KohakuBlueleaf/LyCORIS/blob/main/example_configs/preset_configs/example.toml\n",
    "# \n",
    "# 使用 --optimizer_args 设置 weight_decay 和 betas, 更高的 weight_decay 可以降低拟合程度, 减少过拟合\n",
    "# 如果拟合程度不够高, 可以提高 --max_train_epochs 的值, 或者适当降低 weight_decay 的值, 可自行测试\n",
    "# 较小的训练集适合使用较小的值, 如 0.05, 较大的训练集适合用 0.1\n",
    "# 当 weight_decay 设置为 0.05 时, 大概在 38 Epoch 有比较好的效果\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#         preset=\"attn-mlp\" \\\n",
    "#     --optimizer_args \\\n",
    "#         weight_decay=0.1 \\\n",
    "#         betas=\"0.9,0.95\" \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 人物 LoRA, 使用多卡进行训练\n",
    "# 适合极少图或者单图训练集进行人物 LoRA 训练\n",
    "# 训练集使用打标器进行打标后, 要保留的人物的哪些特征, 就把对应的 Tag 删去, 触发词可加可不加\n",
    "# \n",
    "# 该参数使用 scale_weight_norms 降低过拟合程度, 进行训练时, 可在控制台输出看到 Average key norm 这个值\n",
    "# 通常测试 LoRA 时就测试 Average key norm 值在 0.5 ~ 0.9 之间的保存的 LoRA 模型\n",
    "# max_train_epochs 设置为 200, save_every_n_epochs 设置为 1 以为了更好的挑选最好的结果\n",
    "# \n",
    "# 可使用该方法训练一个人物 LoRA 模型用于生成人物的图片, 并将这些图片重新制作成训练集\n",
    "# 再使用不带 scale_weight_norms 的训练参数进行训练, 通过这种方式, 可以在图片极少的情况下得到比较好的 LoRA 模型\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=1 \\\n",
    "#     --max_train_epochs=200 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --scale_weight_norms=1 \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用 rtx 4060 8g laptop 进行训练, 通过 fp8 降低显存占用\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# !python \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=3 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.0002 \\\n",
    "#     --unet_lr=0.0002 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"AdamW8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --fp8_base\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用多卡进行训练\n",
    "# 该参数也可以用于人物 LoRA 训练\n",
    "# \n",
    "# 在训练多画风 LoRA 或者人物 LoRA 时, 通常会打上触发词\n",
    "# 当使用了 --network_train_unet_only 后, Text Encoder 虽然不会训练, 但并不影响将触发词训练进 LoRA 模型中\n",
    "# 并且不训练 Text Encoder 避免 Text Encoder 被炼烂(Text Encoder 比较容易被炼烂)\n",
    "#\n",
    "# 这个参数是在 Illustrious-XL-v0.1.safetensors 模型上测出来的, 大概在 32 Epoch 左右有比较好的效果\n",
    "# 用 animagine-xl-3.1.safetensors 那套参数也有不错的效果, 只是学习率比这套低了点, 学得慢一点\n",
    "# 学习率调度器从 cosine_with_restarts 换成 constant_with_warmup, 此时学习率靠优化器(Lion8bit)进行调度\n",
    "# 拟合速度会更快\n",
    "# constant_with_warmup 用在大规模的训练上比较好, 但用在小规模训练也有不错的效果\n",
    "# 如果训练集的图比较少, 重复的图较多, 重复次数较高, 可能容易造成过拟合\n",
    "# \n",
    "# 参数加上了 noise_offset, 可以提高暗处和亮处的表现, 一般使用设置成 0.05 ~ 0.1\n",
    "# 但 noise_offset 可能会导致画面泛白, 光影效果变差\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/Illustrious-XL-v0.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/Nachoneko\" \\\n",
    "#     --output_name=\"Nachoneko_2\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/Nachoneko\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00012 \\\n",
    "#     --unet_lr=0.00012 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --noise_offset=0.1 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 人物 LoRA, 使用多卡进行训练\n",
    "# 参数中使用了 --scale_weight_norms, 用于提高泛化性, 但可能会造成拟合度降低\n",
    "# 如果当训练人物 LoRA 的图片较多时, 可考虑删去该参数\n",
    "# 当训练人物 LoRA 的图片较少, 为了避免过拟合, 就可以考虑使用 --scale_weight_norms 降低过拟合概率\n",
    "#\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animagine-xl-3.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/robin\" \\\n",
    "#     --output_name=\"robin_1\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/robin_1\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=50 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --scale_weight_norms=1 \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 人物 LoRA, 使用多卡进行训练\n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animagine-xl-3.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/murasame_(senren)_3\" \\\n",
    "#     --output_name=\"murasame_(senren)_10\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/murasame_(senren)_10\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=50 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --learning_rate=0.0001 \\\n",
    "#     --unet_lr=0.0001 \\\n",
    "#     --text_encoder_lr=0.00004 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --scale_weight_norms=1 \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 XL 画风 LoRA, 使用单卡进行训练 (Kaggle 的单 Tesla P100 性能不如双 Tesla T4, 建议使用双卡训练)\n",
    "# !python \"{SD_SCRIPTS_PATH}/sdxl_train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animagine-xl-3.1.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/sdxl_fp16_fix_vae.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/rafa\" \\\n",
    "#     --output_name=\"rafa_1\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/rafa\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"1024,1024\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=2048 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=50 \\\n",
    "#     --train_batch_size=6 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00007 \\\n",
    "#     --unet_lr=0.00007 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"cosine_with_restarts\" \\\n",
    "#     --lr_warmup_steps=0 \\\n",
    "#     --lr_scheduler_num_cycles=1 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 SD1.5 画风 LoRA, 使用双卡进行训练\n",
    "# 使用 NovelAI 1 模型进行训练\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animefull-final-pruned.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/vae-ft-mse-840000-ema-pruned.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/sunfish\" \\\n",
    "#     --output_name=\"nai1-sunfish_5\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/nai1-sunfish_5\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"768,768\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=1024 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=12 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --network_train_unet_only \\\n",
    "#     --learning_rate=0.00024 \\\n",
    "#     --unet_lr=0.00024 \\\n",
    "#     --text_encoder_lr=0.00001 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n",
    "\n",
    "\n",
    "# 使用 lokr 算法训练 SD1.5 多画风(多概念) LoRA, 使用双卡进行训练\n",
    "# 使用 NovelAI 1 模型进行训练\n",
    "# \n",
    "# 在 SD1.5 中训练 Text Encoder 可以帮助模型更好的区分不同的画风(概念)\n",
    "# \n",
    "# !python -m accelerate.commands.launch \\\n",
    "#     --num_cpu_threads_per_process=1 \\\n",
    "#     --multi_gpu \\\n",
    "#     --num_processes=2 \\\n",
    "#     \"{SD_SCRIPTS_PATH}/train_network.py\" \\\n",
    "#     --pretrained_model_name_or_path=\"{SD_MODEL_PATH}/animefull-final-pruned.safetensors\" \\\n",
    "#     --vae=\"{SD_MODEL_PATH}/vae-ft-mse-840000-ema-pruned.safetensors\" \\\n",
    "#     --train_data_dir=\"{INPUT_DATASET_PATH}/sunfish\" \\\n",
    "#     --output_name=\"nai1-sunfish_5\" \\\n",
    "#     --output_dir=\"{OUTPUT_PATH}/nai1-sunfish_5\" \\\n",
    "#     --prior_loss_weight=1 \\\n",
    "#     --resolution=\"768,768\" \\\n",
    "#     --enable_bucket \\\n",
    "#     --min_bucket_reso=256 \\\n",
    "#     --max_bucket_reso=1024 \\\n",
    "#     --bucket_reso_steps=64 \\\n",
    "#     --save_model_as=\"safetensors\" \\\n",
    "#     --save_precision=\"fp16\" \\\n",
    "#     --save_every_n_epochs=2 \\\n",
    "#     --max_train_epochs=40 \\\n",
    "#     --train_batch_size=12 \\\n",
    "#     --gradient_checkpointing \\\n",
    "#     --learning_rate=0.00028 \\\n",
    "#     --unet_lr=0.00028 \\\n",
    "#     --text_encoder_lr=0.000015 \\\n",
    "#     --lr_scheduler=\"constant_with_warmup\" \\\n",
    "#     --lr_warmup_steps=100 \\\n",
    "#     --optimizer_type=\"Lion8bit\" \\\n",
    "#     --network_module=\"lycoris.kohya\" \\\n",
    "#     --network_dim=100000 \\\n",
    "#     --network_alpha=100000 \\\n",
    "#     --network_args \\\n",
    "#         conv_dim=100000 \\\n",
    "#         conv_alpha=100000 \\\n",
    "#         algo=lokr \\\n",
    "#         dropout=0 \\\n",
    "#         factor=8 \\\n",
    "#         train_norm=True \\\n",
    "#     --log_with=\"tensorboard\" \\\n",
    "#     --logging_dir=\"{OUTPUT_PATH}/logs\" \\\n",
    "#     --caption_extension=\".txt\" \\\n",
    "#     --shuffle_caption \\\n",
    "#     --keep_tokens=0 \\\n",
    "#     --max_token_length=225 \\\n",
    "#     --seed=1337 \\\n",
    "#     --mixed_precision=\"fp16\" \\\n",
    "#     --xformers \\\n",
    "#     --cache_latents \\\n",
    "#     --cache_latents_to_disk \\\n",
    "#     --persistent_data_loader_workers \\\n",
    "#     --full_fp16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型上传\n",
    "5. [← 上一个单元](#模型训练)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型上传到 HuggingFace / ModelScope, 通常不需要修改, 修改参数建议通过上方的参数配置单元进行修改\n",
    "\n",
    "# 使用 HuggingFace 上传模型\n",
    "if USE_HF_TO_SAVE_MODEL:\n",
    "    echo(\"使用 HuggingFace 保存模型\")\n",
    "    sd_scripts.repo_manager.push_file_to_huggingface(\n",
    "        hf_access_token=HF_TOKEN, # HuggingFace Token\n",
    "        repo_id=HF_REPO_ID, # HuggingFace 仓库地址\n",
    "        repo_type=HF_REPO_TYPE, # HuggingFace 仓库种类\n",
    "        upload_path=OUTPUT_PATH # 要上传文件的目录\n",
    "    )\n",
    "\n",
    "# 使用 ModelScope 上传模型\n",
    "if USE_MS_TO_SAVE_MODEL:\n",
    "    echo(\"使用 ModelScope 保存模型\")\n",
    "    # 配置 Git\n",
    "    sd_scripts.repo_manager.set_git_config(\n",
    "        email=GIT_USER_EMAIL,\n",
    "        username=GIT_USER_NAME\n",
    "    )\n",
    "    # 上传模型\n",
    "    sd_scripts.repo_manager.push_file_to_modelscope(\n",
    "        ms_access_token = MS_TOKEN, # Modelscope Token\n",
    "        repo_id=MS_REPO_ID, # Modelscope 的仓库地址\n",
    "        repo_type=MS_REPO_TYPE, # ModelScope 仓库的种类\n",
    "        work_path=os.path.join(WORKSPACE, \"working\", \"MS_REPO\"), # 脚本工作目录, 仓库将克隆至该文件夹中\n",
    "        upload_path=OUTPUT_PATH # 要上传文件的目录\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
